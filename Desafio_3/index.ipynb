{
  "cells": [
    {
      "metadata": {
        "id": "ec9BiH16iCwL"
      },
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://github.com/hernancontigiani/ceia_memorias_especializacion/raw/master/Figures/logoFIUBA.jpg\" width=\"500\" align=\"center\">\n",
        "\n",
        "\n",
        "# Procesamiento de lenguaje natural\n",
        "## Modelo de lenguaje con tokenizaciÃ³n por caracteres"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iv5PEwGzZA9-"
      },
      "source": [
        "### Entrenamiento del Modelo\n",
        "\n",
        "El proceso de entrenamiento se llevÃ³ a cabo mediante el script `train.py`. Debido al alto costo computacional y la duraciÃ³n del proceso, esta etapa se desacoplÃ³ del notebook principal y se ejecutÃ³ en segundo plano (*background*) en un servidor Linux dedicado.\n",
        "\n",
        "Para consultar los detalles de la implementaciÃ³n, las curvas de aprendizaje y el anÃ¡lisis de los resultados, por favor refiÃ©rase al documento `index.md`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mCeMWWupxN1-"
      },
      "source": [
        "### GeneraciÃ³n de secuencias"
      ]
    },
    {
      "metadata": {
        "id": "YwzNMYuBiCwQ",
        "outputId": "7c108539-4b42-4ebe-d576-ee46c3ae39da",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'procesamiento_lenguaje_natural-tp'...\n",
            "remote: Enumerating objects: 130, done.\u001b[K\n",
            "remote: Counting objects: 100% (130/130), done.\u001b[K\n",
            "remote: Compressing objects: 100% (112/112), done.\u001b[K\n",
            "remote: Total 130 (delta 35), reused 94 (delta 14), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (130/130), 5.74 MiB | 18.73 MiB/s, done.\n",
            "Resolving deltas: 100% (35/35), done.\n",
            "/content/procesamiento_lenguaje_natural-tp/Desafio_3\n"
          ]
        }
      ],
      "execution_count": 1,
      "source": [
        "\n",
        "# Solo ejecutar esta celda cuando se use desde colab\n",
        "!git clone https://github.com/joseluisdiaz/procesamiento_lenguaje_natural-tp.git\n",
        "%cd /content/procesamiento_lenguaje_natural-tp/Desafio_3/\n"
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-12-10T22:37:14.361533Z",
          "start_time": "2025-12-10T22:37:12.172332Z"
        },
        "id": "qQeTa6MAiCwR"
      },
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.utils import pad_sequences\n",
        "import os"
      ],
      "outputs": [],
      "execution_count": 2
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-12-11T00:01:12.112885Z",
          "start_time": "2025-12-11T00:01:12.109943Z"
        },
        "id": "Xve5_BCGiCwS"
      },
      "cell_type": "code",
      "source": [
        "def hidratar_diccionarios(vocab_path='vocab.pkl'):\n",
        "    \"\"\"\n",
        "    Carga los diccionarios, inyectÃ¡ndolos en el entorno para\n",
        "    que las funciones de inferencia puedan usarlos directamente.\n",
        "    \"\"\"\n",
        "    if not os.path.exists(vocab_path):\n",
        "        print(f\"âš ï¸ ERROR: No se encuentran {vocab_path}\")\n",
        "        print(\"AsegÃºrate de subir los archivos generados por train.py al entorno del notebook.\")\n",
        "        return None, None, None\n",
        "\n",
        "    print(f\"Cargando vocabulario desde {vocab_path}...\")\n",
        "    with open(vocab_path, 'rb') as f:\n",
        "        vocab_data = pickle.load(f)\n",
        "\n",
        "    char2idx = vocab_data['char2idx']\n",
        "    idx2char = vocab_data['idx2char']\n",
        "\n",
        "    print(\"âœ… Â¡Entorno hidratado correctamente!\")\n",
        "    return char2idx, idx2char\n",
        "\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": 3
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-12-11T00:01:24.281341Z",
          "start_time": "2025-12-11T00:01:24.072509Z"
        },
        "id": "QRLOa8nMiCwT",
        "outputId": "ee734a8e-6324-419d-a028-61043022f4a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 795
        }
      },
      "cell_type": "code",
      "source": [
        "# --- EJECUTAR CARGA ---\n",
        "# Esto define las variables globales char2idx e idx2char\n",
        "char2idx, idx2char = hidratar_diccionarios()\n",
        "model_simplernn = load_model('simplernn_best_model.keras')\n",
        "model_gru = load_model('gru_best_model.keras')\n",
        "model_lstm = load_model('lstm_best_model.keras')\n",
        "\n",
        "model_simplernn.summary()\n",
        "model_gru.summary()\n",
        "model_lstm.summary()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cargando vocabulario desde vocab.pkl...\n",
            "âœ… Â¡Entorno hidratado correctamente!\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ time_distributed                â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m67\u001b[0m)       â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”‚ (\u001b[38;5;33mTimeDistributed\u001b[0m)               â”‚                        â”‚               â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ simple_rnn (\u001b[38;5;33mSimpleRNN\u001b[0m)          â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m)      â”‚        \u001b[38;5;34m53,600\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense (\u001b[38;5;33mDense\u001b[0m)                   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m67\u001b[0m)       â”‚        \u001b[38;5;34m13,467\u001b[0m â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                    </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape           </span>â”ƒ<span style=\"font-weight: bold\">       Param # </span>â”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ time_distributed                â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">67</span>)       â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               â”‚                        â”‚               â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ simple_rnn (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SimpleRNN</span>)          â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)      â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">53,600</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">67</span>)       â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">13,467</span> â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m134,136\u001b[0m (523.97 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">134,136</span> (523.97 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m67,067\u001b[0m (261.98 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">67,067</span> (261.98 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m67,069\u001b[0m (261.99 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">67,069</span> (261.99 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ time_distributed                â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m67\u001b[0m)       â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”‚ (\u001b[38;5;33mTimeDistributed\u001b[0m)               â”‚                        â”‚               â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ gru (\u001b[38;5;33mGRU\u001b[0m)                       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m)      â”‚       \u001b[38;5;34m161,400\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense (\u001b[38;5;33mDense\u001b[0m)                   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m67\u001b[0m)       â”‚        \u001b[38;5;34m13,467\u001b[0m â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                    </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape           </span>â”ƒ<span style=\"font-weight: bold\">       Param # </span>â”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ time_distributed                â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">67</span>)       â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               â”‚                        â”‚               â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ gru (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)      â”‚       <span style=\"color: #00af00; text-decoration-color: #00af00\">161,400</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">67</span>)       â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">13,467</span> â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m349,736\u001b[0m (1.33 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">349,736</span> (1.33 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m174,867\u001b[0m (683.07 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">174,867</span> (683.07 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m174,869\u001b[0m (683.09 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">174,869</span> (683.09 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ time_distributed                â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m67\u001b[0m)       â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”‚ (\u001b[38;5;33mTimeDistributed\u001b[0m)               â”‚                        â”‚               â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m)      â”‚       \u001b[38;5;34m214,400\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense (\u001b[38;5;33mDense\u001b[0m)                   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m67\u001b[0m)       â”‚        \u001b[38;5;34m13,467\u001b[0m â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                    </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape           </span>â”ƒ<span style=\"font-weight: bold\">       Param # </span>â”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ time_distributed                â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">67</span>)       â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               â”‚                        â”‚               â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)      â”‚       <span style=\"color: #00af00; text-decoration-color: #00af00\">214,400</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">67</span>)       â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">13,467</span> â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m455,736\u001b[0m (1.74 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">455,736</span> (1.74 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m227,867\u001b[0m (890.11 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">227,867</span> (890.11 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m227,869\u001b[0m (890.12 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">227,869</span> (890.12 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 5
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bwbS_pfhxvB3",
        "ExecuteTime": {
          "end_time": "2025-12-11T00:00:37.228688Z",
          "start_time": "2025-12-11T00:00:37.223577Z"
        }
      },
      "source": [
        "def generate_seq(model, seed_text, max_length, n_words):\n",
        "    \"\"\"\n",
        "        Exec model sequence prediction\n",
        "\n",
        "        Args:\n",
        "            model (keras): modelo entrenado\n",
        "            seed_text (string): texto de entrada (input_seq)\n",
        "            max_length (int): mÃ¡xima longitud de la sequencia de entrada\n",
        "            n_words (int): nÃºmeros de caracteres a agregar a la sequencia de entrada\n",
        "        returns:\n",
        "            output_text (string): sentencia con las \"n_words\" agregadas\n",
        "    \"\"\"\n",
        "    output_text = seed_text\n",
        "\t# generate a fixed number of words\n",
        "    for _ in range(n_words):\n",
        "\t\t# Encodeamos\n",
        "        encoded = [char2idx[ch] for ch in output_text.lower() ]\n",
        "\t\t# Si tienen distinto largo\n",
        "        encoded = pad_sequences([encoded], maxlen=max_length, padding='pre')\n",
        "\n",
        "\t\t# PredicciÃ³n softmax\n",
        "        y_hat = np.argmax(model.predict(encoded,verbose=0)[0,-1,:])\n",
        "\t\t# Vamos concatenando las predicciones\n",
        "        out_word = ''\n",
        "\n",
        "        out_word = idx2char[y_hat]\n",
        "\n",
        "\t\t# Agrego las palabras a la frase predicha\n",
        "        output_text += out_word\n",
        "    return output_text"
      ],
      "outputs": [],
      "execution_count": 6
    },
    {
      "metadata": {
        "id": "PcC8UH-fiCwU"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": 7,
      "source": [
        "# Definimos los modelos en un diccionario\n",
        "modelos = {\n",
        "    \"SimpleRNN\": model_simplernn,\n",
        "    \"GRU\": model_gru,\n",
        "    \"LSTM\": model_lstm\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JoFqRC5pxzqS",
        "ExecuteTime": {
          "end_time": "2025-12-11T19:58:13.465200Z",
          "start_time": "2025-12-11T19:57:56.970817Z"
        },
        "outputId": "7f1288a4-8b0a-498c-9272-1995be49a01e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "seed = 'habia una vez'\n",
        "n_words = 100\n",
        "max_length = 100\n",
        "\n",
        "print(f\"--- SEMILLA: '{seed}' ---\\n\")\n",
        "\n",
        "for nombre, modelo in modelos.items():\n",
        "    print(f\"ğŸ”µ Modelo: {nombre}\")\n",
        "    texto = generate_seq(modelo, seed, max_length, n_words)\n",
        "    print(f\"Generado: ...{texto[len(seed):]}\")\n",
        "    print(f\"Full:     {texto}\")\n",
        "    print(\"-\" * 50) # Separador visual"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- SEMILLA: 'habia una vez' ---\n",
            "\n",
            "ğŸ”µ Modelo: SimpleRNN\n",
            "Generado: ... en el camino de la carca de la carca de la carca de la carca de la carca de la carca de la carca de\n",
            "Full:     habia una vez en el camino de la carca de la carca de la carca de la carca de la carca de la carca de la carca de\n",
            "--------------------------------------------------\n",
            "ğŸ”µ Modelo: GRU\n",
            "Generado: ... en el camino de la maÃ±ana, se habÃ­a despuÃ©s de haber ser \n",
            "visto a la estaciÃ³n de la maÃ±ana, se habÃ­\n",
            "Full:     habia una vez en el camino de la maÃ±ana, se habÃ­a despuÃ©s de haber ser \n",
            "visto a la estaciÃ³n de la maÃ±ana, se habÃ­\n",
            "--------------------------------------------------\n",
            "ğŸ”µ Modelo: LSTM\n",
            "Generado: ... en el camino de la maÃ±ana, el tren se habÃ­a desaparecido en \n",
            "consiguiente, el tren se habÃ­a desapar\n",
            "Full:     habia una vez en el camino de la maÃ±ana, el tren se habÃ­a desaparecido en \n",
            "consiguiente, el tren se habÃ­a desapar\n",
            "--------------------------------------------------\n"
          ]
        }
      ],
      "execution_count": 8
    },
    {
      "metadata": {
        "id": "0ctf6wToiCwV"
      },
      "cell_type": "markdown",
      "source": [
        "SimpleRNN entrÃ³ en loop como era de esperar (memoria corta) mientras que GRU y LSTM aprendio algo mÃ¡s sobre el libro."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "drJ6xn5qW1Hl"
      },
      "source": [
        "###  Beam search y muestreo aleatorio"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "YYo6-YCUiirR"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_vovn9XZW1Hl",
        "ExecuteTime": {
          "end_time": "2025-12-10T23:50:51.385643Z",
          "start_time": "2025-12-10T23:50:51.382935Z"
        }
      },
      "source": [
        "# funcionalidades para hacer encoding y decoding\n",
        "\n",
        "def encode(text, max_length=100):\n",
        "\n",
        "    encoded = [char2idx[ch] for ch in text]\n",
        "    encoded = pad_sequences([encoded], maxlen=max_length, padding='pre')\n",
        "\n",
        "    return encoded\n",
        "\n",
        "def decode(seq):\n",
        "    return ''.join([idx2char[ch] for ch in seq])"
      ],
      "outputs": [],
      "execution_count": 9
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I_lZiQwkW1Hl",
        "ExecuteTime": {
          "end_time": "2025-12-10T23:50:54.218385Z",
          "start_time": "2025-12-10T23:50:54.210938Z"
        }
      },
      "source": [
        "from scipy.special import softmax\n",
        "\n",
        "# funciÃ³n que selecciona candidatos para el beam search\n",
        "def select_candidates(pred,num_beams,vocab_size,history_probs,history_tokens,temp,mode):\n",
        "\n",
        "  # colectar todas las probabilidades para la siguiente bÃºsqueda\n",
        "  pred_large = []\n",
        "\n",
        "  for idx,pp in enumerate(pred):\n",
        "    pred_large.extend(np.log(pp+1E-10)+history_probs[idx])\n",
        "\n",
        "  pred_large = np.array(pred_large)\n",
        "\n",
        "  # criterio de selecciÃ³n\n",
        "  if mode == 'det':\n",
        "    idx_select = np.argsort(pred_large)[::-1][:num_beams] # beam search determinista\n",
        "  elif mode == 'sto':\n",
        "    idx_select = np.random.choice(np.arange(pred_large.shape[0]), num_beams, p=softmax(pred_large/temp)) # beam search con muestreo aleatorio\n",
        "  else:\n",
        "    raise ValueError(f'Wrong selection mode. {mode} was given. det and sto are supported.')\n",
        "\n",
        "  # traducir a Ã­ndices de token en el vocabulario\n",
        "  new_history_tokens = np.concatenate((np.array(history_tokens)[idx_select//vocab_size],\n",
        "                        np.array([idx_select%vocab_size]).T),\n",
        "                      axis=1)\n",
        "\n",
        "  # devolver el producto de las probabilidades (log) y la secuencia de tokens seleccionados\n",
        "  return pred_large[idx_select.astype(int)], new_history_tokens.astype(int)\n",
        "\n",
        "\n",
        "def beam_search(model,num_beams,num_words,input,temp=1,mode='det'):\n",
        "\n",
        "    # first iteration\n",
        "\n",
        "    # encode\n",
        "    encoded = encode(input)\n",
        "\n",
        "    # first prediction\n",
        "    y_hat = model.predict(encoded,verbose=0)[0,-1,:]\n",
        "\n",
        "    # get vocabulary size\n",
        "    vocab_size = y_hat.shape[0]\n",
        "\n",
        "    # initialize history\n",
        "    history_probs = [0]*num_beams\n",
        "    history_tokens = [encoded[0]]*num_beams\n",
        "\n",
        "    # select num_beams candidates\n",
        "    history_probs, history_tokens = select_candidates([y_hat],\n",
        "                                        num_beams,\n",
        "                                        vocab_size,\n",
        "                                        history_probs,\n",
        "                                        history_tokens,\n",
        "                                        temp,\n",
        "                                        mode)\n",
        "\n",
        "    # beam search loop\n",
        "    for i in range(num_words-1):\n",
        "\n",
        "      preds = []\n",
        "\n",
        "      for hist in history_tokens:\n",
        "\n",
        "        # actualizar secuencia de tokens\n",
        "        input_update = np.array([hist[i+1:]]).copy()\n",
        "\n",
        "        # predicciÃ³n\n",
        "        y_hat = model.predict(input_update,verbose=0)[0,-1,:]\n",
        "\n",
        "        preds.append(y_hat)\n",
        "\n",
        "      history_probs, history_tokens = select_candidates(preds,\n",
        "                                                        num_beams,\n",
        "                                                        vocab_size,\n",
        "                                                        history_probs,\n",
        "                                                        history_tokens,\n",
        "                                                        temp,\n",
        "                                                        mode)\n",
        "\n",
        "    return history_tokens[:,-(len(input)+num_words):]"
      ],
      "outputs": [],
      "execution_count": 10
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GeLqAoOYW1Hm",
        "ExecuteTime": {
          "end_time": "2025-12-11T20:27:07.321994Z",
          "start_time": "2025-12-11T20:19:26.746487Z"
        },
        "outputId": "e6e7c049-6b62-476c-e048-154d97134176",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# ConfiguraciÃ³n global\n",
        "seed = \"habia una vez\"\n",
        "L = 50  # Longitud a generar\n",
        "num_beams_det = 5   # Beams para determinista\n",
        "num_beams_sto = 10  # Beams para estocÃ¡stico (mÃ¡s ancho ayuda a la variedad)\n",
        "temperaturas = [0.2, 0.5, 1.0, 1.2, 1.5]\n",
        "\n",
        "# Definimos tus modelos disponibles\n",
        "# AsegÃºrate de tener estas variables ya cargadas en tu notebook\n",
        "modelos = {\n",
        "    \"SimpleRNN\": model_simplernn,\n",
        "    \"GRU\": model_gru,\n",
        "    \"LSTM\": model_lstm\n",
        "}\n",
        "\n",
        "def evaluar_generacion(nombre_modelo, modelo):\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"ğŸ¤– EVALUANDO MODELO: {nombre_modelo}\")\n",
        "    print(f\"{'='*60}\")\n",
        "\n",
        "    # --- 1. Beam Search Determinista ---\n",
        "    print(f\"\\nğŸ”¹ Modo: Beam Search Determinista (Beams={num_beams_det})\")\n",
        "    try:\n",
        "        secuencias = beam_search(\n",
        "            model=modelo,\n",
        "            num_beams=num_beams_det,\n",
        "            num_words=L,\n",
        "            input=seed,\n",
        "            mode='det'\n",
        "        )\n",
        "        # En determinista, el Ã­ndice 0 es el de mayor probabilidad acumulada\n",
        "        texto = decode(secuencias[0])\n",
        "        print(f\"   Generado: ...{texto}\")\n",
        "    except Exception as e:\n",
        "        print(f\"   âŒ Error: {e}\")\n",
        "\n",
        "    # --- 2. Beam Search EstocÃ¡stico con Temperaturas ---\n",
        "    print(f\"\\nğŸ”¹ Modo: Beam Search EstocÃ¡stico\")\n",
        "\n",
        "    for temp in temperaturas:\n",
        "        try:\n",
        "            secuencias = beam_search(\n",
        "                model=modelo,\n",
        "                num_beams=num_beams_sto,\n",
        "                num_words=L,\n",
        "                input=seed,\n",
        "                temp=temp,\n",
        "                mode='sto'\n",
        "            )\n",
        "\n",
        "            # En estocÃ¡stico, cualquiera de los caminos es vÃ¡lido. Mostramos el primero.\n",
        "            texto = decode(secuencias[0])\n",
        "            print(f\"   ğŸŒ¡ï¸ Temp {temp}: ...{texto}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"   âŒ Error con temp {temp}: {e}\")\n",
        "\n",
        "# --- Bucle Principal ---\n",
        "for nombre, modelo in modelos.items():\n",
        "    evaluar_generacion(nombre, modelo)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "ğŸ¤– EVALUANDO MODELO: SimpleRNN\n",
            "============================================================\n",
            "\n",
            "ğŸ”¹ Modo: Beam Search Determinista (Beams=5)\n",
            "   Generado: ...habia una vez en su compaÃ±ero de los viajeros que se habÃ­a comp\n",
            "\n",
            "ğŸ”¹ Modo: Beam Search EstocÃ¡stico\n",
            "   ğŸŒ¡ï¸ Temp 0.2: ...habia una vez en el cortado por el capitÃ¡n de la maÃ±ana, sin em\n",
            "   ğŸŒ¡ï¸ Temp 0.5: ...habia una vez en el conductor de los viajeros que se habÃ­a esta\n",
            "   ğŸŒ¡ï¸ Temp 1.0: ...habia una vez en la estaciÃ³n del consiguiente de los viajeros â€”\n",
            "   ğŸŒ¡ï¸ Temp 1.2: ...habia una vez se habÃ­a profecto, sin parecÃ­a para que no puede \n",
            "   ğŸŒ¡ï¸ Temp 1.5: ...habia una vez en el corte inglÃ©s se habÃ­a con el cuento que ser\n",
            "\n",
            "============================================================\n",
            "ğŸ¤– EVALUANDO MODELO: GRU\n",
            "============================================================\n",
            "\n",
            "ğŸ”¹ Modo: Beam Search Determinista (Beams=5)\n",
            "   Generado: ...habia una vez en la estaciÃ³n de la estaciÃ³n de la estaciÃ³n del \n",
            "\n",
            "ğŸ”¹ Modo: Beam Search EstocÃ¡stico\n",
            "   ğŸŒ¡ï¸ Temp 0.2: ...habia una vez en el cual no se habÃ­a despuÃ©s de haber sido entr\n",
            "   ğŸŒ¡ï¸ Temp 0.5: ...habia una vez en el cual no se habÃ­a recomendado por la estaciÃ³\n",
            "   ğŸŒ¡ï¸ Temp 1.0: ...habia una vez en la estaciÃ³n de la estaciÃ³n de calcuta de los m\n",
            "   ğŸŒ¡ï¸ Temp 1.2: ...habia una vez entre los mormones de la compaÃ±Ã­a de la maÃ±ana, y\n",
            "   ğŸŒ¡ï¸ Temp 1.5: ...habia una vez en que el honorable gentleman no habÃ­a recomendar\n",
            "\n",
            "============================================================\n",
            "ğŸ¤– EVALUANDO MODELO: LSTM\n",
            "============================================================\n",
            "\n",
            "ğŸ”¹ Modo: Beam Search Determinista (Beams=5)\n",
            "   Generado: ...habia una vez en el coronel proctor de los viajeros se habÃ­an d\n",
            "\n",
            "ğŸ”¹ Modo: Beam Search EstocÃ¡stico\n",
            "   ğŸŒ¡ï¸ Temp 0.2: ...habia una vez en el camino de la maÃ±ana, el tren se habÃ­a compr\n",
            "   ğŸŒ¡ï¸ Temp 0.5: ...habia una vez la estaciÃ³n de la india, que se habÃ­a dejado en e\n",
            "   ğŸŒ¡ï¸ Temp 1.0: ...habia una vez en su amo. el capitÃ¡n de los viajeros de la pagod\n",
            "   ğŸŒ¡ï¸ Temp 1.2: ...habia una vez el reform-club de todas las cuales estaban entreg\n",
            "   ğŸŒ¡ï¸ Temp 1.5: ...habia una vez a todos los hombres de los viajeros, y el vagÃ³n y\n"
          ]
        }
      ],
      "execution_count": 11
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q_LlqmtEW1Hn"
      },
      "source": [
        "**Arquitectura:** La **LSTM** demostrÃ³ ser superior pudiendo rescatar nombres propios (ej. \"coronel proctor\", \"reform-club\").\n",
        "\n",
        "**Estrategia:**\n",
        "* **Greedy Search:** Tiende a caer en bucles repetitivos (\"de la casa de la la carca de la carca de...\").\n",
        "* **Beam Search Determinista:** Genera texto gramaticalmente correcto pero a veces monÃ³tono.\n",
        "* **Beam Search EstocÃ¡stico (Temp ~1.0):** Ofrece el mejor balance entre coherencia y creatividad, evitando repeticiones y generando frases mÃ¡s naturales."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}