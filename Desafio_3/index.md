# Generaci칩n de Texto Caracter a Caracter (Char-Level RNN)

Este proyecto implementa y compara diferentes arquitecturas de Redes Neuronales Recurrentes (SimpleRNN, GRU y LSTM) para la generaci칩n de texto a nivel de caracteres. El modelo fue entrenado utilizando el corpus del libro *"La vuelta al mundo en 80 d칤as"* de Julio Verne.

El objetivo es predecir el siguiente caracter dada una secuencia de texto anterior, permitiendo generar "nuevo" texto que imita el estilo y estructura del autor.

## Estructura del Proyecto

* **`preparar_datos.py`**: Descarga el libro, limpia el texto, genera el vocabulario y guarda los datos procesados (`corpus_tokenizado.npy` y `vocab.pkl`).
* **`train.py`**: Script de entrenamiento. Define la arquitectura, conecta con Weights & Biases (W&B) y guarda el mejor modelo (`best_model.keras`).
* **`inference_utils.py` / `generate.py`**: Funciones para cargar el modelo y generar texto usando estrategias como Greedy Search y Beam Search.
* **`vocab.pkl`**: Diccionarios de mapeo (caracter <-> 칤ndice).
* **`best_model.keras`**: El modelo entrenado con menor perplejidad.

## Instrucciones de Ejecuci칩n

### 1. Preparaci칩n del Entorno
Instala las dependencias necesarias:
```bash
pip install tensorflow numpy pandas scipy wandb python-dotenv beautifulsoup4 lxml
```

### 2. Procesamiento de Datos
Antes de entrenar, debes descargar y tokenizar el dataset. Esto genera los archivos est치ticos para no repetir el proceso en cada entrenamiento.

```bash
python preparar_datos.py
```

### 3. Entrenamiento
Puedes entrenar el modelo ejecutando el script principal. El script soporta variables de entorno para cambiar la configuraci칩n sin tocar el c칩digo.

**Entrenamiento b치sico (SimpleRNN por defecto):**
```bash
python train.py
```

**Entrenamiento personalizado (Recomendado):**
Puedes elegir la arquitectura (`LSTM`, `GRU`, `SimpleRNN`) y el n칰mero de capas (`LAYERS`).

```bash
# Ejemplo: Entrenar una LSTM de 1 capa (Linux/Mac)
MODEL=LSTM LAYERS=1 python train.py

# Ejemplo: Entrenar una GRU (Windows PowerShell)
$env:MODEL="GRU"; python train.py
```

*Nota: Se requiere una cuenta de [Weights & Biases](https://wandb.ai/). La primera vez que lo ejecutes te pedir치 tu API Key, o puedes definirla en un archivo `.env` como `WANDB_API_KEY`.*

## 游늵 An치lisis de Resultados

Se entrenaron tres arquitecturas bajo las mismas condiciones (Contexto: 100 caracteres, Hidden Units: 200, Optimizador: RMSprop) para comparar su desempe침o. A continuaci칩n se presentan las m칠tricas obtenidas.

### Comparativa de Perplejidad (Validation Perplexity)

La perplejidad mide qu칠 tan "sorprendido" est치 el modelo al ver nuevos datos. **Menor es mejor.**

![Perplejidad de Validaci칩n](g1.png)

* **LSTM (L칤nea Rosa):** Fue el modelo m치s robusto. Aunque su convergencia inicial fue m치s lenta que la GRU, logr칩 mantener el descenso de la m칠trica por m치s tiempo, alcanzando la **menor perplejidad final (< 3.9)** tras ~100 칠pocas. Esto indica una mejor capacidad para modelar dependencias a largo plazo y estructura gramatical.
* **GRU (L칤nea Verde):** Mostr칩 la convergencia m치s r치pida. En las primeras 10 칠pocas redujo dr치sticamente el error. Sin embargo, el *Early Stopping* detuvo el entrenamiento alrededor de la 칠poca 25 con una perplejidad cercana a 4.0, sugiriendo que satur칩 su capacidad de aprendizaje m치s r치pido que la LSTM.
* **SimpleRNN (L칤nea Violeta):** Tuvo el peor desempe침o. Se estanc칩 r치pidamente en una perplejidad de ~4.5. Su incapacidad para retener informaci칩n de contexto le impidi칩 aprender estructuras complejas, resultando en textos repetitivos.

### Comparativa de Loss (Batch Loss)

![Training Loss](g2.png)

La gr치fica de Loss confirma lo observado en la perplejidad. La **LSTM** demuestra una capacidad de aprendizaje continuo y estable a lo largo de muchos pasos de entrenamiento, mientras que la **SimpleRNN** choca con una "pared" de aprendizaje muy temprano debido al problema del desvanecimiento del gradiente.

## Modelos Pre-entrenados

El proyecto incluye tres checkpoints correspondientes a las mejores 칠pocas de entrenamiento de cada arquitectura. Aseg칰rate de tener los archivos `.keras` en la ra칤z del proyecto:

* `simplernn_best_model.keras`: Modelo base con SimpleRNN.
* `gru_best_model.keras`: Modelo intermedio con celdas GRU.
* `lstm_best_model.keras`: Modelo con mejor rendimiento (LSTM).

##  Exploraci칩n Interactiva

Para facilitar la experimentaci칩n y comparaci칩n visual entre modelos, se incluye el notebook **`index.ipynb`** [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/joseluisdiaz/procesamiento_lenguaje_natural-tp/blob/main/Desafio_3/index.ipynb).

Este notebook ya contiene las celdas necesarias para:

1. Cargar las librer칤as y diccionarios.
2.  Instanciar los tres modelos entrenados.
3.  Ejecutar pruebas de generaci칩n de texto comparando estrategias (Greedy vs Beam Search) y temperaturas en tiempo real.
