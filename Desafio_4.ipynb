{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pfa39F4lsLf3"
      },
      "source": [
        "<img src=\"https://github.com/hernancontigiani/ceia_memorias_especializacion/raw/master/Figures/logoFIUBA.jpg\" width=\"500\" align=\"center\">\n",
        "\n",
        "\n",
        "# Procesamiento de lenguaje natural\n",
        "## LSTM Traductor\n",
        "Ejemplo basado en [LINK](https://stackabuse.com/python-for-nlp-neural-machine-translation-with-seq2seq-in-keras/)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cq3YXak9sGHd",
        "ExecuteTime": {
          "end_time": "2025-12-14T00:21:07.349104Z",
          "start_time": "2025-12-14T00:21:07.322128Z"
        }
      },
      "source": [
        "import re\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import one_hot\n",
        "from tensorflow.keras.utils import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Activation, Dropout, Dense\n",
        "from tensorflow.keras.layers import Flatten, LSTM, SimpleRNN\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Embedding\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.layers import Input\n",
        "from keras.utils import plot_model"
      ],
      "outputs": [],
      "execution_count": 3
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RHNkUaPp6aYq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fcaa3b8a-8e0a-4cc8-85e9-be617fd39d62",
        "ExecuteTime": {
          "end_time": "2025-12-14T00:21:09.435946Z",
          "start_time": "2025-12-14T00:21:09.431063Z"
        }
      },
      "source": [
        "# Descargar la carpeta de dataset\n",
        "\n",
        "import os\n",
        "if os.access('spa-eng', os.F_OK) is False:\n",
        "    if os.access('spa-eng.zip', os.F_OK) is False:\n",
        "        !curl -L -o 'spa-eng.zip' 'http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip'\n",
        "    !unzip -q spa-eng.zip\n",
        "else:\n",
        "    print(\"El dataset ya se encuentra descargado\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 2576k  100 2576k    0     0  3104k      0 --:--:-- --:--:-- --:--:-- 3100k\n"
          ]
        }
      ],
      "execution_count": 4
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-9aNLZBDtA5J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2dad80b1-205d-4385-8a8a-5a729a46f1d7",
        "ExecuteTime": {
          "end_time": "2025-12-14T00:21:11.124627Z",
          "start_time": "2025-12-14T00:21:11.030350Z"
        }
      },
      "source": [
        "# dataset_file\n",
        "\n",
        "text_file = \"./spa-eng/spa.txt\"\n",
        "with open(text_file) as f:\n",
        "    lines = f.read().split(\"\\n\")[:-1]\n",
        "\n",
        "# Por limitaciones de RAM no se leen todas las filas\n",
        "MAX_NUM_SENTENCES = 50000\n",
        "\n",
        "# Mezclar el dataset, forzar semilla siempre igual\n",
        "np.random.seed([40])\n",
        "np.random.shuffle(lines)\n",
        "\n",
        "input_sentences = []\n",
        "output_sentences = []\n",
        "output_sentences_inputs = []\n",
        "count = 0\n",
        "\n",
        "for line in lines:\n",
        "    count += 1\n",
        "    if count > MAX_NUM_SENTENCES:\n",
        "        break\n",
        "\n",
        "    # el tabulador seÃ±aliza la separaciÃ³n entre las oraciones\n",
        "    # en ambos idiomas\n",
        "    if '\\t' not in line:\n",
        "        continue\n",
        "\n",
        "    # Input sentence --> eng\n",
        "    # output --> spa\n",
        "    input_sentence, output = line.rstrip().split('\\t')\n",
        "\n",
        "    # output sentence (decoder_output) tiene <eos>\n",
        "    output_sentence = output + ' <eos>'\n",
        "    # output sentence input (decoder_input) tiene <sos>\n",
        "    output_sentence_input = '<sos> ' + output\n",
        "\n",
        "    input_sentences.append(input_sentence)\n",
        "    output_sentences.append(output_sentence)\n",
        "    output_sentences_inputs.append(output_sentence_input)\n",
        "\n",
        "print(\"Cantidad de rows disponibles:\", len(lines))\n",
        "print(\"Cantidad de rows utilizadas:\", len(input_sentences))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cantidad de rows disponibles: 118964\n",
            "Cantidad de rows utilizadas: 50000\n"
          ]
        }
      ],
      "execution_count": 92
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8P-ynUNP5xp6"
      },
      "source": [
        "### 2 - Preprocesamiento"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "# Definir el tamaÃ±o mÃ¡ximo del vocabulario\n",
        "MAX_VOCAB_SIZE = 16000\n",
        "# Vamos a necesitar un tokenizador para cada idioma\n",
        "\n",
        "# Tokenizar las palabras con el Tokenizer de Keras\n",
        "# Definir una mÃ¡xima cantidad de palabras a utilizar:\n",
        "# - num_words --> the maximum number of words to keep, based on word frequency.\n",
        "# - Only the most common num_words-1 words will be kept.\n",
        "\n",
        "# tokenizador de inglÃ©s\n",
        "input_tokenizer = Tokenizer(num_words=MAX_VOCAB_SIZE)\n",
        "input_tokenizer.fit_on_texts(input_sentences)\n",
        "input_integer_seq = input_tokenizer.texts_to_sequences(input_sentences)\n",
        "\n",
        "word2idx_inputs = input_tokenizer.word_index\n",
        "print(\"Palabras en el vocabulario:\", len(word2idx_inputs))\n",
        "\n",
        "max_input_len = max(len(sen) for sen in input_integer_seq)\n",
        "print(\"Sentencia de entrada mÃ¡s larga:\", max_input_len)\n",
        "# tokenizador de espaÃ±ol\n",
        "# A los filtros de sÃ­mbolos del Tokenizer agregamos el \"Â¿\",\n",
        "# sacamos los \"<>\" para que no afectar nuestros tokens\n",
        "output_tokenizer = Tokenizer(num_words=MAX_VOCAB_SIZE, filters='!\"#$%&()*+,-./:;=Â¿?@[\\\\]^_`{|}~\\t\\n')\n",
        "output_tokenizer.fit_on_texts([\"<sos>\", \"<eos>\"] + output_sentences)\n",
        "output_integer_seq = output_tokenizer.texts_to_sequences(output_sentences)\n",
        "output_input_integer_seq = output_tokenizer.texts_to_sequences(output_sentences_inputs)\n",
        "\n",
        "word2idx_outputs = output_tokenizer.word_index\n",
        "print(\"Palabras en el vocabulario:\", len(word2idx_outputs))\n",
        "\n",
        "num_words_output = min(len(word2idx_outputs) + 1, MAX_VOCAB_SIZE)\n",
        "# Se suma 1 para incluir el token de palabra desconocida\n",
        "\n",
        "max_out_len = max(len(sen) for sen in output_integer_seq)\n",
        "print(\"Sentencia de salida mÃ¡s larga:\", max_out_len)\n",
        "\n",
        "# Por una cuestion de que no explote la RAM se limitarÃ¡ el tamaÃ±o de las sentencias de entrada\n",
        "# a la mitad:\n",
        "max_input_len = 32\n",
        "max_out_len = 36\n",
        "\n",
        "print(\"Cantidad de rows del dataset:\", len(input_integer_seq))\n",
        "\n",
        "encoder_input_sequences = pad_sequences(input_integer_seq, maxlen=max_input_len)\n",
        "print(\"encoder_input_sequences shape:\", encoder_input_sequences.shape)\n",
        "\n",
        "decoder_input_sequences = pad_sequences(output_input_integer_seq, maxlen=max_out_len, padding='post')\n",
        "print(\"decoder_input_sequences shape:\", decoder_input_sequences.shape)\n",
        "\n",
        "# Lo dejamos como secuencia de enteros\n",
        "decoder_output_sequences = pad_sequences(output_integer_seq, maxlen=max_out_len, padding='post')\n",
        "# Simplemente asignamos esto a decoder_targets\n",
        "decoder_targets = decoder_output_sequences\n",
        "\n",
        "print(\"decoder_targets shape (Sparse):\", decoder_targets.shape)\n",
        "\n",
        "#from tensorflow.keras.utils import to_categorical\n",
        "#decoder_output_sequences = pad_sequences(output_integer_seq, maxlen=max_out_len, padding='post')\n",
        "#decoder_targets = to_categorical(decoder_output_sequences, num_classes=num_words_output)\n",
        "#decoder_targets.shape\n",
        "\n"
      ],
      "metadata": {
        "id": "EK_wY4KUw0EG",
        "outputId": "60818aac-1040-437a-d505-08a45adc919b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "ExecuteTime": {
          "end_time": "2025-12-14T00:21:17.321707Z",
          "start_time": "2025-12-14T00:21:16.706117Z"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Palabras en el vocabulario: 9994\n",
            "Sentencia de entrada mÃ¡s larga: 47\n",
            "Palabras en el vocabulario: 18056\n",
            "Sentencia de salida mÃ¡s larga: 48\n",
            "Cantidad de rows del dataset: 50000\n",
            "encoder_input_sequences shape: (50000, 32)\n",
            "decoder_input_sequences shape: (50000, 36)\n",
            "decoder_targets shape (Sparse): (50000, 36)\n"
          ]
        }
      ],
      "execution_count": 93
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_CJIsLBbj6rg"
      },
      "source": [
        "#### 3 - Preparar los embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jlnzm7oOuC4z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42b9f356-8efb-4e13-9876-5d720719e556",
        "ExecuteTime": {
          "end_time": "2025-12-14T00:21:22.848169Z",
          "start_time": "2025-12-14T00:21:22.844280Z"
        }
      },
      "source": [
        "import os\n",
        "\n",
        "if not os.access('cc.en.300.vec.gz', os.F_OK):\n",
        "    !curl -o cc.en.300.vec.gz https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.en.300.vec.gz\n",
        "if not os.access('cc.en.300.vec', os.F_OK):\n",
        "    !gunzip cc.en.300.vec.gz\n",
        "\n",
        "if not os.access('cc.es.300.vec.gz', os.F_OK):\n",
        "    !curl -o cc.es.300.vec.gz https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.es.300.vec.gz\n",
        "if not os.access('cc.es.300.vec', os.F_OK):\n",
        "    !gunzip cc.es.300.vec.gz\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 1264M  100 1264M    0     0   314M      0  0:00:04  0:00:04 --:--:--  314M\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 1226M  100 1226M    0     0   304M      0  0:00:04  0:00:04 --:--:--  304M\n"
          ]
        }
      ],
      "execution_count": 8
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZgqtV8GpkSc8",
        "ExecuteTime": {
          "end_time": "2025-12-14T00:21:27.526098Z",
          "start_time": "2025-12-14T00:21:27.364300Z"
        }
      },
      "source": [
        "import logging\n",
        "import os\n",
        "from pathlib import Path\n",
        "from io import StringIO\n",
        "import pickle\n",
        "\n",
        "class WordsEmbeddings(object):\n",
        "    logger = logging.getLogger(__name__)\n",
        "\n",
        "    def __init__(self):\n",
        "        # load the embeddings\n",
        "        words_embedding_pkl = Path(self.PKL_PATH)\n",
        "        if not words_embedding_pkl.is_file():\n",
        "            words_embedding_txt = Path(self.WORD_TO_VEC_MODEL_TXT_PATH)\n",
        "            assert words_embedding_txt.is_file(), 'Words embedding not available'\n",
        "            embeddings = self.convert_model_to_pickle()\n",
        "        else:\n",
        "            embeddings = self.load_model_from_pickle()\n",
        "        self.embeddings = embeddings\n",
        "        # build the vocabulary hashmap\n",
        "        index = np.arange(self.embeddings.shape[0])\n",
        "        # Dicctionarios para traducir de embedding a IDX de la palabra\n",
        "        self.word2idx = dict(zip(self.embeddings['word'], index))\n",
        "        self.idx2word = dict(zip(index, self.embeddings['word']))\n",
        "\n",
        "    def get_words_embeddings(self, words):\n",
        "        words_idxs = self.words2idxs(words)\n",
        "        return self.embeddings[words_idxs]['embedding']\n",
        "\n",
        "    def words2idxs(self, words):\n",
        "        return np.array([self.word2idx.get(word, -1) for word in words])\n",
        "\n",
        "    def idxs2words(self, idxs):\n",
        "        return np.array([self.idx2word.get(idx, '-1') for idx in idxs])\n",
        "\n",
        "    def load_model_from_pickle(self):\n",
        "        self.logger.debug(\n",
        "            'loading words embeddings from pickle {}'.format(\n",
        "                self.PKL_PATH\n",
        "            )\n",
        "        )\n",
        "        max_bytes = 2**28 - 1 # 256MB\n",
        "        bytes_in = bytearray(0)\n",
        "        input_size = os.path.getsize(self.PKL_PATH)\n",
        "        with open(self.PKL_PATH, 'rb') as f_in:\n",
        "            for _ in range(0, input_size, max_bytes):\n",
        "                bytes_in += f_in.read(max_bytes)\n",
        "        embeddings = pickle.loads(bytes_in)\n",
        "        self.logger.debug('words embeddings loaded')\n",
        "        return embeddings\n",
        "\n",
        "    def convert_model_to_pickle(self):\n",
        "        # create a numpy strctured array:\n",
        "        # word     embedding\n",
        "        # U50      np.float32[]\n",
        "        # word_1   a, b, c\n",
        "        # word_2   d, e, f\n",
        "        # ...\n",
        "        # word_n   g, h, i\n",
        "        self.logger.debug(\n",
        "            'converting and loading words embeddings from text file {}'.format(\n",
        "                self.WORD_TO_VEC_MODEL_TXT_PATH\n",
        "            )\n",
        "        )\n",
        "        structure = [('word', np.dtype('U' + str(self.WORD_MAX_SIZE))),\n",
        "                     ('embedding', np.float32, (self.N_FEATURES,))]\n",
        "        structure = np.dtype(structure)\n",
        "        # load numpy array from disk using a generator\n",
        "        with open(self.WORD_TO_VEC_MODEL_TXT_PATH, encoding=\"utf8\") as words_embeddings_txt:\n",
        "            embeddings_gen = (\n",
        "                (line.split()[0], line.split()[1:]) for line in words_embeddings_txt\n",
        "                if len(line.split()[1:]) == self.N_FEATURES\n",
        "            )\n",
        "            embeddings = np.fromiter(embeddings_gen, structure)\n",
        "        # add a null embedding\n",
        "        null_embedding = np.array(\n",
        "            [('null_embedding', np.zeros((self.N_FEATURES,), dtype=np.float32))],\n",
        "            dtype=structure\n",
        "        )\n",
        "        embeddings = np.concatenate([embeddings, null_embedding])\n",
        "        # dump numpy array to disk using pickle\n",
        "        max_bytes = 2**28 - 1 # # 256MB\n",
        "        bytes_out = pickle.dumps(embeddings, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "        with open(self.PKL_PATH, 'wb') as f_out:\n",
        "            for idx in range(0, len(bytes_out), max_bytes):\n",
        "                f_out.write(bytes_out[idx:idx+max_bytes])\n",
        "        self.logger.debug('words embeddings loaded')\n",
        "        return embeddings\n",
        "\n",
        "\n",
        "class GloveEmbeddings(WordsEmbeddings):\n",
        "    WORD_TO_VEC_MODEL_TXT_PATH = 'glove.twitter.27B.50d.txt'\n",
        "    PKL_PATH = 'gloveembedding.pkl'\n",
        "    N_FEATURES = 50\n",
        "    WORD_MAX_SIZE = 60\n",
        "\n",
        "class FasttextEmbeddingsEN(WordsEmbeddings):\n",
        "    WORD_TO_VEC_MODEL_TXT_PATH = 'cc.en.300.vec'\n",
        "    PKL_PATH = 'fasttext_en.pkl'\n",
        "    N_FEATURES = 300\n",
        "    WORD_MAX_SIZE = 60\n",
        "\n",
        "class FasttextEmbeddingsES(WordsEmbeddings):\n",
        "    WORD_TO_VEC_MODEL_TXT_PATH = 'cc.es.300.vec'\n",
        "    PKL_PATH = 'fasttext_es.pkl'\n",
        "    N_FEATURES = 300\n",
        "    WORD_MAX_SIZE = 60\n",
        "\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": 9
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mosj2-x-kXBK",
        "ExecuteTime": {
          "end_time": "2025-12-14T00:21:49.444320Z",
          "start_time": "2025-12-14T00:21:35.295413Z"
        }
      },
      "source": [
        "model_embeddings_en = FasttextEmbeddingsEN()\n",
        "model_embeddings_es = FasttextEmbeddingsES()\n"
      ],
      "outputs": [],
      "execution_count": 10
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b9FS8ca1ke_B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "40b16a84-e040-433c-9cf4-15d749053efa",
        "ExecuteTime": {
          "end_time": "2025-12-14T00:24:27.371432Z",
          "start_time": "2025-12-14T00:24:27.326959Z"
        }
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "def create_embedding_matrix(word_index, embedding_model, max_vocab_size):\n",
        "    \"\"\"\n",
        "    Crea una matriz de embeddings a partir de un diccionario de palabras y un modelo de embeddings.\n",
        "\n",
        "    Args:\n",
        "        word_index (dict): Diccionario {palabra: indice} del tokenizador.\n",
        "        embedding_model (object): Instancia del modelo de embeddings (ej. FasttextEmbeddingsEN).\n",
        "        max_vocab_size (int): TamaÃ±o mÃ¡ximo del vocabulario permitido.\n",
        "\n",
        "    Returns:\n",
        "        np.array: Matriz de embeddings de dimensiones (nb_words, embed_dim).\n",
        "    \"\"\"\n",
        "    print('Preparing embedding matrix...')\n",
        "\n",
        "    # Obtener dimensiÃ³n de los vectores del modelo\n",
        "    embed_dim = embedding_model.N_FEATURES\n",
        "\n",
        "    # Definir el tamaÃ±o del vocabulario (cota superior)\n",
        "    # Nota: Se usa len(word_index) + 1 para asegurar cobertura si los Ã­ndices empiezan en 1\n",
        "    nb_words = min(max_vocab_size, len(word_index) + 1)\n",
        "\n",
        "    # Inicializar matriz con ceros\n",
        "    embedding_matrix = np.zeros((nb_words, embed_dim))\n",
        "\n",
        "    words_not_found = []\n",
        "\n",
        "    for word, i in word_index.items():\n",
        "        # Si el Ã­ndice supera el tamaÃ±o mÃ¡ximo definido, lo ignoramos\n",
        "        if i >= nb_words:\n",
        "            continue\n",
        "\n",
        "        # Obtener el vector del modelo\n",
        "        # Nota: Asumimos que get_words_embeddings devuelve una lista/array, tomamos el [0]\n",
        "        embedding_vector = embedding_model.get_words_embeddings([word])[0]\n",
        "\n",
        "        if (embedding_vector is not None) and len(embedding_vector) > 0:\n",
        "            embedding_matrix[i] = embedding_vector\n",
        "        else:\n",
        "            words_not_found.append(word)\n",
        "\n",
        "    # Reporte de palabras nulas (vectores de ceros)\n",
        "    null_count = np.sum(np.sum(embedding_matrix**2, axis=1) == 0)\n",
        "    print(f'Number of null word embeddings: {null_count}')\n",
        "    print(embedding_matrix.shape)\n",
        "    return embedding_matrix\n",
        "\n",
        "print(\"Crear matriz para InglÃ©s (Encoder)\")\n",
        "embedding_matrix_en = create_embedding_matrix(\n",
        "    word_index=word2idx_inputs,\n",
        "    embedding_model=model_embeddings_en,\n",
        "    max_vocab_size=MAX_VOCAB_SIZE\n",
        ")\n",
        "\n",
        "print(\"Crear matriz para EspaÃ±ol (Decoder)\")\n",
        "embedding_matrix_es = create_embedding_matrix(\n",
        "    word_index=word2idx_outputs,\n",
        "    embedding_model=model_embeddings_es,\n",
        "    max_vocab_size=MAX_VOCAB_SIZE\n",
        ")\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Crear matriz para InglÃ©s (Encoder)\n",
            "Preparing embedding matrix...\n",
            "Number of null word embeddings: 291\n",
            "(9995, 300)\n",
            "Crear matriz para EspaÃ±ol (Decoder)\n",
            "Preparing embedding matrix...\n",
            "Number of null word embeddings: 354\n",
            "(16000, 300)\n"
          ]
        }
      ],
      "execution_count": 94
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "U0dicIr7zZ9r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3vKbhjtIwPgM"
      },
      "source": [
        "### 4 - Entrenar el modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t_urD1qO2kOx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 512
        },
        "outputId": "7dd09bf9-f3eb-4be8-e14d-355faa8542a7",
        "ExecuteTime": {
          "end_time": "2025-12-14T00:24:56.290772Z",
          "start_time": "2025-12-14T00:24:55.354425Z"
        }
      },
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, LSTM, Dense, Embedding\n",
        "import tensorflow as tf\n",
        "\n",
        "# Asumo que estas variables ya las tenÃ©s definidas arriba:\n",
        "# n_units, max_input_len, nb_words, embed_dim, embedding_matrix,\n",
        "# num_words_output, max_out_len\n",
        "\n",
        "n_units = 512\n",
        "DROPOUT=0.3\n",
        "\n",
        "# --- ENCODER ---\n",
        "encoder_inputs = Input(shape=(max_input_len,), name='Encoder_Input')\n",
        "\n",
        "encoder_embedding_layer = Embedding(\n",
        "    input_dim=embedding_matrix_en.shape[0],    # TamaÃ±o del vocabulario de entrada\n",
        "    output_dim=model_embeddings_en.N_FEATURES, # DimensiÃ³n del vector denso\n",
        "    weights=[embedding_matrix_en],             # Cargar pesos pre-entrenados\n",
        "    trainable=False,                           # Congelar para no re-entrenar\n",
        "    name='Encoder_Embedding'\n",
        ")\n",
        "\n",
        "encoder_inputs_x = encoder_embedding_layer(encoder_inputs)\n",
        "\n",
        "# LSTM Encoder\n",
        "encoder = LSTM(n_units, return_state=True, dropout=DROPOUT, name='Encoder_LSTM')\n",
        "encoder_outputs, state_h, state_c = encoder(encoder_inputs_x)\n",
        "\n",
        "# Guardamos los estados para pasarlos al decoder (Context Vector)\n",
        "encoder_states = [state_h, state_c]\n",
        "\n",
        "# --- DECODER ---\n",
        "decoder_inputs = Input(shape=(max_out_len,), name='Decoder_Input')\n",
        "\n",
        "decoder_embedding_layer = Embedding(\n",
        "    input_dim=embedding_matrix_es.shape[0],      # TamaÃ±o del vocabulario de salida\n",
        "    output_dim=model_embeddings_es.N_FEATURES,   # DimensiÃ³n 300 (FastText)\n",
        "    weights=[embedding_matrix_es],               # Cargar pesos pre-entrenados (EspaÃ±ol)\n",
        "    trainable=False,                             # Congelar para no re-entrenar\n",
        "    name='Decoder_Embedding'\n",
        ")\n",
        "\n",
        "decoder_inputs_x = decoder_embedding_layer(decoder_inputs)\n",
        "\n",
        "# LSTM Decoder\n",
        "# return_sequences=True es vital aquÃ­ porque queremos la predicciÃ³n palabra por palabra\n",
        "decoder_lstm = LSTM(n_units, return_sequences=True, return_state=True, dropout=DROPOUT, name='Decoder_LSTM')\n",
        "\n",
        "# Inicializamos el decoder con los estados del encoder\n",
        "decoder_outputs, _, _ = decoder_lstm(decoder_inputs_x, initial_state=encoder_states)\n",
        "\n",
        "# --- SALIDA ---\n",
        "decoder_dense = Dense(num_words_output, activation='softmax', name='Output_Layer')\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "# --- MODELO ---\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs, name='Seq2Seq_Translator')\n",
        "\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer=\"Adam\", metrics=['accuracy'])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "encoder_model = Model(encoder_inputs, encoder_states)\n",
        "\n",
        "# define inference decoder\n",
        "decoder_state_input_h = Input(shape=(n_units,))\n",
        "decoder_state_input_c = Input(shape=(n_units,))\n",
        "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
        "\n",
        "# En cada predicciÃ³n habrÃ¡ una sola palabra de entrada al decoder,\n",
        "# que es la realimentaciÃ³n de la palabra anterior\n",
        "# por lo que hay que modificar el input shape de la layer de Embedding\n",
        "decoder_inputs_single = Input(shape=(1,))\n",
        "decoder_inputs_single_x = decoder_embedding_layer(decoder_inputs_single)\n",
        "\n",
        "decoder_outputs, state_h, state_c = decoder_lstm(\n",
        "    decoder_inputs_single_x,\n",
        "    initial_state=decoder_states_inputs\n",
        ")\n",
        "\n",
        "decoder_states = [state_h, state_c]\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "decoder_model = Model(\n",
        "    [decoder_inputs_single] + decoder_states_inputs,\n",
        "    [decoder_outputs] + decoder_states\n",
        ")\n",
        "\n"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"Seq2Seq_Translator\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"Seq2Seq_Translator\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ Encoder_Input       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ -                 â”‚\n",
              "â”‚ (\u001b[38;5;33mInputLayer\u001b[0m)        â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ Decoder_Input       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m36\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ -                 â”‚\n",
              "â”‚ (\u001b[38;5;33mInputLayer\u001b[0m)        â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ Encoder_Embedding   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m300\u001b[0m)   â”‚  \u001b[38;5;34m2,998,500\u001b[0m â”‚ Encoder_Input[\u001b[38;5;34m0\u001b[0m]â€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mEmbedding\u001b[0m)         â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ Decoder_Embedding   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m36\u001b[0m, \u001b[38;5;34m300\u001b[0m)   â”‚  \u001b[38;5;34m4,800,000\u001b[0m â”‚ Decoder_Input[\u001b[38;5;34m0\u001b[0m]â€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mEmbedding\u001b[0m)         â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ Encoder_LSTM (\u001b[38;5;33mLSTM\u001b[0m) â”‚ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m),     â”‚  \u001b[38;5;34m1,665,024\u001b[0m â”‚ Encoder_Embeddinâ€¦ â”‚\n",
              "â”‚                     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m),      â”‚            â”‚                   â”‚\n",
              "â”‚                     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)]      â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ Decoder_LSTM (\u001b[38;5;33mLSTM\u001b[0m) â”‚ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m36\u001b[0m, \u001b[38;5;34m512\u001b[0m), â”‚  \u001b[38;5;34m1,665,024\u001b[0m â”‚ Decoder_Embeddinâ€¦ â”‚\n",
              "â”‚                     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m),      â”‚            â”‚ Encoder_LSTM[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34mâ€¦\u001b[0m â”‚\n",
              "â”‚                     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)]      â”‚            â”‚ Encoder_LSTM[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34mâ€¦\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ Output_Layer        â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m36\u001b[0m, \u001b[38;5;34m16000\u001b[0m) â”‚  \u001b[38;5;34m8,208,000\u001b[0m â”‚ Decoder_LSTM[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34mâ€¦\u001b[0m â”‚\n",
              "â”‚ (\u001b[38;5;33mDense\u001b[0m)             â”‚                   â”‚            â”‚                   â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ<span style=\"font-weight: bold\"> Layer (type)        </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape      </span>â”ƒ<span style=\"font-weight: bold\">    Param # </span>â”ƒ<span style=\"font-weight: bold\"> Connected to      </span>â”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ Encoder_Input       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ -                 â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ Decoder_Input       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ -                 â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ Encoder_Embedding   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)   â”‚  <span style=\"color: #00af00; text-decoration-color: #00af00\">2,998,500</span> â”‚ Encoder_Input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]â€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ Decoder_Embedding   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)   â”‚  <span style=\"color: #00af00; text-decoration-color: #00af00\">4,800,000</span> â”‚ Decoder_Input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]â€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ Encoder_LSTM (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>) â”‚ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>),     â”‚  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,665,024</span> â”‚ Encoder_Embeddinâ€¦ â”‚\n",
              "â”‚                     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>),      â”‚            â”‚                   â”‚\n",
              "â”‚                     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)]      â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ Decoder_LSTM (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>) â”‚ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>), â”‚  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,665,024</span> â”‚ Decoder_Embeddinâ€¦ â”‚\n",
              "â”‚                     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>),      â”‚            â”‚ Encoder_LSTM[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">â€¦</span> â”‚\n",
              "â”‚                     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)]      â”‚            â”‚ Encoder_LSTM[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">â€¦</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ Output_Layer        â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16000</span>) â”‚  <span style=\"color: #00af00; text-decoration-color: #00af00\">8,208,000</span> â”‚ Decoder_LSTM[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">â€¦</span> â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             â”‚                   â”‚            â”‚                   â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m19,336,548\u001b[0m (73.76 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">19,336,548</span> (73.76 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m11,538,048\u001b[0m (44.01 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">11,538,048</span> (44.01 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m7,798,500\u001b[0m (29.75 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,798,500</span> (29.75 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 95
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-12-14T00:24:40.188655Z",
          "start_time": "2025-12-14T00:24:37.848947Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zNOTeh3bQ0uo",
        "outputId": "b3e2e085-6094-4d0d-9514-3323a56bddf4"
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "import wandb\n",
        "\n",
        "\n",
        "# Intentamos obtener la clave segÃºn el entorno\n",
        "try:\n",
        "    # Intenta importar la librerÃ­a de secretos de Colab\n",
        "    from google.colab import userdata\n",
        "    wandb_api_key = userdata.get('WANDB_KEY')\n",
        "    print(\"ğŸ“ Entorno detectado: Google Colab (Usando Secretos)\")\n",
        "\n",
        "except ImportError:\n",
        "    # Si falla, asumimos entorno local y buscamos variable de entorno\n",
        "    # (Asegurate de tener python-dotenv instalado si usas un archivo .env)\n",
        "    wandb_api_key = os.getenv(\"WANDB_KEY\")\n",
        "    print(\"ğŸ“ Entorno detectado: Local (Usando variables de entorno)\")\n",
        "\n",
        "\n",
        "# LÃ³gica de login unificada\n",
        "if wandb_api_key:\n",
        "    wandb.login(key=wandb_api_key)\n",
        "    print(\"âœ… Login en WANDB exitoso.\")\n",
        "else:\n",
        "    print(\"âš ï¸ No se detectÃ³ clave automÃ¡tica. Iniciando login interactivo...\")\n",
        "    wandb.login()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ“ Entorno detectado: Google Colab (Usando Secretos)\n",
            "âœ… Login en WANDB exitoso.\n"
          ]
        }
      ],
      "execution_count": 16
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "# 1. Montar Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# 2. Definir la ruta donde guardaremos el modelo\n",
        "# Puedes cambiar 'Modelos/Traductor' por la carpeta que prefieras en tu Drive\n",
        "save_dir = '/content/drive/MyDrive/Modelos/Traductor'\n",
        "\n",
        "# Crear la carpeta si no existe\n",
        "if not os.path.exists(save_dir):\n",
        "    os.makedirs(save_dir)\n",
        "\n",
        "# Definir la ruta completa del archivo\n",
        "model_filepath = os.path.join(save_dir, 'best_translator_model.keras')\n",
        "\n",
        "print(f\"ğŸ“ El modelo se guardarÃ¡ en: {model_filepath}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nlss3vg8xstK",
        "outputId": "742c87b8-f8f3-481d-8c0b-26f47b98caa5"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "ğŸ“ El modelo se guardarÃ¡ en: /content/drive/MyDrive/Modelos/Traductor/best_translator_model.keras\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VnlIx1Vezjwc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "2c76f2ed-e0fc-4a7f-fbd0-11f27b269fb1",
        "ExecuteTime": {
          "end_time": "2025-12-14T00:25:29.597547Z",
          "start_time": "2025-12-14T00:25:03.200128Z"
        }
      },
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from wandb.integration.keras import WandbMetricsLogger\n",
        "\n",
        "# Inicializar la run de WANDB\n",
        "run = wandb.init(\n",
        "    project=\"traductor-seq2seq-lstm\", # Ponle el nombre que quieras a tu proyecto\n",
        "    config={\n",
        "        \"epochs\": 30,\n",
        "        \"batch_size\": 32,             # El default de Keras es 32 si no lo especificas\n",
        "        \"n_units\": n_units,           # 128\n",
        "        \"embedding_dim\": 300,         # FastText\n",
        "        \"architecture\": \"LSTM + FastText Frozen + sparse + dropout\"\n",
        "    }\n",
        ")\n",
        "\n",
        "\n",
        "checkpoint = ModelCheckpoint(\n",
        "    filepath=model_filepath,  # Nombre del archivo (usa .keras para Keras 3)\n",
        "    monitor='val_accuracy',       # MÃ©trica a vigilar\n",
        "    save_best_only=True,          # Â¡Clave! Solo guarda si supera el rÃ©cord anterior\n",
        "    mode='max',                   # Queremos que la accuracy suba\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# ConfiguraciÃ³n del Early Stopping\n",
        "early_stopping = EarlyStopping(\n",
        "    monitor='val_accuracy',      # Miramos la accuracy de validaciÃ³n\n",
        "    patience=5,                  # Esperamos 5 Ã©pocas sin mejora antes de cortar\n",
        "    mode='max',                  # Queremos que la mÃ©trica suba\n",
        "    restore_best_weights=True,   # CRÃTICO: Al final, volver a los pesos de la mejor Ã©poca\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# 3. Entrenamiento\n",
        "hist = model.fit(\n",
        "    [encoder_input_sequences, decoder_input_sequences],\n",
        "    decoder_targets,\n",
        "    epochs=50,             # Ponemos de mÃ¡s, total EarlyStopping corta\n",
        "    batch_size=32,\n",
        "    validation_split=0.2,\n",
        "    callbacks=[\n",
        "        WandbMetricsLogger(log_freq=\"batch\"), # Sube logs a la nube\n",
        "        early_stopping,                       # Frena si se estanca\n",
        "        checkpoint                            # Guarda el mejor en disco\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Cerrar la run al terminar (opcional pero recomendado en notebooks)\n",
        "wandb.finish()"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Finishing previous runs because reinit is set to 'default'."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>batch/accuracy</td><td>â–ƒâ–‚â–‚â–‚â–‚â–â–â–â–â–â–â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–„â–„â–„â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ˆâ–†â–…â–„â–„â–„â–„</td></tr><tr><td>batch/batch_step</td><td>â–â–â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–‡â–‡â–‡â–ˆâ–ˆ</td></tr><tr><td>batch/learning_rate</td><td>â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>batch/loss</td><td>â–„â–†â–…â–…â–†â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–ƒâ–„â–…â–…â–â–â–â–â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒ</td></tr><tr><td>epoch/accuracy</td><td>â–â–…â–ˆ</td></tr><tr><td>epoch/epoch</td><td>â–â–…â–ˆ</td></tr><tr><td>epoch/learning_rate</td><td>â–â–â–</td></tr><tr><td>epoch/loss</td><td>â–ˆâ–„â–</td></tr><tr><td>epoch/val_accuracy</td><td>â–â–ˆâ–ƒ</td></tr><tr><td>epoch/val_loss</td><td>â–â–‡â–ˆ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>batch/accuracy</td><td>0.94513</td></tr><tr><td>batch/batch_step</td><td>1999</td></tr><tr><td>batch/learning_rate</td><td>0.001</td></tr><tr><td>batch/loss</td><td>0.21951</td></tr><tr><td>epoch/accuracy</td><td>0.94378</td></tr><tr><td>epoch/epoch</td><td>2</td></tr><tr><td>epoch/learning_rate</td><td>0.001</td></tr><tr><td>epoch/loss</td><td>0.22538</td></tr><tr><td>epoch/val_accuracy</td><td>0.87877</td></tr><tr><td>epoch/val_loss</td><td>0.97576</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">silvery-armadillo-17</strong> at: <a href='https://wandb.ai/diazjoseluis-auth0/traductor-seq2seq-lstm/runs/68kqooxs' target=\"_blank\">https://wandb.ai/diazjoseluis-auth0/traductor-seq2seq-lstm/runs/68kqooxs</a><br> View project at: <a href='https://wandb.ai/diazjoseluis-auth0/traductor-seq2seq-lstm' target=\"_blank\">https://wandb.ai/diazjoseluis-auth0/traductor-seq2seq-lstm</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20251214_025413-68kqooxs/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.23.1"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20251214_025621-s69eajzw</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/diazjoseluis-auth0/traductor-seq2seq-lstm/runs/s69eajzw' target=\"_blank\">divine-firefly-18</a></strong> to <a href='https://wandb.ai/diazjoseluis-auth0/traductor-seq2seq-lstm' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/diazjoseluis-auth0/traductor-seq2seq-lstm' target=\"_blank\">https://wandb.ai/diazjoseluis-auth0/traductor-seq2seq-lstm</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/diazjoseluis-auth0/traductor-seq2seq-lstm/runs/s69eajzw' target=\"_blank\">https://wandb.ai/diazjoseluis-auth0/traductor-seq2seq-lstm/runs/s69eajzw</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m1249/1250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.8189 - loss: 1.5557\n",
            "Epoch 1: val_accuracy improved from -inf to 0.85932, saving model to /content/drive/MyDrive/Modelos/Traductor/best_translator_model.keras\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 37ms/step - accuracy: 0.8190 - loss: 1.5551 - val_accuracy: 0.8593 - val_loss: 0.9046\n",
            "Epoch 2/50\n",
            "\u001b[1m1249/1250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.8607 - loss: 0.8853\n",
            "Epoch 2: val_accuracy improved from 0.85932 to 0.87216, saving model to /content/drive/MyDrive/Modelos/Traductor/best_translator_model.keras\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 37ms/step - accuracy: 0.8607 - loss: 0.8852 - val_accuracy: 0.8722 - val_loss: 0.7624\n",
            "Epoch 3/50\n",
            "\u001b[1m1249/1250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.8733 - loss: 0.7334\n",
            "Epoch 3: val_accuracy improved from 0.87216 to 0.88139, saving model to /content/drive/MyDrive/Modelos/Traductor/best_translator_model.keras\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 37ms/step - accuracy: 0.8733 - loss: 0.7333 - val_accuracy: 0.8814 - val_loss: 0.6773\n",
            "Epoch 4/50\n",
            "\u001b[1m1249/1250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.8833 - loss: 0.6173\n",
            "Epoch 4: val_accuracy improved from 0.88139 to 0.88799, saving model to /content/drive/MyDrive/Modelos/Traductor/best_translator_model.keras\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 37ms/step - accuracy: 0.8833 - loss: 0.6173 - val_accuracy: 0.8880 - val_loss: 0.6232\n",
            "Epoch 5/50\n",
            "\u001b[1m1249/1250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.8913 - loss: 0.5303\n",
            "Epoch 5: val_accuracy improved from 0.88799 to 0.89304, saving model to /content/drive/MyDrive/Modelos/Traductor/best_translator_model.keras\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 37ms/step - accuracy: 0.8913 - loss: 0.5303 - val_accuracy: 0.8930 - val_loss: 0.5877\n",
            "Epoch 6/50\n",
            "\u001b[1m1249/1250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9002 - loss: 0.4537\n",
            "Epoch 6: val_accuracy improved from 0.89304 to 0.89691, saving model to /content/drive/MyDrive/Modelos/Traductor/best_translator_model.keras\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 37ms/step - accuracy: 0.9002 - loss: 0.4537 - val_accuracy: 0.8969 - val_loss: 0.5657\n",
            "Epoch 7/50\n",
            "\u001b[1m1249/1250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9093 - loss: 0.3948\n",
            "Epoch 7: val_accuracy improved from 0.89691 to 0.89978, saving model to /content/drive/MyDrive/Modelos/Traductor/best_translator_model.keras\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 37ms/step - accuracy: 0.9093 - loss: 0.3948 - val_accuracy: 0.8998 - val_loss: 0.5539\n",
            "Epoch 8/50\n",
            "\u001b[1m 633/1250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m18s\u001b[0m 30ms/step - accuracy: 0.9201 - loss: 0.3375"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OVz1uug_zu2J",
        "ExecuteTime": {
          "end_time": "2025-12-14T00:15:08.064610Z",
          "start_time": "2025-12-14T00:15:07.938281Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "outputId": "23e37bbb-1c38-4c44-b0d9-a004a2f768db"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Entrenamiento\n",
        "epoch_count = range(1, len(hist.history['accuracy']) + 1)\n",
        "sns.lineplot(x=epoch_count,  y=hist.history['accuracy'], label='train')\n",
        "sns.lineplot(x=epoch_count,  y=hist.history['val_accuracy'], label='valid')\n",
        "plt.show()"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "execution_count": 83
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zbwn0ekDy_s2"
      },
      "source": [
        "### 5 - Inferencia"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "jnkl3mSpsU_7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "outputId": "286b6e10-b1d0-4967-caf0-e68d2e422e3c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nStep 1:\\nA deal is a deal -> Encoder -> enc(h1,c1)\\n\\nenc(h1,c1) + <sos> -> Decoder -> Un + dec(h1,c1)\\n\\nstep 2:\\ndec(h1,c1) + Un -> Decoder -> trato + dec(h2,c2)\\n\\nstep 3:\\ndec(h2,c2) + trato -> Decoder -> es + dec(h3,c3)\\n\\nstep 4:\\ndec(h3,c3) + es -> Decoder -> un + dec(h4,c4)\\n\\nstep 5:\\ndec(h4,c4) + un -> Decoder -> trato + dec(h5,c5)\\n\\nstep 6:\\ndec(h5,c5) + trato. -> Decoder -> <eos> + dec(h6,c6)\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "'''\n",
        "Step 1:\n",
        "A deal is a deal -> Encoder -> enc(h1,c1)\n",
        "\n",
        "enc(h1,c1) + <sos> -> Decoder -> Un + dec(h1,c1)\n",
        "\n",
        "step 2:\n",
        "dec(h1,c1) + Un -> Decoder -> trato + dec(h2,c2)\n",
        "\n",
        "step 3:\n",
        "dec(h2,c2) + trato -> Decoder -> es + dec(h3,c3)\n",
        "\n",
        "step 4:\n",
        "dec(h3,c3) + es -> Decoder -> un + dec(h4,c4)\n",
        "\n",
        "step 5:\n",
        "dec(h4,c4) + un -> Decoder -> trato + dec(h5,c5)\n",
        "\n",
        "step 6:\n",
        "dec(h5,c5) + trato. -> Decoder -> <eos> + dec(h6,c6)\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "id": "71XeCtfYmOFx"
      },
      "outputs": [],
      "source": [
        "# Armar los conversores de Ã­ndice a palabra:\n",
        "idx2word_input = {v:k for k, v in word2idx_inputs.items()}\n",
        "idx2word_target = {v:k for k, v in word2idx_outputs.items()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "id": "MlUyp9M6ua2V"
      },
      "outputs": [],
      "source": [
        "def translate_sentence(input_seq):\n",
        "    # Se transforma la sequencia de entrada a los estados \"h\" y \"c\" de la LSTM\n",
        "    # para enviar la primera vez al decoder\n",
        "    states_value = encoder_model.predict(input_seq)\n",
        "\n",
        "    # Se inicializa la secuencia de entrada al decoder como \"<sos>\"\n",
        "    target_seq = np.zeros((1, 1))\n",
        "    target_seq[0, 0] = word2idx_outputs['<sos>']\n",
        "\n",
        "    # Se obtiene el Ã­ndice que finaliza la inferencia\n",
        "    eos = word2idx_outputs['<eos>']\n",
        "\n",
        "    output_sentence = []\n",
        "    for _ in range(max_out_len):\n",
        "        # PredicciÃ³n del prÃ³ximo elemento\n",
        "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
        "        idx = np.argmax(output_tokens[0, 0, :])\n",
        "\n",
        "        # Si es \"end of sentece <eos>\" se acaba\n",
        "        if eos == idx:\n",
        "            break\n",
        "\n",
        "        # Transformar idx a palabra\n",
        "        word = ''\n",
        "        if idx > 0:\n",
        "            word = idx2word_target[idx]\n",
        "            output_sentence.append(word)\n",
        "\n",
        "        # Actualizar los estados dada la Ãºltima predicciÃ³n\n",
        "        states_value = [h, c]\n",
        "\n",
        "        # Actualizar secuencia de entrada con la salida (re-alimentaciÃ³n)\n",
        "        target_seq[0, 0] = idx\n",
        "\n",
        "    return ' '.join(output_sentence)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "id": "ZhGVjLKcunxW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4eeb7dbe-ea1b-4df9-bcde-ef0881687947"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "-\n",
            "Input: I can't hear you.\n",
            "Response: no puedo oÃ­rte\n"
          ]
        }
      ],
      "source": [
        "i = np.random.choice(len(input_sentences))\n",
        "input_seq = encoder_input_sequences[i:i+1]\n",
        "translation = translate_sentence(input_seq)\n",
        "print('-')\n",
        "print('Input:', input_sentences[i])\n",
        "print('Response:', translation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "id": "KYZ1Q_Z_2G4m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa573280-0551-4caf-d960-da6e314a1010"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: She was sick\n",
            "Representacion en vector de tokens de ids: [20, 11, 444]\n",
            "Padding del vector: [[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0   0  20  11 444]]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "Response: ella estaba enferma\n"
          ]
        }
      ],
      "source": [
        "input_test = \"She was sick\"\n",
        "print('Input:', input_test)\n",
        "\n",
        "# Convertir a secuencia\n",
        "integer_seq_test = input_tokenizer.texts_to_sequences([input_test])[0]\n",
        "print(\"Representacion en vector de tokens de ids:\", integer_seq_test)\n",
        "\n",
        "if len(integer_seq_test) == 0:\n",
        "    print(\"âš ï¸ ERROR: La palabra no estÃ¡ en el vocabulario del tokenizador (input_tokenizer).\")\n",
        "else:\n",
        "    # Padding\n",
        "    encoder_sequence_test = pad_sequences([integer_seq_test], maxlen=max_input_len)\n",
        "    print(\"Padding del vector:\", encoder_sequence_test)\n",
        "\n",
        "    # Inferencia\n",
        "    # AsegÃºrate de haber corrido la celda de 'translate_sentence'\n",
        "    # y la celda de definiciÃ³n de encoder_model/decoder_model de arriba.\n",
        "    translation = translate_sentence(encoder_sequence_test)\n",
        "    print('Response:', translation)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pkOjSJweqdF8"
      },
      "source": [
        "### 6 - ConclusiÃ³n\n",
        "A primera vista parece que el modelo tendrÃ­a que funcionar muy bien por el accuracy alcanzado. La realidad es que las respuestas no tienen que ver demasiado con la pregunta/traducciÃ³n pero la respuesta en si tiene bastante coherencia.\\\n",
        "Para poder mejorar el modelo harÃ­a falta poder consumir todo el dataset y todo el vocabulario, pero la cantidad de RAM no es suficiente.\\\n",
        "Este problema se resuelve con:\n",
        "- Utilizando un DataGenerator para no levantar todo el dataset junto en el entrenamiento.\n",
        "- Transfer learning evitando tener que entrenar todo el modelo  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZSy0kaSKuC4-"
      },
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "vscode": {
      "interpreter": {
        "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}