{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pfa39F4lsLf3"
   },
   "source": [
    "<img src=\"https://github.com/hernancontigiani/ceia_memorias_especializacion/raw/master/Figures/logoFIUBA.jpg\" width=\"500\" align=\"center\">\n",
    "\n",
    "\n",
    "# Procesamiento de lenguaje natural\n",
    "## LSTM Traductor\n",
    "Ejemplo basado en [LINK](https://stackabuse.com/python-for-nlp-neural-machine-translation-with-seq2seq-in-keras/)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "cq3YXak9sGHd",
    "ExecuteTime": {
     "end_time": "2025-12-14T00:21:07.349104Z",
     "start_time": "2025-12-14T00:21:07.322128Z"
    }
   },
   "source": [
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import one_hot\n",
    "from tensorflow.keras.utils import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Activation, Dropout, Dense\n",
    "from tensorflow.keras.layers import Flatten, LSTM, SimpleRNN\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.layers import Input\n",
    "from keras.utils import plot_model"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "RHNkUaPp6aYq",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "d75f6c71-12a3-4314-e8f3-ff74c0440259",
    "ExecuteTime": {
     "end_time": "2025-12-14T00:21:09.435946Z",
     "start_time": "2025-12-14T00:21:09.431063Z"
    }
   },
   "source": [
    "# Descargar la carpeta de dataset\n",
    "\n",
    "import os\n",
    "if os.access('spa-eng', os.F_OK) is False:\n",
    "    if os.access('spa-eng.zip', os.F_OK) is False:\n",
    "        !curl -L -o 'spa-eng.zip' 'http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip'\n",
    "    !unzip -q spa-eng.zip\n",
    "else:\n",
    "    print(\"El dataset ya se encuentra descargado\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El dataset ya se encuentra descargado\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "-9aNLZBDtA5J",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "e32597c0-65fc-4829-9594-2966ce514099",
    "ExecuteTime": {
     "end_time": "2025-12-14T00:21:11.124627Z",
     "start_time": "2025-12-14T00:21:11.030350Z"
    }
   },
   "source": [
    "# dataset_file\n",
    "\n",
    "text_file = \"./spa-eng/spa.txt\"\n",
    "with open(text_file) as f:\n",
    "    lines = f.read().split(\"\\n\")[:-1]\n",
    "\n",
    "# Por limitaciones de RAM no se leen todas las filas\n",
    "MAX_NUM_SENTENCES = 6000\n",
    "\n",
    "# Mezclar el dataset, forzar semilla siempre igual\n",
    "np.random.seed([40])\n",
    "np.random.shuffle(lines)\n",
    "\n",
    "input_sentences = []\n",
    "output_sentences = []\n",
    "output_sentences_inputs = []\n",
    "count = 0\n",
    "\n",
    "for line in lines:\n",
    "    count += 1\n",
    "    if count > MAX_NUM_SENTENCES:\n",
    "        break\n",
    "\n",
    "    # el tabulador señaliza la separación entre las oraciones\n",
    "    # en ambos idiomas\n",
    "    if '\\t' not in line:\n",
    "        continue\n",
    "\n",
    "    # Input sentence --> eng\n",
    "    # output --> spa\n",
    "    input_sentence, output = line.rstrip().split('\\t')\n",
    "\n",
    "    # output sentence (decoder_output) tiene <eos>\n",
    "    output_sentence = output + ' <eos>'\n",
    "    # output sentence input (decoder_input) tiene <sos>\n",
    "    output_sentence_input = '<sos> ' + output\n",
    "\n",
    "    input_sentences.append(input_sentence)\n",
    "    output_sentences.append(output_sentence)\n",
    "    output_sentences_inputs.append(output_sentence_input)\n",
    "\n",
    "print(\"Cantidad de rows disponibles:\", len(lines))\n",
    "print(\"Cantidad de rows utilizadas:\", len(input_sentences))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de rows disponibles: 118964\n",
      "Cantidad de rows utilizadas: 6000\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8P-ynUNP5xp6"
   },
   "source": [
    "### 2 - Preprocesamiento"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "# Definir el tamaño máximo del vocabulario\n",
    "MAX_VOCAB_SIZE = 8000\n",
    "# Vamos a necesitar un tokenizador para cada idioma\n",
    "\n",
    "# Tokenizar las palabras con el Tokenizer de Keras\n",
    "# Definir una máxima cantidad de palabras a utilizar:\n",
    "# - num_words --> the maximum number of words to keep, based on word frequency.\n",
    "# - Only the most common num_words-1 words will be kept.\n",
    "\n",
    "# tokenizador de inglés\n",
    "input_tokenizer = Tokenizer(num_words=MAX_VOCAB_SIZE)\n",
    "input_tokenizer.fit_on_texts(input_sentences)\n",
    "input_integer_seq = input_tokenizer.texts_to_sequences(input_sentences)\n",
    "\n",
    "word2idx_inputs = input_tokenizer.word_index\n",
    "print(\"Palabras en el vocabulario:\", len(word2idx_inputs))\n",
    "\n",
    "max_input_len = max(len(sen) for sen in input_integer_seq)\n",
    "print(\"Sentencia de entrada más larga:\", max_input_len)\n",
    "# tokenizador de español\n",
    "# A los filtros de símbolos del Tokenizer agregamos el \"¿\",\n",
    "# sacamos los \"<>\" para que no afectar nuestros tokens\n",
    "output_tokenizer = Tokenizer(num_words=MAX_VOCAB_SIZE, filters='!\"#$%&()*+,-./:;=¿?@[\\\\]^_`{|}~\\t\\n')\n",
    "output_tokenizer.fit_on_texts([\"<sos>\", \"<eos>\"] + output_sentences)\n",
    "output_integer_seq = output_tokenizer.texts_to_sequences(output_sentences)\n",
    "output_input_integer_seq = output_tokenizer.texts_to_sequences(output_sentences_inputs)\n",
    "\n",
    "word2idx_outputs = output_tokenizer.word_index\n",
    "print(\"Palabras en el vocabulario:\", len(word2idx_outputs))\n",
    "\n",
    "num_words_output = min(len(word2idx_outputs) + 1, MAX_VOCAB_SIZE)\n",
    "# Se suma 1 para incluir el token de palabra desconocida\n",
    "\n",
    "max_out_len = max(len(sen) for sen in output_integer_seq)\n",
    "print(\"Sentencia de salida más larga:\", max_out_len)\n",
    "\n",
    "# Por una cuestion de que no explote la RAM se limitará el tamaño de las sentencias de entrada\n",
    "# a la mitad:\n",
    "max_input_len = 32\n",
    "max_out_len = 36\n",
    "\n",
    "print(\"Cantidad de rows del dataset:\", len(input_integer_seq))\n",
    "\n",
    "encoder_input_sequences = pad_sequences(input_integer_seq, maxlen=max_input_len)\n",
    "print(\"encoder_input_sequences shape:\", encoder_input_sequences.shape)\n",
    "\n",
    "decoder_input_sequences = pad_sequences(output_input_integer_seq, maxlen=max_out_len, padding='post')\n",
    "print(\"decoder_input_sequences shape:\", decoder_input_sequences.shape)\n",
    "\n",
    "#La última capa del modelo (softmax) necesita que los valores de salida del decoder (decoder_sequences) estén en formato oneHotEncoder.\n",
    "# Se utiliza \"decoder_output_sequences\" con la misma estrategia con que se transformó la entrada del decoder.\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "decoder_output_sequences = pad_sequences(output_integer_seq, maxlen=max_out_len, padding='post')\n",
    "decoder_targets = to_categorical(decoder_output_sequences, num_classes=num_words_output)\n",
    "decoder_targets.shape"
   ],
   "metadata": {
    "id": "EK_wY4KUw0EG",
    "outputId": "b10b5490-c491-4c87-dfd8-99d2a233923f",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 216
    },
    "ExecuteTime": {
     "end_time": "2025-12-14T00:21:17.321707Z",
     "start_time": "2025-12-14T00:21:16.706117Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Palabras en el vocabulario: 3851\n",
      "Sentencia de entrada más larga: 32\n",
      "Palabras en el vocabulario: 5721\n",
      "Sentencia de salida más larga: 36\n",
      "Cantidad de rows del dataset: 6000\n",
      "encoder_input_sequences shape: (6000, 32)\n",
      "decoder_input_sequences shape: (6000, 36)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(6000, 36, 5722)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_CJIsLBbj6rg"
   },
   "source": "#### 3 - Preparar los embeddings"
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Jlnzm7oOuC4z",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "74d7f7d8-dfe6-4861-f8a2-c4e36d54835a",
    "ExecuteTime": {
     "end_time": "2025-12-14T00:21:22.848169Z",
     "start_time": "2025-12-14T00:21:22.844280Z"
    }
   },
   "source": [
    "import os\n",
    "\n",
    "if not os.access('cc.en.300.vec.gz', os.F_OK):\n",
    "    !curl -o cc.en.300.vec.gz https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.en.300.vec.gz\n",
    "if not os.access('cc.en.300.vec', os.F_OK):\n",
    "    !gunzip cc.en.300.vec.gz\n",
    "\n",
    "if not os.access('cc.es.300.vec.gz', os.F_OK):\n",
    "    !curl -o cc.es.300.vec.gz https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.es.300.vec.gz\n",
    "if not os.access('cc.es.300.vec', os.F_OK):\n",
    "    !gunzip cc.es.300.vec.gz\n"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "ZgqtV8GpkSc8",
    "ExecuteTime": {
     "end_time": "2025-12-14T00:21:27.526098Z",
     "start_time": "2025-12-14T00:21:27.364300Z"
    }
   },
   "source": [
    "import logging\n",
    "import os\n",
    "from pathlib import Path\n",
    "from io import StringIO\n",
    "import pickle\n",
    "\n",
    "class WordsEmbeddings(object):\n",
    "    logger = logging.getLogger(__name__)\n",
    "\n",
    "    def __init__(self):\n",
    "        # load the embeddings\n",
    "        words_embedding_pkl = Path(self.PKL_PATH)\n",
    "        if not words_embedding_pkl.is_file():\n",
    "            words_embedding_txt = Path(self.WORD_TO_VEC_MODEL_TXT_PATH)\n",
    "            assert words_embedding_txt.is_file(), 'Words embedding not available'\n",
    "            embeddings = self.convert_model_to_pickle()\n",
    "        else:\n",
    "            embeddings = self.load_model_from_pickle()\n",
    "        self.embeddings = embeddings\n",
    "        # build the vocabulary hashmap\n",
    "        index = np.arange(self.embeddings.shape[0])\n",
    "        # Dicctionarios para traducir de embedding a IDX de la palabra\n",
    "        self.word2idx = dict(zip(self.embeddings['word'], index))\n",
    "        self.idx2word = dict(zip(index, self.embeddings['word']))\n",
    "\n",
    "    def get_words_embeddings(self, words):\n",
    "        words_idxs = self.words2idxs(words)\n",
    "        return self.embeddings[words_idxs]['embedding']\n",
    "\n",
    "    def words2idxs(self, words):\n",
    "        return np.array([self.word2idx.get(word, -1) for word in words])\n",
    "\n",
    "    def idxs2words(self, idxs):\n",
    "        return np.array([self.idx2word.get(idx, '-1') for idx in idxs])\n",
    "\n",
    "    def load_model_from_pickle(self):\n",
    "        self.logger.debug(\n",
    "            'loading words embeddings from pickle {}'.format(\n",
    "                self.PKL_PATH\n",
    "            )\n",
    "        )\n",
    "        max_bytes = 2**28 - 1 # 256MB\n",
    "        bytes_in = bytearray(0)\n",
    "        input_size = os.path.getsize(self.PKL_PATH)\n",
    "        with open(self.PKL_PATH, 'rb') as f_in:\n",
    "            for _ in range(0, input_size, max_bytes):\n",
    "                bytes_in += f_in.read(max_bytes)\n",
    "        embeddings = pickle.loads(bytes_in)\n",
    "        self.logger.debug('words embeddings loaded')\n",
    "        return embeddings\n",
    "\n",
    "    def convert_model_to_pickle(self):\n",
    "        # create a numpy strctured array:\n",
    "        # word     embedding\n",
    "        # U50      np.float32[]\n",
    "        # word_1   a, b, c\n",
    "        # word_2   d, e, f\n",
    "        # ...\n",
    "        # word_n   g, h, i\n",
    "        self.logger.debug(\n",
    "            'converting and loading words embeddings from text file {}'.format(\n",
    "                self.WORD_TO_VEC_MODEL_TXT_PATH\n",
    "            )\n",
    "        )\n",
    "        structure = [('word', np.dtype('U' + str(self.WORD_MAX_SIZE))),\n",
    "                     ('embedding', np.float32, (self.N_FEATURES,))]\n",
    "        structure = np.dtype(structure)\n",
    "        # load numpy array from disk using a generator\n",
    "        with open(self.WORD_TO_VEC_MODEL_TXT_PATH, encoding=\"utf8\") as words_embeddings_txt:\n",
    "            embeddings_gen = (\n",
    "                (line.split()[0], line.split()[1:]) for line in words_embeddings_txt\n",
    "                if len(line.split()[1:]) == self.N_FEATURES\n",
    "            )\n",
    "            embeddings = np.fromiter(embeddings_gen, structure)\n",
    "        # add a null embedding\n",
    "        null_embedding = np.array(\n",
    "            [('null_embedding', np.zeros((self.N_FEATURES,), dtype=np.float32))],\n",
    "            dtype=structure\n",
    "        )\n",
    "        embeddings = np.concatenate([embeddings, null_embedding])\n",
    "        # dump numpy array to disk using pickle\n",
    "        max_bytes = 2**28 - 1 # # 256MB\n",
    "        bytes_out = pickle.dumps(embeddings, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "        with open(self.PKL_PATH, 'wb') as f_out:\n",
    "            for idx in range(0, len(bytes_out), max_bytes):\n",
    "                f_out.write(bytes_out[idx:idx+max_bytes])\n",
    "        self.logger.debug('words embeddings loaded')\n",
    "        return embeddings\n",
    "\n",
    "\n",
    "class GloveEmbeddings(WordsEmbeddings):\n",
    "    WORD_TO_VEC_MODEL_TXT_PATH = 'glove.twitter.27B.50d.txt'\n",
    "    PKL_PATH = 'gloveembedding.pkl'\n",
    "    N_FEATURES = 50\n",
    "    WORD_MAX_SIZE = 60\n",
    "\n",
    "class FasttextEmbeddingsEN(WordsEmbeddings):\n",
    "    WORD_TO_VEC_MODEL_TXT_PATH = 'cc.en.300.vec'\n",
    "    PKL_PATH = 'fasttext_en.pkl'\n",
    "    N_FEATURES = 300\n",
    "    WORD_MAX_SIZE = 60\n",
    "\n",
    "class FasttextEmbeddingsES(WordsEmbeddings):\n",
    "    WORD_TO_VEC_MODEL_TXT_PATH = 'cc.es.300.vec'\n",
    "    PKL_PATH = 'fasttext_es.pkl'\n",
    "    N_FEATURES = 300\n",
    "    WORD_MAX_SIZE = 60\n",
    "\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Mosj2-x-kXBK",
    "ExecuteTime": {
     "end_time": "2025-12-14T00:21:49.444320Z",
     "start_time": "2025-12-14T00:21:35.295413Z"
    }
   },
   "source": [
    "model_embeddings_en = FasttextEmbeddingsEN()\n",
    "model_embeddings_es = FasttextEmbeddingsES()\n"
   ],
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "b9FS8ca1ke_B",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "4e21f33e-2137-4742-ca79-2ca2e367136b",
    "ExecuteTime": {
     "end_time": "2025-12-14T00:24:27.371432Z",
     "start_time": "2025-12-14T00:24:27.326959Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "\n",
    "def create_embedding_matrix(word_index, embedding_model, max_vocab_size):\n",
    "    \"\"\"\n",
    "    Crea una matriz de embeddings a partir de un diccionario de palabras y un modelo de embeddings.\n",
    "\n",
    "    Args:\n",
    "        word_index (dict): Diccionario {palabra: indice} del tokenizador.\n",
    "        embedding_model (object): Instancia del modelo de embeddings (ej. FasttextEmbeddingsEN).\n",
    "        max_vocab_size (int): Tamaño máximo del vocabulario permitido.\n",
    "\n",
    "    Returns:\n",
    "        np.array: Matriz de embeddings de dimensiones (nb_words, embed_dim).\n",
    "    \"\"\"\n",
    "    print('Preparing embedding matrix...')\n",
    "\n",
    "    # Obtener dimensión de los vectores del modelo\n",
    "    embed_dim = embedding_model.N_FEATURES\n",
    "\n",
    "    # Definir el tamaño del vocabulario (cota superior)\n",
    "    # Nota: Se usa len(word_index) + 1 para asegurar cobertura si los índices empiezan en 1\n",
    "    nb_words = min(max_vocab_size, len(word_index) + 1)\n",
    "\n",
    "    # Inicializar matriz con ceros\n",
    "    embedding_matrix = np.zeros((nb_words, embed_dim))\n",
    "\n",
    "    words_not_found = []\n",
    "\n",
    "    for word, i in word_index.items():\n",
    "        # Si el índice supera el tamaño máximo definido, lo ignoramos\n",
    "        if i >= nb_words:\n",
    "            continue\n",
    "\n",
    "        # Obtener el vector del modelo\n",
    "        # Nota: Asumimos que get_words_embeddings devuelve una lista/array, tomamos el [0]\n",
    "        embedding_vector = embedding_model.get_words_embeddings([word])[0]\n",
    "\n",
    "        if (embedding_vector is not None) and len(embedding_vector) > 0:\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "        else:\n",
    "            words_not_found.append(word)\n",
    "\n",
    "    # Reporte de palabras nulas (vectores de ceros)\n",
    "    null_count = np.sum(np.sum(embedding_matrix**2, axis=1) == 0)\n",
    "    print(f'Number of null word embeddings: {null_count}')\n",
    "    print(embedding_matrix.shape)\n",
    "    return embedding_matrix\n",
    "\n",
    "print(\"Crear matriz para Inglés (Encoder)\")\n",
    "embedding_matrix_en = create_embedding_matrix(\n",
    "    word_index=word2idx_inputs,\n",
    "    embedding_model=model_embeddings_en,\n",
    "    max_vocab_size=MAX_VOCAB_SIZE\n",
    ")\n",
    "\n",
    "print(\"Crear matriz para Español (Decoder)\")\n",
    "embedding_matrix_es = create_embedding_matrix(\n",
    "    word_index=word2idx_outputs,\n",
    "    embedding_model=model_embeddings_es,\n",
    "    max_vocab_size=MAX_VOCAB_SIZE\n",
    ")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crear matriz para Inglés (Encoder)\n",
      "Preparing embedding matrix...\n",
      "Number of null word embeddings: 74\n",
      "(3852, 300)\n",
      "Crear matriz para Español (Decoder)\n",
      "Preparing embedding matrix...\n",
      "Number of null word embeddings: 62\n",
      "(5722, 300)\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3vKbhjtIwPgM"
   },
   "source": [
    "### 4 - Entrenar el modelo"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "t_urD1qO2kOx",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 512
    },
    "outputId": "45a0ee72-cf5d-4de6-ebf7-cdad0715ab2e",
    "ExecuteTime": {
     "end_time": "2025-12-14T00:24:56.290772Z",
     "start_time": "2025-12-14T00:24:55.354425Z"
    }
   },
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense, Embedding\n",
    "import tensorflow as tf\n",
    "\n",
    "# Asumo que estas variables ya las tenés definidas arriba:\n",
    "# n_units, max_input_len, nb_words, embed_dim, embedding_matrix,\n",
    "# num_words_output, max_out_len\n",
    "\n",
    "n_units = 128\n",
    "\n",
    "# --- ENCODER ---\n",
    "encoder_inputs = Input(shape=(max_input_len,), name='Encoder_Input')\n",
    "\n",
    "encoder_embedding_layer = Embedding(\n",
    "    input_dim=embedding_matrix_en.shape[0],    # Tamaño del vocabulario de entrada\n",
    "    output_dim=model_embeddings_en.N_FEATURES, # Dimensión del vector denso\n",
    "    weights=[embedding_matrix_en],             # Cargar pesos pre-entrenados\n",
    "    trainable=False,                           # Congelar para no re-entrenar\n",
    "    name='Encoder_Embedding'\n",
    ")\n",
    "\n",
    "encoder_inputs_x = encoder_embedding_layer(encoder_inputs)\n",
    "\n",
    "# LSTM Encoder\n",
    "encoder = LSTM(n_units, return_state=True, name='Encoder_LSTM')\n",
    "encoder_outputs, state_h, state_c = encoder(encoder_inputs_x)\n",
    "\n",
    "# Guardamos los estados para pasarlos al decoder (Context Vector)\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "# --- DECODER ---\n",
    "decoder_inputs = Input(shape=(max_out_len,), name='Decoder_Input')\n",
    "\n",
    "decoder_embedding_layer = Embedding(\n",
    "    input_dim=embedding_matrix_es.shape[0],      # Tamaño del vocabulario de salida\n",
    "    output_dim=model_embeddings_es.N_FEATURES,   # Dimensión 300 (FastText)\n",
    "    weights=[embedding_matrix_es],               # Cargar pesos pre-entrenados (Español)\n",
    "    trainable=False,                             # Congelar para no re-entrenar\n",
    "    name='Decoder_Embedding'\n",
    ")\n",
    "\n",
    "decoder_inputs_x = decoder_embedding_layer(decoder_inputs)\n",
    "\n",
    "# LSTM Decoder\n",
    "# return_sequences=True es vital aquí porque queremos la predicción palabra por palabra\n",
    "decoder_lstm = LSTM(n_units, return_sequences=True, return_state=True, name='Decoder_LSTM')\n",
    "\n",
    "# Inicializamos el decoder con los estados del encoder\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_inputs_x, initial_state=encoder_states)\n",
    "\n",
    "# --- SALIDA ---\n",
    "decoder_dense = Dense(num_words_output, activation='softmax', name='Output_Layer')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "# --- MODELO ---\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs, name='Seq2Seq_Translator')\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=\"Adam\", metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "encoder_model = Model(encoder_inputs, encoder_states)\n",
    "\n",
    "# define inference decoder\n",
    "decoder_state_input_h = Input(shape=(n_units,))\n",
    "decoder_state_input_c = Input(shape=(n_units,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "\n",
    "# En cada predicción habrá una sola palabra de entrada al decoder,\n",
    "# que es la realimentación de la palabra anterior\n",
    "# por lo que hay que modificar el input shape de la layer de Embedding\n",
    "decoder_inputs_single = Input(shape=(1,))\n",
    "decoder_inputs_single_x = decoder_embedding_layer(decoder_inputs_single)\n",
    "\n",
    "decoder_outputs, state_h, state_c = decoder_lstm(decoder_inputs_single_x, initial_state=decoder_states_inputs)\n",
    "decoder_states = [state_h, state_c]\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "decoder_model = Model([decoder_inputs_single] + decoder_states_inputs, [decoder_outputs] + decoder_states)\n",
    "\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1765671895.712878    9237 gpu_device.cc:2020] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4626 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1660 SUPER, pci bus id: 0000:0a:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1mModel: \"Seq2Seq_Translator\"\u001B[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"Seq2Seq_Translator\"</span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001B[1m \u001B[0m\u001B[1mLayer (type)       \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mOutput Shape     \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1m   Param #\u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mConnected to     \u001B[0m\u001B[1m \u001B[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Encoder_Input       │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m32\u001B[0m)        │          \u001B[38;5;34m0\u001B[0m │ -                 │\n",
       "│ (\u001B[38;5;33mInputLayer\u001B[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Decoder_Input       │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m36\u001B[0m)        │          \u001B[38;5;34m0\u001B[0m │ -                 │\n",
       "│ (\u001B[38;5;33mInputLayer\u001B[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Encoder_Embedding   │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m32\u001B[0m, \u001B[38;5;34m300\u001B[0m)   │  \u001B[38;5;34m1,155,600\u001B[0m │ Encoder_Input[\u001B[38;5;34m0\u001B[0m]… │\n",
       "│ (\u001B[38;5;33mEmbedding\u001B[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Decoder_Embedding   │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m36\u001B[0m, \u001B[38;5;34m300\u001B[0m)   │  \u001B[38;5;34m1,716,600\u001B[0m │ Decoder_Input[\u001B[38;5;34m0\u001B[0m]… │\n",
       "│ (\u001B[38;5;33mEmbedding\u001B[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Encoder_LSTM (\u001B[38;5;33mLSTM\u001B[0m) │ [(\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m128\u001B[0m),     │    \u001B[38;5;34m219,648\u001B[0m │ Encoder_Embeddin… │\n",
       "│                     │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m128\u001B[0m),      │            │                   │\n",
       "│                     │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m128\u001B[0m)]      │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Decoder_LSTM (\u001B[38;5;33mLSTM\u001B[0m) │ [(\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m36\u001B[0m, \u001B[38;5;34m128\u001B[0m), │    \u001B[38;5;34m219,648\u001B[0m │ Decoder_Embeddin… │\n",
       "│                     │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m128\u001B[0m),      │            │ Encoder_LSTM[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m…\u001B[0m │\n",
       "│                     │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m128\u001B[0m)]      │            │ Encoder_LSTM[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m…\u001B[0m │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Output_Layer        │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m36\u001B[0m, \u001B[38;5;34m5722\u001B[0m)  │    \u001B[38;5;34m738,138\u001B[0m │ Decoder_LSTM[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m…\u001B[0m │\n",
       "│ (\u001B[38;5;33mDense\u001B[0m)             │                   │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Encoder_Input       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Decoder_Input       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Encoder_Embedding   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)   │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,155,600</span> │ Encoder_Input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Decoder_Embedding   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)   │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,716,600</span> │ Decoder_Input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Encoder_LSTM (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>) │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>),     │    <span style=\"color: #00af00; text-decoration-color: #00af00\">219,648</span> │ Encoder_Embeddin… │\n",
       "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>),      │            │                   │\n",
       "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)]      │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Decoder_LSTM (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>) │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>), │    <span style=\"color: #00af00; text-decoration-color: #00af00\">219,648</span> │ Decoder_Embeddin… │\n",
       "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>),      │            │ Encoder_LSTM[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)]      │            │ Encoder_LSTM[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Output_Layer        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5722</span>)  │    <span style=\"color: #00af00; text-decoration-color: #00af00\">738,138</span> │ Decoder_LSTM[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Total params: \u001B[0m\u001B[38;5;34m4,049,634\u001B[0m (15.45 MB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,049,634</span> (15.45 MB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Trainable params: \u001B[0m\u001B[38;5;34m1,177,434\u001B[0m (4.49 MB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,177,434</span> (4.49 MB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Non-trainable params: \u001B[0m\u001B[38;5;34m2,872,200\u001B[0m (10.96 MB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,872,200</span> (10.96 MB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-14T00:24:40.188655Z",
     "start_time": "2025-12-14T00:24:37.848947Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import wandb\n",
    "from wandb.integration.keras import WandbMetricsLogger\n",
    "\n",
    "# Intentar recuperar la clave del entorno\n",
    "wandb_api_key = os.getenv(\"WANDB_API_KEY\")\n",
    "\n",
    "if wandb_api_key:\n",
    "    # Loguearse de forma no interactiva\n",
    "    wandb.login(key=wandb_api_key)\n",
    "    print(\"Logueado en WANDB exitosamente desde variable de entorno.\")\n",
    "else:\n",
    "    # Fallback por si la variable no existe (pedirá input manual)\n",
    "    raise RuntimeError(\"No se encontró WANDB_API_KEY en el entorno\")\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: \u001B[32m\u001B[41mERROR\u001B[0m Failed to detect the name of this notebook. You can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \u001B[33mWARNING\u001B[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \u001B[33mWARNING\u001B[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Appending key for api.wandb.ai to your netrc file: /home/jose/.netrc\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Currently logged in as: \u001B[33mdiazjoseluis\u001B[0m (\u001B[33mdiazjoseluis-auth0\u001B[0m) to \u001B[32mhttps://api.wandb.ai\u001B[0m. Use \u001B[1m`wandb login --relogin`\u001B[0m to force relogin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logueado en WANDB exitosamente desde variable de entorno.\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "VnlIx1Vezjwc",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "51db248e-b85d-4fea-baa4-76cebc5a715a",
    "ExecuteTime": {
     "end_time": "2025-12-14T00:25:29.597547Z",
     "start_time": "2025-12-14T00:25:03.200128Z"
    }
   },
   "source": [
    "# Inicializar la run de WANDB\n",
    "run = wandb.init(\n",
    "    project=\"traductor-seq2seq-lstm\", # Ponle el nombre que quieras a tu proyecto\n",
    "    config={\n",
    "        \"epochs\": 30,\n",
    "        \"batch_size\": 32,             # El default de Keras es 32 si no lo especificas\n",
    "        \"n_units\": n_units,           # 128\n",
    "        \"embedding_dim\": 300,         # FastText\n",
    "        \"architecture\": \"LSTM + FastText Frozen\"\n",
    "    }\n",
    ")\n",
    "\n",
    "hist = model.fit(\n",
    "    [encoder_input_sequences, decoder_input_sequences],\n",
    "    decoder_targets,\n",
    "    epochs=30,\n",
    "    batch_size=32,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[WandbMetricsLogger(log_freq=\"batch\")]\n",
    ")\n",
    "\n",
    "# Cerrar la run al terminar (opcional pero recomendado en notebooks)\n",
    "wandb.finish()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Tracking run with wandb version 0.23.1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Run data is saved locally in <code>/home/jose/Code/jupyer/wandb/run-20251214_002503-9lonxb2d</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/diazjoseluis-auth0/traductor-seq2seq-lstm/runs/9lonxb2d' target=\"_blank\">glowing-sponge-6</a></strong> to <a href='https://wandb.ai/diazjoseluis-auth0/traductor-seq2seq-lstm' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View project at <a href='https://wandb.ai/diazjoseluis-auth0/traductor-seq2seq-lstm' target=\"_blank\">https://wandb.ai/diazjoseluis-auth0/traductor-seq2seq-lstm</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run at <a href='https://wandb.ai/diazjoseluis-auth0/traductor-seq2seq-lstm/runs/9lonxb2d' target=\"_blank\">https://wandb.ai/diazjoseluis-auth0/traductor-seq2seq-lstm/runs/9lonxb2d</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-14 00:25:07.195368: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:84] Allocation of 3955046400 exceeds 10% of free system memory.\n",
      "2025-12-14 00:25:10.850316: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:84] Allocation of 3955046400 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-14 00:25:14.216351: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:473] Loaded cuDNN version 91002\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m149/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.7654 - loss: 4.5058"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-14 00:25:29.489963: W external/local_xla/xla/tsl/framework/bfc_allocator.cc:501] Allocator (GPU_0_bfc) ran out of memory trying to allocate 942.96MiB (rounded to 988761600)requested by op _EagerConst\n",
      "If the cause is memory fragmentation maybe the environment variable 'TF_GPU_ALLOCATOR=cuda_malloc_async' will improve the situation. \n",
      "Current allocation summary follows.\n",
      "Current allocation summary follows.\n",
      "2025-12-14 00:25:29.489997: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1049] BFCAllocator dump for GPU_0_bfc\n",
      "2025-12-14 00:25:29.490007: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (256): \tTotal Chunks: 38, Chunks in use: 36. 9.5KiB allocated for chunks. 9.0KiB in use in bin. 192B client-requested in use in bin.\n",
      "2025-12-14 00:25:29.490012: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (512): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-12-14 00:25:29.490017: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (1024): \tTotal Chunks: 2, Chunks in use: 1. 2.8KiB allocated for chunks. 1.2KiB in use in bin. 1.0KiB client-requested in use in bin.\n",
      "2025-12-14 00:25:29.490022: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (2048): \tTotal Chunks: 7, Chunks in use: 7. 15.0KiB allocated for chunks. 15.0KiB in use in bin. 14.0KiB client-requested in use in bin.\n",
      "2025-12-14 00:25:29.490027: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (4096): \tTotal Chunks: 2, Chunks in use: 1. 9.5KiB allocated for chunks. 4.5KiB in use in bin. 4.5KiB client-requested in use in bin.\n",
      "2025-12-14 00:25:29.490030: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (8192): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-12-14 00:25:29.490035: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (16384): \tTotal Chunks: 3, Chunks in use: 3. 69.8KiB allocated for chunks. 69.8KiB in use in bin. 60.7KiB client-requested in use in bin.\n",
      "2025-12-14 00:25:29.490040: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (32768): \tTotal Chunks: 1, Chunks in use: 1. 34.8KiB allocated for chunks. 34.8KiB in use in bin. 22.4KiB client-requested in use in bin.\n",
      "2025-12-14 00:25:29.490044: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (65536): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-12-14 00:25:29.490047: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (131072): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-12-14 00:25:29.490052: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (262144): \tTotal Chunks: 6, Chunks in use: 6. 1.71MiB allocated for chunks. 1.71MiB in use in bin. 1.50MiB client-requested in use in bin.\n",
      "2025-12-14 00:25:29.490056: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (524288): \tTotal Chunks: 10, Chunks in use: 7. 6.57MiB allocated for chunks. 4.20MiB in use in bin. 4.02MiB client-requested in use in bin.\n",
      "2025-12-14 00:25:29.490060: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (1048576): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-12-14 00:25:29.490065: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (2097152): \tTotal Chunks: 4, Chunks in use: 3. 11.48MiB allocated for chunks. 8.38MiB in use in bin. 8.38MiB client-requested in use in bin.\n",
      "2025-12-14 00:25:29.490070: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (4194304): \tTotal Chunks: 2, Chunks in use: 2. 10.96MiB allocated for chunks. 10.96MiB in use in bin. 10.96MiB client-requested in use in bin.\n",
      "2025-12-14 00:25:29.490073: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (8388608): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-12-14 00:25:29.490083: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (16777216): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-12-14 00:25:29.490087: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (33554432): \tTotal Chunks: 1, Chunks in use: 0. 34.23MiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-12-14 00:25:29.490091: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (67108864): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-12-14 00:25:29.490094: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (134217728): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-12-14 00:25:29.490099: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (268435456): \tTotal Chunks: 2, Chunks in use: 1. 4.45GiB allocated for chunks. 3.68GiB in use in bin. 3.68GiB client-requested in use in bin.\n",
      "2025-12-14 00:25:29.490105: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1072] Bin for 942.96MiB was 256.00MiB, Chunk State: \n",
      "2025-12-14 00:25:29.490115: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1078]   Size: 789.66MiB | Requested Size: 6.29MiB | in_use: 0 | bin_num: 20, prev:   Size: 600.0KiB | Requested Size: 600.0KiB | in_use: 1 | bin_num: -1\n",
      "2025-12-14 00:25:29.490118: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1085] Next region of size 4851302400\n",
      "2025-12-14 00:25:29.490124: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 74d166000000 of size 1280 next 1\n",
      "2025-12-14 00:25:29.490127: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 74d166000500 of size 256 next 2\n",
      "2025-12-14 00:25:29.490130: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 74d166000600 of size 256 next 3\n",
      "2025-12-14 00:25:29.490133: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 74d166000700 of size 256 next 4\n",
      "2025-12-14 00:25:29.490136: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 74d166000800 of size 4622592 next 5\n",
      "2025-12-14 00:25:29.490140: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 74d166469100 of size 256 next 10\n",
      "2025-12-14 00:25:29.490143: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 74d166469200 of size 256 next 11\n",
      "2025-12-14 00:25:29.490146: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 74d166469300 of size 256 next 7\n",
      "2025-12-14 00:25:29.490149: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 74d166469400 of size 256 next 8\n",
      "2025-12-14 00:25:29.490152: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 74d166469500 of size 256 next 9\n",
      "2025-12-14 00:25:29.490155: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 74d166469600 of size 256 next 18\n",
      "2025-12-14 00:25:29.490158: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 74d166469700 of size 256 next 41\n",
      "2025-12-14 00:25:29.490161: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 74d166469800 of size 256 next 35\n",
      "2025-12-14 00:25:29.490164: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 74d166469900 of size 256 next 36\n",
      "2025-12-14 00:25:29.490167: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 74d166469a00 of size 256 next 37\n",
      "2025-12-14 00:25:29.490170: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 74d166469b00 of size 256 next 39\n",
      "2025-12-14 00:25:29.490173: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] Free  at 74d166469c00 of size 256 next 19\n",
      "2025-12-14 00:25:29.490176: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 74d166469d00 of size 2048 next 20\n",
      "2025-12-14 00:25:29.490181: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 74d16646a500 of size 256 next 22\n",
      "2025-12-14 00:25:29.490184: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 74d16646a600 of size 256 next 31\n",
      "2025-12-14 00:25:29.490187: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 74d16646a700 of size 256 next 30\n",
      "2025-12-14 00:25:29.490190: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 74d16646a800 of size 256 next 26\n",
      "2025-12-14 00:25:29.490193: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 74d16646a900 of size 2048 next 29\n",
      "2025-12-14 00:25:29.490196: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 74d16646b100 of size 23040 next 27\n",
      "2025-12-14 00:25:29.490199: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 74d166470b00 of size 35584 next 12\n",
      "2025-12-14 00:25:29.490202: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 74d166479600 of size 256 next 13\n",
      "2025-12-14 00:25:29.490205: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 74d166479700 of size 256 next 24\n",
      "2025-12-14 00:25:29.490208: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 74d166479800 of size 256 next 16\n",
      "2025-12-14 00:25:29.490211: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 74d166479900 of size 458752 next 17\n",
      "2025-12-14 00:25:29.490214: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 74d1664e9900 of size 704256 next 14\n",
      "2025-12-14 00:25:29.490217: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 74d166595800 of size 614400 next 15\n",
      "2025-12-14 00:25:29.490221: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 74d16662b800 of size 6866432 next 21\n",
      "2025-12-14 00:25:29.490224: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 74d166cb7e00 of size 2048 next 40\n",
      "2025-12-14 00:25:29.490227: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 74d166cb8600 of size 256 next 42\n",
      "2025-12-14 00:25:29.490230: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 74d166cb8700 of size 256 next 43\n",
      "2025-12-14 00:25:29.490233: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 74d166cb8800 of size 16384 next 45\n",
      "2025-12-14 00:25:29.490236: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 74d166cbc800 of size 256 next 46\n",
      "2025-12-14 00:25:29.490239: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 74d166cbc900 of size 256 next 47\n",
      "2025-12-14 00:25:29.490242: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 74d166cbca00 of size 256 next 48\n",
      "2025-12-14 00:25:29.490245: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 74d166cbcb00 of size 256 next 49\n",
      "2025-12-14 00:25:29.490248: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 74d166cbcc00 of size 256 next 50\n",
      "2025-12-14 00:25:29.490250: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 74d166cbcd00 of size 256 next 51\n",
      "2025-12-14 00:25:29.490253: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 74d166cbce00 of size 256 next 52\n",
      "2025-12-14 00:25:29.490256: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 74d166cbcf00 of size 2048 next 53\n",
      "2025-12-14 00:25:29.490259: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 74d166cbd700 of size 4608 next 54\n",
      "2025-12-14 00:25:29.490263: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 74d166cbe900 of size 32000 next 67\n",
      "2025-12-14 00:25:29.490266: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 74d166cc6600 of size 256 next 122\n",
      "2025-12-14 00:25:29.490269: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 74d166cc6700 of size 256 next 128\n",
      "2025-12-14 00:25:29.490273: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] Free  at 74d166cc6800 of size 256 next 70\n",
      "2025-12-14 00:25:29.490276: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 74d166cc6900 of size 256 next 127\n",
      "2025-12-14 00:25:29.490278: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 74d166cc6a00 of size 256 next 114\n",
      "2025-12-14 00:25:29.490281: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] Free  at 74d166cc6b00 of size 1536 next 105\n",
      "2025-12-14 00:25:29.490284: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 74d166cc7100 of size 256 next 91\n",
      "2025-12-14 00:25:29.490287: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 74d166cc7200 of size 3072 next 23\n",
      "2025-12-14 00:25:29.490290: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 74d166cc7e00 of size 262144 next 28\n",
      "2025-12-14 00:25:29.490294: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 74d166d07e00 of size 286720 next 25\n",
      "2025-12-14 00:25:29.490297: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 74d166d4de00 of size 614400 next 6\n",
      "2025-12-14 00:25:29.490300: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 74d166de3e00 of size 2929664 next 34\n",
      "2025-12-14 00:25:29.490303: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 74d1670af200 of size 524288 next 44\n",
      "2025-12-14 00:25:29.490306: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 74d16712f200 of size 2048 next 86\n",
      "2025-12-14 00:25:29.490309: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 74d16712fa00 of size 2048 next 106\n",
      "2025-12-14 00:25:29.490312: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] Free  at 74d167130200 of size 806912 next 89\n",
      "2025-12-14 00:25:29.490315: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 74d1671f5200 of size 262144 next 99\n",
      "2025-12-14 00:25:29.490317: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 74d167235200 of size 262144 next 60\n",
      "2025-12-14 00:25:29.490321: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 74d167275200 of size 264448 next 108\n",
      "2025-12-14 00:25:29.490324: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] Free  at 74d1672b5b00 of size 5120 next 68\n",
      "2025-12-14 00:25:29.490326: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 74d1672b6f00 of size 256 next 100\n",
      "2025-12-14 00:25:29.490329: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] Free  at 74d1672b7000 of size 800256 next 33\n",
      "2025-12-14 00:25:29.490332: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 74d16737a600 of size 2929664 next 32\n",
      "2025-12-14 00:25:29.490335: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 74d167645a00 of size 3955046400 next 38\n",
      "2025-12-14 00:25:29.490338: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] Free  at 74d253219200 of size 35888384 next 87\n",
      "2025-12-14 00:25:29.490341: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 74d255452f00 of size 614400 next 59\n",
      "2025-12-14 00:25:29.490344: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] Free  at 74d2554e8f00 of size 3244288 next 56\n",
      "2025-12-14 00:25:29.490347: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 74d255801000 of size 716800 next 79\n",
      "2025-12-14 00:25:29.490350: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] Free  at 74d2558b0000 of size 880640 next 61\n",
      "2025-12-14 00:25:29.490353: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 74d255987000 of size 2929664 next 102\n",
      "2025-12-14 00:25:29.490356: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 74d255c52400 of size 614400 next 103\n",
      "2025-12-14 00:25:29.490359: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] Free  at 74d255ce8400 of size 828013568 next 18446744073709551615\n",
      "2025-12-14 00:25:29.490362: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1110]      Summary of in-use Chunks by size: \n",
      "2025-12-14 00:25:29.490365: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 36 Chunks of size 256 totalling 9.0KiB\n",
      "2025-12-14 00:25:29.490367: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 1 Chunks of size 1280 totalling 1.2KiB\n",
      "2025-12-14 00:25:29.490368: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 6 Chunks of size 2048 totalling 12.0KiB\n",
      "2025-12-14 00:25:29.490370: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 1 Chunks of size 3072 totalling 3.0KiB\n",
      "2025-12-14 00:25:29.490372: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 1 Chunks of size 4608 totalling 4.5KiB\n",
      "2025-12-14 00:25:29.490373: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 1 Chunks of size 16384 totalling 16.0KiB\n",
      "2025-12-14 00:25:29.490375: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 1 Chunks of size 23040 totalling 22.5KiB\n",
      "2025-12-14 00:25:29.490377: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 1 Chunks of size 32000 totalling 31.2KiB\n",
      "2025-12-14 00:25:29.490378: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 1 Chunks of size 35584 totalling 34.8KiB\n",
      "2025-12-14 00:25:29.490380: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 3 Chunks of size 262144 totalling 768.0KiB\n",
      "2025-12-14 00:25:29.490382: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 1 Chunks of size 264448 totalling 258.2KiB\n",
      "2025-12-14 00:25:29.490383: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 1 Chunks of size 286720 totalling 280.0KiB\n",
      "2025-12-14 00:25:29.490385: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 1 Chunks of size 458752 totalling 448.0KiB\n",
      "2025-12-14 00:25:29.490387: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 1 Chunks of size 524288 totalling 512.0KiB\n",
      "2025-12-14 00:25:29.490388: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 4 Chunks of size 614400 totalling 2.34MiB\n",
      "2025-12-14 00:25:29.490390: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 1 Chunks of size 704256 totalling 687.8KiB\n",
      "2025-12-14 00:25:29.490392: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 1 Chunks of size 716800 totalling 700.0KiB\n",
      "2025-12-14 00:25:29.490393: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 3 Chunks of size 2929664 totalling 8.38MiB\n",
      "2025-12-14 00:25:29.490395: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 1 Chunks of size 4622592 totalling 4.41MiB\n",
      "2025-12-14 00:25:29.490397: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 1 Chunks of size 6866432 totalling 6.55MiB\n",
      "2025-12-14 00:25:29.490398: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 1 Chunks of size 3955046400 totalling 3.68GiB\n",
      "2025-12-14 00:25:29.490400: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1117] Sum Total of in-use chunks: 3.71GiB\n",
      "2025-12-14 00:25:29.490402: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1119] Total bytes in pool: 4851302400 memory_limit_: 4851302400 available bytes: 0 curr_region_allocation_bytes_: 9702604800\n",
      "2025-12-14 00:25:29.490406: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1124] Stats: \n",
      "Limit:                      4851302400\n",
      "InUse:                      3981661184\n",
      "MaxInUse:                   4267955712\n",
      "NumAllocs:                       30022\n",
      "MaxAllocSize:               3955046400\n",
      "Reserved:                            0\n",
      "PeakReserved:                        0\n",
      "LargestFreeBlock:                    0\n",
      "\n",
      "2025-12-14 00:25:29.490409: W external/local_xla/xla/tsl/framework/bfc_allocator.cc:512] ***********************************************************************************_________________\n"
     ]
    },
    {
     "ename": "InternalError",
     "evalue": "Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized.",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mInternalError\u001B[39m                             Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[14]\u001B[39m\u001B[32m, line 13\u001B[39m\n\u001B[32m      1\u001B[39m \u001B[38;5;66;03m# Inicializar la run de WANDB\u001B[39;00m\n\u001B[32m      2\u001B[39m run = wandb.init(\n\u001B[32m      3\u001B[39m     project=\u001B[33m\"\u001B[39m\u001B[33mtraductor-seq2seq-lstm\u001B[39m\u001B[33m\"\u001B[39m, \u001B[38;5;66;03m# Ponle el nombre que quieras a tu proyecto\u001B[39;00m\n\u001B[32m      4\u001B[39m     config={\n\u001B[32m   (...)\u001B[39m\u001B[32m     10\u001B[39m     }\n\u001B[32m     11\u001B[39m )\n\u001B[32m---> \u001B[39m\u001B[32m13\u001B[39m hist = \u001B[43mmodel\u001B[49m\u001B[43m.\u001B[49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m     14\u001B[39m \u001B[43m    \u001B[49m\u001B[43m[\u001B[49m\u001B[43mencoder_input_sequences\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdecoder_input_sequences\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     15\u001B[39m \u001B[43m    \u001B[49m\u001B[43mdecoder_targets\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     16\u001B[39m \u001B[43m    \u001B[49m\u001B[43mepochs\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m30\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m     17\u001B[39m \u001B[43m    \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m32\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m     18\u001B[39m \u001B[43m    \u001B[49m\u001B[43mvalidation_split\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m0.2\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m     19\u001B[39m \u001B[43m    \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[43m=\u001B[49m\u001B[43m[\u001B[49m\u001B[43mWandbMetricsLogger\u001B[49m\u001B[43m(\u001B[49m\u001B[43mlog_freq\u001B[49m\u001B[43m=\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mbatch\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m]\u001B[49m\n\u001B[32m     20\u001B[39m \u001B[43m)\u001B[49m\n\u001B[32m     22\u001B[39m \u001B[38;5;66;03m# Cerrar la run al terminar (opcional pero recomendado en notebooks)\u001B[39;00m\n\u001B[32m     23\u001B[39m wandb.finish()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Code/jupyer/.venv/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:122\u001B[39m, in \u001B[36mfilter_traceback.<locals>.error_handler\u001B[39m\u001B[34m(*args, **kwargs)\u001B[39m\n\u001B[32m    119\u001B[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n\u001B[32m    120\u001B[39m     \u001B[38;5;66;03m# To get the full stack trace, call:\u001B[39;00m\n\u001B[32m    121\u001B[39m     \u001B[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m122\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m e.with_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m    123\u001B[39m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[32m    124\u001B[39m     \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Code/jupyer/.venv/lib/python3.12/site-packages/tensorflow/python/framework/constant_op.py:108\u001B[39m, in \u001B[36mconvert_to_eager_tensor\u001B[39m\u001B[34m(value, ctx, dtype)\u001B[39m\n\u001B[32m    106\u001B[39m     dtype = dtypes.as_dtype(dtype).as_datatype_enum\n\u001B[32m    107\u001B[39m ctx.ensure_initialized()\n\u001B[32m--> \u001B[39m\u001B[32m108\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mops\u001B[49m\u001B[43m.\u001B[49m\u001B[43mEagerTensor\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvalue\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mctx\u001B[49m\u001B[43m.\u001B[49m\u001B[43mdevice_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[31mInternalError\u001B[39m: Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized."
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "OVz1uug_zu2J",
    "ExecuteTime": {
     "end_time": "2025-12-14T00:15:08.064610Z",
     "start_time": "2025-12-14T00:15:07.938281Z"
    }
   },
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Entrenamiento\n",
    "epoch_count = range(1, len(hist.history['accuracy']) + 1)\n",
    "sns.lineplot(x=epoch_count,  y=hist.history['accuracy'], label='train')\n",
    "sns.lineplot(x=epoch_count,  y=hist.history['val_accuracy'], label='valid')\n",
    "plt.show()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 16
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zbwn0ekDy_s2"
   },
   "source": [
    "### 5 - Inferencia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jnkl3mSpsU_7"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Step 1:\n",
    "A deal is a deal -> Encoder -> enc(h1,c1)\n",
    "\n",
    "enc(h1,c1) + <sos> -> Decoder -> Un + dec(h1,c1)\n",
    "\n",
    "step 2:\n",
    "dec(h1,c1) + Un -> Decoder -> trato + dec(h2,c2)\n",
    "\n",
    "step 3:\n",
    "dec(h2,c2) + trato -> Decoder -> es + dec(h3,c3)\n",
    "\n",
    "step 4:\n",
    "dec(h3,c3) + es -> Decoder -> un + dec(h4,c4)\n",
    "\n",
    "step 5:\n",
    "dec(h4,c4) + un -> Decoder -> trato + dec(h5,c5)\n",
    "\n",
    "step 6:\n",
    "dec(h5,c5) + trato. -> Decoder -> <eos> + dec(h6,c6)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "71XeCtfYmOFx"
   },
   "outputs": [],
   "source": [
    "# Armar los conversores de índice a palabra:\n",
    "idx2word_input = {v:k for k, v in word2idx_inputs.items()}\n",
    "idx2word_target = {v:k for k, v in word2idx_outputs.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MlUyp9M6ua2V"
   },
   "outputs": [],
   "source": [
    "def translate_sentence(input_seq):\n",
    "    # Se transforma la sequencia de entrada a los estados \"h\" y \"c\" de la LSTM\n",
    "    # para enviar la primera vez al decoder\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "\n",
    "    # Se inicializa la secuencia de entrada al decoder como \"<sos>\"\n",
    "    target_seq = np.zeros((1, 1))\n",
    "    target_seq[0, 0] = word2idx_outputs['<sos>']\n",
    "\n",
    "    # Se obtiene el índice que finaliza la inferencia\n",
    "    eos = word2idx_outputs['<eos>']\n",
    "\n",
    "    output_sentence = []\n",
    "    for _ in range(max_out_len):\n",
    "        # Predicción del próximo elemento\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
    "        idx = np.argmax(output_tokens[0, 0, :])\n",
    "\n",
    "        # Si es \"end of sentece <eos>\" se acaba\n",
    "        if eos == idx:\n",
    "            break\n",
    "\n",
    "        # Transformar idx a palabra\n",
    "        word = ''\n",
    "        if idx > 0:\n",
    "            word = idx2word_target[idx]\n",
    "            output_sentence.append(word)\n",
    "\n",
    "        # Actualizar los estados dada la última predicción\n",
    "        states_value = [h, c]\n",
    "\n",
    "        # Actualizar secuencia de entrada con la salida (re-alimentación)\n",
    "        target_seq[0, 0] = idx\n",
    "\n",
    "    return ' '.join(output_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZhGVjLKcunxW"
   },
   "outputs": [],
   "source": [
    "i = np.random.choice(len(input_sentences))\n",
    "input_seq = encoder_input_sequences[i:i+1]\n",
    "translation = translate_sentence(input_seq)\n",
    "print('-')\n",
    "print('Input:', input_sentences[i])\n",
    "print('Response:', translation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KYZ1Q_Z_2G4m"
   },
   "outputs": [],
   "source": [
    "input_test = \"Goodnight.\"\n",
    "print('Input:', input_test)\n",
    "integer_seq_test = input_tokenizer.texts_to_sequences([input_test])[0]\n",
    "print(\"Representacion en vector de tokens de ids\", integer_seq_test)\n",
    "encoder_sequence_test = pad_sequences([integer_seq_test], maxlen=max_input_len)\n",
    "print(\"Padding del vector:\", encoder_sequence_test)\n",
    "\n",
    "print('Input:', input_test)\n",
    "translation = translate_sentence(encoder_sequence_test)\n",
    "print('Response:', translation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pkOjSJweqdF8"
   },
   "source": [
    "### 6 - Conclusión\n",
    "A primera vista parece que el modelo tendría que funcionar muy bien por el accuracy alcanzado. La realidad es que las respuestas no tienen que ver demasiado con la pregunta/traducción pero la respuesta en si tiene bastante coherencia.\\\n",
    "Para poder mejorar el modelo haría falta poder consumir todo el dataset y todo el vocabulario, pero la cantidad de RAM no es suficiente.\\\n",
    "Este problema se resuelve con:\n",
    "- Utilizando un DataGenerator para no levantar todo el dataset junto en el entrenamiento.\n",
    "- Transfer learning evitando tener que entrenar todo el modelo  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZSy0kaSKuC4-"
   },
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": [],
   "machine_shape": "hm",
   "gpuType": "A100"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
