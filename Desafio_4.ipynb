{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pfa39F4lsLf3"
      },
      "source": [
        "<img src=\"https://github.com/hernancontigiani/ceia_memorias_especializacion/raw/master/Figures/logoFIUBA.jpg\" width=\"500\" align=\"center\">\n",
        "\n",
        "\n",
        "# Procesamiento de lenguaje natural\n",
        "## LSTM Traductor\n",
        "Ejemplo basado en [LINK](https://stackabuse.com/python-for-nlp-neural-machine-translation-with-seq2seq-in-keras/)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Resumen del proceso de optimización\n",
        "\n",
        "* **Iteración 1: FastText & Embeddings**\n",
        "    Reemplazo de GloVe por **FastText (300d)**, implementando una carga agnóstica de pesos y congelando la capa de embedding para *transfer learning*.\n",
        "\n",
        "* **Iteración 2: Monitoreo con WANDB**\n",
        "    Integración de **Weights & Biases** adaptada a Keras 3 (`WandbMetricsLogger`) y gestión segura de credenciales mediante *Secrets* y variables de entorno.\n",
        "\n",
        "* **Iteración 3: Optimización de Memoria**\n",
        "    Migración a `sparse_categorical_crossentropy` para eliminar la codificación *one-hot* en los targets, reduciendo drásticamente el uso de RAM.\n",
        "\n",
        "* **Iteración 4: Capacidad y Regularización**\n",
        "    Escalado de la arquitectura a **256 unidades LSTM** e introducción de **Dropout (0.3)** en encoder y decoder para combatir el *overfitting*.\n",
        "\n",
        "* **Iteración 5: Persistencia e Inferencia**\n",
        "    Implementación de **EarlyStopping** y **ModelCheckpoint** en Google Drive, junto con una lógica de \"hidratación\" para reconstruir la inferencia desde el modelo guardado.\n",
        "\n",
        "* **Iteración 6: DataGenerator (Full Dataset)**\n",
        "    Desarrollo de un generador de datos (`Sequence`) para entrenar por *batches*, permitiendo el uso del **dataset completo (+118k frases)** sin límites de memoria.\n",
        "\n",
        "* **Iteración 7: Scaling Definitivo (512 Units)**\n",
        "    Escalado final de la arquitectura a **512 unidades LSTM** y aumento del **Dropout a 0.4**, maximizando la capacidad del modelo para capturar matices complejos en el dataset completo.\n",
        "\n",
        "### Análisis de Resultados: Impacto de la Escala y el Volumen de Datos\n",
        "\n",
        "![Arquitectura del modelo](https://github.com/joseluisdiaz/procesamiento_lenguaje_natural-tp/raw/main/img/desafio4.png)\n",
        "\n",
        "La gráfica comparativa de experimentos muestra una evolución clara y positiva en el rendimiento del modelo a través de las distintas iteraciones. La línea naranja (**`final_run`**), correspondiente a nuestra arquitectura definitiva (**512 unidades, Dropout 0.4 y Dataset Completo**), demuestra la superioridad de la estrategia de escalado frente a las pruebas anteriores.\n",
        "\n",
        "**Observaciones**\n",
        "\n",
        "* **Convergencia Acelerada:**\n",
        "    A diferencia de los modelos iniciales (líneas violetas y azules) que comenzaban con una *accuracy* baja y subían lentamente, la `final_run` (naranja) muestra un arranque explosivo. Esto se atribuye a la integración de **Embeddings FastText (300d)** y al aumento de capacidad (512 units), permitiendo al modelo aprovechar el conocimiento pre-entrenado desde la primera época.\n",
        "\n",
        "* **Ruptura del \"Plateau\":**\n",
        "    Los modelos intermedios (líneas rojas/marrones) tendían a estancarse o \"plancharse\" alrededor del 85-88% de accuracy debido a la falta de datos (limitados a 15k muestras). La línea naranja rompe ese techo, superando el **90% de accuracy** y manteniendo una pendiente ascendente sostenida. Esto confirma que el modelo anterior estaba subajustado (*underfitting*) por falta de capacidad o limitado por la escasez de ejemplos variados.\n",
        "\n",
        "* **Estabilidad Generalización (Train vs. Val):**\n",
        "    Lo más destacable es la línea punteada naranja (*validation accuracy*). A pesar de haber cuadruplicado la complejidad del modelo (de 128 a 512 unidades), la validación no colapsa ni se separa drásticamente del entrenamiento. Esto valida el uso del **Dataset Completo (118k oraciones)** junto con un **Dropout del 0.4**: el modelo tiene suficientes datos \"reales\" para llenar su capacidad neuronal sin necesidad de recurrir a la memorización pura (*overfitting*), logrando generalizar reglas gramaticales complejas.\n",
        "\n",
        "**Conclusión:**\n",
        "La configuración final representa el punto óptimo de equilibrio. Hemos logrado transformar un prototipo limitado por memoria en un traductor robusto, donde el aumento de recursos computacionales (VRAM/Cómputo) se traduce directamente en una mejora tangible en la calidad de la traducción."
      ],
      "metadata": {
        "id": "3PFcSHG58hz1"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cq3YXak9sGHd",
        "ExecuteTime": {
          "end_time": "2025-12-14T00:21:07.349104Z",
          "start_time": "2025-12-14T00:21:07.322128Z"
        }
      },
      "source": [
        "import re\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import one_hot\n",
        "from tensorflow.keras.utils import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Activation, Dropout, Dense\n",
        "from tensorflow.keras.layers import Flatten, LSTM, SimpleRNN\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Embedding\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.layers import Input\n",
        "from keras.utils import plot_model"
      ],
      "outputs": [],
      "execution_count": 1
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RHNkUaPp6aYq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b2e9166-1e5f-44ac-ba7c-e92b0a653381",
        "ExecuteTime": {
          "end_time": "2025-12-14T00:21:09.435946Z",
          "start_time": "2025-12-14T00:21:09.431063Z"
        }
      },
      "source": [
        "# Descargar la carpeta de dataset\n",
        "\n",
        "import os\n",
        "if os.access('spa-eng', os.F_OK) is False:\n",
        "    if os.access('spa-eng.zip', os.F_OK) is False:\n",
        "        !curl -L -o 'spa-eng.zip' 'http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip'\n",
        "    !unzip -q spa-eng.zip\n",
        "else:\n",
        "    print(\"El dataset ya se encuentra descargado\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 2576k  100 2576k    0     0  1814k      0  0:00:01  0:00:01 --:--:-- 1815k\n"
          ]
        }
      ],
      "execution_count": 2
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-9aNLZBDtA5J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5615dac1-4273-403b-c10a-8d335862cd26",
        "ExecuteTime": {
          "end_time": "2025-12-14T00:21:11.124627Z",
          "start_time": "2025-12-14T00:21:11.030350Z"
        }
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# 1. Leer el archivo completo\n",
        "text_file = \"./spa-eng/spa.txt\"\n",
        "with open(text_file) as f:\n",
        "    lines = f.read().split(\"\\n\")[:-1]\n",
        "\n",
        "# Mezclar\n",
        "np.random.seed(42) # Semilla distinta para variar\n",
        "np.random.shuffle(lines)\n",
        "\n",
        "print(f\"Total de frases disponibles: {len(lines)}\")\n",
        "\n",
        "# 2. Separar pares crudos (sin tokenizar aún)\n",
        "input_sentences = []         # Inglés (Encoder Input)\n",
        "output_sentences = []        # Español con <eos> (Decoder Target)\n",
        "output_sentences_inputs = [] # Español con <sos> (Decoder Input)\n",
        "\n",
        "for line in lines:\n",
        "    if '\\t' not in line: continue\n",
        "\n",
        "    eng, spa = line.rstrip().split('\\t')\n",
        "\n",
        "    input_sentences.append(eng)\n",
        "    # Preparamos los strings con sus etiquetas\n",
        "    output_sentences.append(spa + ' <eos>')\n",
        "    output_sentences_inputs.append('<sos> ' + spa)\n",
        "\n",
        "# 3. Dividir en Train y Validation (80/20) AHORA, sobre los strings\n",
        "# Esto es mucho más rápido y liviano que dividir matrices\n",
        "data_train, data_val = train_test_split(\n",
        "    list(zip(input_sentences, output_sentences_inputs, output_sentences)),\n",
        "    test_size=0.2,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Desempaquetar\n",
        "input_train = [x[0] for x in data_train]\n",
        "dec_input_train = [x[1] for x in data_train]\n",
        "dec_target_train = [x[2] for x in data_train]\n",
        "\n",
        "input_val = [x[0] for x in data_val]\n",
        "dec_input_val = [x[1] for x in data_val]\n",
        "dec_target_val = [x[2] for x in data_val]\n",
        "\n",
        "print(f\"Frases de entrenamiento: {len(input_train)}\")\n",
        "print(f\"Frases de validación: {len(input_val)}\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total de frases disponibles: 118964\n",
            "Frases de entrenamiento: 95171\n",
            "Frases de validación: 23793\n"
          ]
        }
      ],
      "execution_count": 3
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8P-ynUNP5xp6"
      },
      "source": [
        "### 2 - Preprocesamiento"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "# Definir el tamaño máximo del vocabulario\n",
        "MAX_VOCAB_SIZE = 20000\n",
        "# Vamos a necesitar un tokenizador para cada idioma\n",
        "\n",
        "# Tokenizar las palabras con el Tokenizer de Keras\n",
        "# Definir una máxima cantidad de palabras a utilizar:\n",
        "# - num_words --> the maximum number of words to keep, based on word frequency.\n",
        "# - Only the most common num_words-1 words will be kept.\n",
        "\n",
        "# --- TOKENIZER INGLÉS ---\n",
        "input_tokenizer = Tokenizer(num_words=MAX_VOCAB_SIZE)\n",
        "input_tokenizer.fit_on_texts(input_sentences) # Fit sobre TODO el dataset\n",
        "word2idx_inputs = input_tokenizer.word_index\n",
        "print(\"Vocabulario Inglés:\", len(word2idx_inputs))\n",
        "\n",
        "# --- TOKENIZER ESPAÑOL ---\n",
        "output_tokenizer = Tokenizer(num_words=MAX_VOCAB_SIZE, filters='!\"#$%&()*+,-./:;=¿?@[\\\\]^_`{|}~\\t\\n')\n",
        "\n",
        "# Fit sobre inputs y outputs para cubrir <sos>, <eos> y todo el texto\n",
        "output_tokenizer.fit_on_texts(output_sentences + output_sentences_inputs)\n",
        "word2idx_outputs = output_tokenizer.word_index\n",
        "num_words_output = min(MAX_VOCAB_SIZE, len(word2idx_outputs) + 1)\n",
        "print(\"Vocabulario Español:\", len(word2idx_outputs))\n",
        "\n",
        "num_words_output = min(len(word2idx_outputs) + 1, MAX_VOCAB_SIZE)\n",
        "# Se suma 1 para incluir el token de palabra desconocida\n",
        "\n",
        "print(\"Calculando longitudes máximas del dataset...\")\n",
        "\n",
        "# 1. Calculamos la longitud máxima en Inglés (Encoder)\n",
        "# Convertimos todo a secuencias de enteros (es rápido y liviano)\n",
        "all_input_seqs = input_tokenizer.texts_to_sequences(input_sentences)\n",
        "max_input_len = max(len(seq) for seq in all_input_seqs)\n",
        "\n",
        "# 2. Calculamos la longitud máxima en Español (Decoder)\n",
        "# Juntamos inputs y targets para asegurarnos de cubrir el caso más largo\n",
        "all_output_seqs = output_tokenizer.texts_to_sequences(output_sentences + output_sentences_inputs)\n",
        "max_out_len = max(len(seq) for seq in all_output_seqs)\n",
        "\n",
        "print(f\"Max Input Len (Inglés): {max_input_len}\")\n",
        "print(f\"Max Output Len (Español): {max_out_len}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "EK_wY4KUw0EG",
        "outputId": "5baa9485-30f7-4f20-cb52-3d11dd2588d6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "ExecuteTime": {
          "end_time": "2025-12-14T00:21:17.321707Z",
          "start_time": "2025-12-14T00:21:16.706117Z"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulario Inglés: 13524\n",
            "Vocabulario Español: 26341\n",
            "Calculando longitudes máximas del dataset...\n",
            "Max Input Len (Inglés): 47\n",
            "Max Output Len (Español): 50\n"
          ]
        }
      ],
      "execution_count": 4
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import Sequence, pad_sequences\n",
        "import numpy as np\n",
        "\n",
        "class NMTDataGenerator(Sequence):\n",
        "    def __init__(self, input_texts, dec_input_texts, dec_target_texts,\n",
        "                 input_tokenizer, output_tokenizer,\n",
        "                 batch_size, max_input_len, max_out_len, shuffle=True):\n",
        "\n",
        "        self.input_texts = input_texts\n",
        "        self.dec_input_texts = dec_input_texts\n",
        "        self.dec_target_texts = dec_target_texts\n",
        "        self.input_tokenizer = input_tokenizer\n",
        "        self.output_tokenizer = output_tokenizer\n",
        "        self.batch_size = batch_size\n",
        "        self.max_input_len = max_input_len\n",
        "        self.max_out_len = max_out_len\n",
        "        self.shuffle = shuffle\n",
        "        self.indexes = np.arange(len(self.input_texts))\n",
        "\n",
        "        self.on_epoch_end() # Inicializar mezcla\n",
        "\n",
        "    def __len__(self):\n",
        "        # Número de batches por época\n",
        "        return int(np.floor(len(self.input_texts) / self.batch_size))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        # Seleccionar índices del batch actual\n",
        "        indexes = self.indexes[index * self.batch_size:(index + 1) * self.batch_size]\n",
        "\n",
        "        # Obtener los strings correspondientes\n",
        "        batch_input_texts = [self.input_texts[k] for k in indexes]\n",
        "        batch_dec_input_texts = [self.dec_input_texts[k] for k in indexes]\n",
        "        batch_dec_target_texts = [self.dec_target_texts[k] for k in indexes]\n",
        "\n",
        "        # --- TRANSFORMACIÓN ---\n",
        "\n",
        "        # 1. Encoder Inputs\n",
        "        encoder_seq = self.input_tokenizer.texts_to_sequences(batch_input_texts)\n",
        "        encoder_input_data = pad_sequences(encoder_seq, maxlen=self.max_input_len, padding='pre')\n",
        "\n",
        "        # 2. Decoder Inputs\n",
        "        dec_input_seq = self.output_tokenizer.texts_to_sequences(batch_dec_input_texts)\n",
        "        decoder_input_data = pad_sequences(dec_input_seq, maxlen=self.max_out_len, padding='post')\n",
        "\n",
        "        # 3. Decoder Targets\n",
        "        dec_target_seq = self.output_tokenizer.texts_to_sequences(batch_dec_target_texts)\n",
        "        decoder_target_data = pad_sequences(dec_target_seq, maxlen=self.max_out_len, padding='post')\n",
        "\n",
        "        # CAMBIO AQUÍ: Usamos una TUPLA (...) en lugar de lista [...] para los inputs\n",
        "        return (encoder_input_data, decoder_input_data), decoder_target_data\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        # Mezclar índices al final de cada época\n",
        "        if self.shuffle:\n",
        "            np.random.shuffle(self.indexes)"
      ],
      "metadata": {
        "id": "fWP1pfNI29cM"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_CJIsLBbj6rg"
      },
      "source": [
        "#### 3 - Preparar los embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jlnzm7oOuC4z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d417c36-4822-4cc3-e79f-142ca8208bda",
        "ExecuteTime": {
          "end_time": "2025-12-14T00:21:22.848169Z",
          "start_time": "2025-12-14T00:21:22.844280Z"
        }
      },
      "source": [
        "import os\n",
        "\n",
        "if not os.access('cc.en.300.vec.gz', os.F_OK):\n",
        "    !curl -o cc.en.300.vec.gz https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.en.300.vec.gz\n",
        "if not os.access('cc.en.300.vec', os.F_OK):\n",
        "    !gunzip cc.en.300.vec.gz\n",
        "\n",
        "if not os.access('cc.es.300.vec.gz', os.F_OK):\n",
        "    !curl -o cc.es.300.vec.gz https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.es.300.vec.gz\n",
        "if not os.access('cc.es.300.vec', os.F_OK):\n",
        "    !gunzip cc.es.300.vec.gz\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 1264M  100 1264M    0     0   146M      0  0:00:08  0:00:08 --:--:--  129M\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 1226M  100 1226M    0     0   169M      0  0:00:07  0:00:07 --:--:--  178M\n"
          ]
        }
      ],
      "execution_count": 6
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZgqtV8GpkSc8",
        "ExecuteTime": {
          "end_time": "2025-12-14T00:21:27.526098Z",
          "start_time": "2025-12-14T00:21:27.364300Z"
        }
      },
      "source": [
        "import logging\n",
        "import os\n",
        "from pathlib import Path\n",
        "from io import StringIO\n",
        "import pickle\n",
        "\n",
        "class WordsEmbeddings(object):\n",
        "    logger = logging.getLogger(__name__)\n",
        "\n",
        "    def __init__(self):\n",
        "        # load the embeddings\n",
        "        words_embedding_pkl = Path(self.PKL_PATH)\n",
        "        if not words_embedding_pkl.is_file():\n",
        "            words_embedding_txt = Path(self.WORD_TO_VEC_MODEL_TXT_PATH)\n",
        "            assert words_embedding_txt.is_file(), 'Words embedding not available'\n",
        "            embeddings = self.convert_model_to_pickle()\n",
        "        else:\n",
        "            embeddings = self.load_model_from_pickle()\n",
        "        self.embeddings = embeddings\n",
        "        # build the vocabulary hashmap\n",
        "        index = np.arange(self.embeddings.shape[0])\n",
        "        # Dicctionarios para traducir de embedding a IDX de la palabra\n",
        "        self.word2idx = dict(zip(self.embeddings['word'], index))\n",
        "        self.idx2word = dict(zip(index, self.embeddings['word']))\n",
        "\n",
        "    def get_words_embeddings(self, words):\n",
        "        words_idxs = self.words2idxs(words)\n",
        "        return self.embeddings[words_idxs]['embedding']\n",
        "\n",
        "    def words2idxs(self, words):\n",
        "        return np.array([self.word2idx.get(word, -1) for word in words])\n",
        "\n",
        "    def idxs2words(self, idxs):\n",
        "        return np.array([self.idx2word.get(idx, '-1') for idx in idxs])\n",
        "\n",
        "    def load_model_from_pickle(self):\n",
        "        self.logger.debug(\n",
        "            'loading words embeddings from pickle {}'.format(\n",
        "                self.PKL_PATH\n",
        "            )\n",
        "        )\n",
        "        max_bytes = 2**28 - 1 # 256MB\n",
        "        bytes_in = bytearray(0)\n",
        "        input_size = os.path.getsize(self.PKL_PATH)\n",
        "        with open(self.PKL_PATH, 'rb') as f_in:\n",
        "            for _ in range(0, input_size, max_bytes):\n",
        "                bytes_in += f_in.read(max_bytes)\n",
        "        embeddings = pickle.loads(bytes_in)\n",
        "        self.logger.debug('words embeddings loaded')\n",
        "        return embeddings\n",
        "\n",
        "    def convert_model_to_pickle(self):\n",
        "        # create a numpy strctured array:\n",
        "        # word     embedding\n",
        "        # U50      np.float32[]\n",
        "        # word_1   a, b, c\n",
        "        # word_2   d, e, f\n",
        "        # ...\n",
        "        # word_n   g, h, i\n",
        "        self.logger.debug(\n",
        "            'converting and loading words embeddings from text file {}'.format(\n",
        "                self.WORD_TO_VEC_MODEL_TXT_PATH\n",
        "            )\n",
        "        )\n",
        "        structure = [('word', np.dtype('U' + str(self.WORD_MAX_SIZE))),\n",
        "                     ('embedding', np.float32, (self.N_FEATURES,))]\n",
        "        structure = np.dtype(structure)\n",
        "        # load numpy array from disk using a generator\n",
        "        with open(self.WORD_TO_VEC_MODEL_TXT_PATH, encoding=\"utf8\") as words_embeddings_txt:\n",
        "            embeddings_gen = (\n",
        "                (line.split()[0], line.split()[1:]) for line in words_embeddings_txt\n",
        "                if len(line.split()[1:]) == self.N_FEATURES\n",
        "            )\n",
        "            embeddings = np.fromiter(embeddings_gen, structure)\n",
        "        # add a null embedding\n",
        "        null_embedding = np.array(\n",
        "            [('null_embedding', np.zeros((self.N_FEATURES,), dtype=np.float32))],\n",
        "            dtype=structure\n",
        "        )\n",
        "        embeddings = np.concatenate([embeddings, null_embedding])\n",
        "        # dump numpy array to disk using pickle\n",
        "        max_bytes = 2**28 - 1 # # 256MB\n",
        "        bytes_out = pickle.dumps(embeddings, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "        with open(self.PKL_PATH, 'wb') as f_out:\n",
        "            for idx in range(0, len(bytes_out), max_bytes):\n",
        "                f_out.write(bytes_out[idx:idx+max_bytes])\n",
        "        self.logger.debug('words embeddings loaded')\n",
        "        return embeddings\n",
        "\n",
        "\n",
        "class GloveEmbeddings(WordsEmbeddings):\n",
        "    WORD_TO_VEC_MODEL_TXT_PATH = 'glove.twitter.27B.50d.txt'\n",
        "    PKL_PATH = 'gloveembedding.pkl'\n",
        "    N_FEATURES = 50\n",
        "    WORD_MAX_SIZE = 60\n",
        "\n",
        "class FasttextEmbeddingsEN(WordsEmbeddings):\n",
        "    WORD_TO_VEC_MODEL_TXT_PATH = 'cc.en.300.vec'\n",
        "    PKL_PATH = 'fasttext_en.pkl'\n",
        "    N_FEATURES = 300\n",
        "    WORD_MAX_SIZE = 60\n",
        "\n",
        "class FasttextEmbeddingsES(WordsEmbeddings):\n",
        "    WORD_TO_VEC_MODEL_TXT_PATH = 'cc.es.300.vec'\n",
        "    PKL_PATH = 'fasttext_es.pkl'\n",
        "    N_FEATURES = 300\n",
        "    WORD_MAX_SIZE = 60\n",
        "\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": 7
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mosj2-x-kXBK",
        "ExecuteTime": {
          "end_time": "2025-12-14T00:21:49.444320Z",
          "start_time": "2025-12-14T00:21:35.295413Z"
        }
      },
      "source": [
        "model_embeddings_en = FasttextEmbeddingsEN()\n",
        "model_embeddings_es = FasttextEmbeddingsES()\n"
      ],
      "outputs": [],
      "execution_count": 8
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b9FS8ca1ke_B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "305b8649-1480-47e1-acae-78692dc45045",
        "ExecuteTime": {
          "end_time": "2025-12-14T00:24:27.371432Z",
          "start_time": "2025-12-14T00:24:27.326959Z"
        }
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "def create_embedding_matrix(word_index, embedding_model, max_vocab_size):\n",
        "    \"\"\"\n",
        "    Crea una matriz de embeddings a partir de un diccionario de palabras y un modelo de embeddings.\n",
        "\n",
        "    Args:\n",
        "        word_index (dict): Diccionario {palabra: indice} del tokenizador.\n",
        "        embedding_model (object): Instancia del modelo de embeddings (ej. FasttextEmbeddingsEN).\n",
        "        max_vocab_size (int): Tamaño máximo del vocabulario permitido.\n",
        "\n",
        "    Returns:\n",
        "        np.array: Matriz de embeddings de dimensiones (nb_words, embed_dim).\n",
        "    \"\"\"\n",
        "    print('Preparing embedding matrix...')\n",
        "\n",
        "    # Obtener dimensión de los vectores del modelo\n",
        "    embed_dim = embedding_model.N_FEATURES\n",
        "\n",
        "    # Definir el tamaño del vocabulario (cota superior)\n",
        "    # Nota: Se usa len(word_index) + 1 para asegurar cobertura si los índices empiezan en 1\n",
        "    nb_words = min(max_vocab_size, len(word_index) + 1)\n",
        "\n",
        "    # Inicializar matriz con ceros\n",
        "    embedding_matrix = np.zeros((nb_words, embed_dim))\n",
        "\n",
        "    words_not_found = []\n",
        "\n",
        "    for word, i in word_index.items():\n",
        "        # Si el índice supera el tamaño máximo definido, lo ignoramos\n",
        "        if i >= nb_words:\n",
        "            continue\n",
        "\n",
        "        # Obtener el vector del modelo\n",
        "        # Nota: Asumimos que get_words_embeddings devuelve una lista/array, tomamos el [0]\n",
        "        embedding_vector = embedding_model.get_words_embeddings([word])[0]\n",
        "\n",
        "        if (embedding_vector is not None) and len(embedding_vector) > 0:\n",
        "            embedding_matrix[i] = embedding_vector\n",
        "        else:\n",
        "            words_not_found.append(word)\n",
        "\n",
        "    # Reporte de palabras nulas (vectores de ceros)\n",
        "    null_count = np.sum(np.sum(embedding_matrix**2, axis=1) == 0)\n",
        "    print(f'Number of null word embeddings: {null_count}')\n",
        "    print(embedding_matrix.shape)\n",
        "    return embedding_matrix\n",
        "\n",
        "print(\"Crear matriz para Inglés (Encoder)\")\n",
        "embedding_matrix_en = create_embedding_matrix(\n",
        "    word_index=word2idx_inputs,\n",
        "    embedding_model=model_embeddings_en,\n",
        "    max_vocab_size=MAX_VOCAB_SIZE\n",
        ")\n",
        "\n",
        "print(\"Crear matriz para Español (Decoder)\")\n",
        "embedding_matrix_es = create_embedding_matrix(\n",
        "    word_index=word2idx_outputs,\n",
        "    embedding_model=model_embeddings_es,\n",
        "    max_vocab_size=MAX_VOCAB_SIZE\n",
        ")\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Crear matriz para Inglés (Encoder)\n",
            "Preparing embedding matrix...\n",
            "Number of null word embeddings: 473\n",
            "(13525, 300)\n",
            "Crear matriz para Español (Decoder)\n",
            "Preparing embedding matrix...\n",
            "Number of null word embeddings: 524\n",
            "(20000, 300)\n"
          ]
        }
      ],
      "execution_count": 9
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "U0dicIr7zZ9r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3vKbhjtIwPgM"
      },
      "source": [
        "### 4 - Entrenar el modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t_urD1qO2kOx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 512
        },
        "outputId": "d18edf20-1cad-4318-afa3-9850798ba0e2",
        "ExecuteTime": {
          "end_time": "2025-12-14T00:24:56.290772Z",
          "start_time": "2025-12-14T00:24:55.354425Z"
        }
      },
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, LSTM, Dense, Embedding\n",
        "import tensorflow as tf\n",
        "\n",
        "# Asumo que estas variables ya las tenés definidas arriba:\n",
        "# n_units, max_input_len, nb_words, embed_dim, embedding_matrix,\n",
        "# num_words_output, max_out_len\n",
        "\n",
        "n_units = 512\n",
        "DROPOUT=0.4\n",
        "\n",
        "# --- ENCODER ---\n",
        "encoder_inputs = Input(shape=(max_input_len,), name='Encoder_Input')\n",
        "\n",
        "encoder_embedding_layer = Embedding(\n",
        "    input_dim=embedding_matrix_en.shape[0],    # Tamaño del vocabulario de entrada\n",
        "    output_dim=model_embeddings_en.N_FEATURES, # Dimensión del vector denso\n",
        "    weights=[embedding_matrix_en],             # Cargar pesos pre-entrenados\n",
        "    trainable=False,                           # Congelar para no re-entrenar\n",
        "    name='Encoder_Embedding'\n",
        ")\n",
        "\n",
        "encoder_inputs_x = encoder_embedding_layer(encoder_inputs)\n",
        "\n",
        "# LSTM Encoder\n",
        "encoder = LSTM(n_units, return_state=True, dropout=DROPOUT, name='Encoder_LSTM')\n",
        "encoder_outputs, state_h, state_c = encoder(encoder_inputs_x)\n",
        "\n",
        "# Guardamos los estados para pasarlos al decoder (Context Vector)\n",
        "encoder_states = [state_h, state_c]\n",
        "\n",
        "# --- DECODER ---\n",
        "decoder_inputs = Input(shape=(max_out_len,), name='Decoder_Input')\n",
        "\n",
        "decoder_embedding_layer = Embedding(\n",
        "    input_dim=embedding_matrix_es.shape[0],      # Tamaño del vocabulario de salida\n",
        "    output_dim=model_embeddings_es.N_FEATURES,   # Dimensión 300 (FastText)\n",
        "    weights=[embedding_matrix_es],               # Cargar pesos pre-entrenados (Español)\n",
        "    trainable=False,                             # Congelar para no re-entrenar\n",
        "    name='Decoder_Embedding'\n",
        ")\n",
        "\n",
        "decoder_inputs_x = decoder_embedding_layer(decoder_inputs)\n",
        "\n",
        "# LSTM Decoder\n",
        "# return_sequences=True es vital aquí porque queremos la predicción palabra por palabra\n",
        "decoder_lstm = LSTM(n_units, return_sequences=True, return_state=True, dropout=DROPOUT, name='Decoder_LSTM')\n",
        "\n",
        "# Inicializamos el decoder con los estados del encoder\n",
        "decoder_outputs, _, _ = decoder_lstm(decoder_inputs_x, initial_state=encoder_states)\n",
        "\n",
        "# --- SALIDA ---\n",
        "decoder_dense = Dense(num_words_output, activation='softmax', name='Output_Layer')\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "# --- MODELO ---\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs, name='Seq2Seq_Translator')\n",
        "\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer=\"Adam\", metrics=['accuracy'])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "encoder_model = Model(encoder_inputs, encoder_states)\n",
        "\n",
        "# define inference decoder\n",
        "decoder_state_input_h = Input(shape=(n_units,))\n",
        "decoder_state_input_c = Input(shape=(n_units,))\n",
        "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
        "\n",
        "# En cada predicción habrá una sola palabra de entrada al decoder,\n",
        "# que es la realimentación de la palabra anterior\n",
        "# por lo que hay que modificar el input shape de la layer de Embedding\n",
        "decoder_inputs_single = Input(shape=(1,))\n",
        "decoder_inputs_single_x = decoder_embedding_layer(decoder_inputs_single)\n",
        "\n",
        "decoder_outputs, state_h, state_c = decoder_lstm(\n",
        "    decoder_inputs_single_x,\n",
        "    initial_state=decoder_states_inputs\n",
        ")\n",
        "\n",
        "decoder_states = [state_h, state_c]\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "decoder_model = Model(\n",
        "    [decoder_inputs_single] + decoder_states_inputs,\n",
        "    [decoder_outputs] + decoder_states\n",
        ")\n",
        "\n"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"Seq2Seq_Translator\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"Seq2Seq_Translator\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ Encoder_Input       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m47\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ Decoder_Input       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ Encoder_Embedding   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m47\u001b[0m, \u001b[38;5;34m300\u001b[0m)   │  \u001b[38;5;34m4,057,500\u001b[0m │ Encoder_Input[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ Decoder_Embedding   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m300\u001b[0m)   │  \u001b[38;5;34m6,000,000\u001b[0m │ Decoder_Input[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ Encoder_LSTM (\u001b[38;5;33mLSTM\u001b[0m) │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m),     │  \u001b[38;5;34m1,665,024\u001b[0m │ Encoder_Embeddin… │\n",
              "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m),      │            │                   │\n",
              "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)]      │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ Decoder_LSTM (\u001b[38;5;33mLSTM\u001b[0m) │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m512\u001b[0m), │  \u001b[38;5;34m1,665,024\u001b[0m │ Decoder_Embeddin… │\n",
              "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m),      │            │ Encoder_LSTM[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)]      │            │ Encoder_LSTM[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ Output_Layer        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m20000\u001b[0m) │ \u001b[38;5;34m10,260,000\u001b[0m │ Decoder_LSTM[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ Encoder_Input       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">47</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ Decoder_Input       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ Encoder_Embedding   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">47</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)   │  <span style=\"color: #00af00; text-decoration-color: #00af00\">4,057,500</span> │ Encoder_Input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ Decoder_Embedding   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)   │  <span style=\"color: #00af00; text-decoration-color: #00af00\">6,000,000</span> │ Decoder_Input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ Encoder_LSTM (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>) │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>),     │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,665,024</span> │ Encoder_Embeddin… │\n",
              "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>),      │            │                   │\n",
              "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)]      │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ Decoder_LSTM (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>) │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>), │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,665,024</span> │ Decoder_Embeddin… │\n",
              "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>),      │            │ Encoder_LSTM[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)]      │            │ Encoder_LSTM[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ Output_Layer        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20000</span>) │ <span style=\"color: #00af00; text-decoration-color: #00af00\">10,260,000</span> │ Decoder_LSTM[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m23,647,548\u001b[0m (90.21 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">23,647,548</span> (90.21 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m13,590,048\u001b[0m (51.84 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">13,590,048</span> (51.84 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m10,057,500\u001b[0m (38.37 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">10,057,500</span> (38.37 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 14
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-12-14T00:24:40.188655Z",
          "start_time": "2025-12-14T00:24:37.848947Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zNOTeh3bQ0uo",
        "outputId": "31fbfd06-763c-4db7-842f-9c711b0d2f30"
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "import wandb\n",
        "\n",
        "\n",
        "# Intentamos obtener la clave según el entorno\n",
        "try:\n",
        "    # Intenta importar la librería de secretos de Colab\n",
        "    from google.colab import userdata\n",
        "    wandb_api_key = userdata.get('WANDB_KEY')\n",
        "    print(\"📍 Entorno detectado: Google Colab (Usando Secretos)\")\n",
        "\n",
        "except ImportError:\n",
        "    # Si falla, asumimos entorno local y buscamos variable de entorno\n",
        "    # (Asegurate de tener python-dotenv instalado si usas un archivo .env)\n",
        "    wandb_api_key = os.getenv(\"WANDB_KEY\")\n",
        "    print(\"📍 Entorno detectado: Local (Usando variables de entorno)\")\n",
        "\n",
        "\n",
        "# Lógica de login unificada\n",
        "if wandb_api_key:\n",
        "    wandb.login(key=wandb_api_key)\n",
        "    print(\"✅ Login en WANDB exitoso.\")\n",
        "else:\n",
        "    print(\"⚠️ No se detectó clave automática. Iniciando login interactivo...\")\n",
        "    wandb.login()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📍 Entorno detectado: Google Colab (Usando Secretos)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/notebook/notebookapp.py:191: SyntaxWarning: invalid escape sequence '\\/'\n",
            "  | |_| | '_ \\/ _` / _` |  _/ -_)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdiazjoseluis\u001b[0m (\u001b[33mdiazjoseluis-auth0\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Login en WANDB exitoso.\n"
          ]
        }
      ],
      "execution_count": 11
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "# 1. Montar Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# 2. Definir la ruta donde guardaremos el modelo\n",
        "# Puedes cambiar 'Modelos/Traductor' por la carpeta que prefieras en tu Drive\n",
        "save_dir = '/content/drive/MyDrive/Modelos/Traductor'\n",
        "\n",
        "# Crear la carpeta si no existe\n",
        "if not os.path.exists(save_dir):\n",
        "    os.makedirs(save_dir)\n",
        "\n",
        "# Definir la ruta completa del archivo\n",
        "model_filepath = os.path.join(save_dir, 'best_translator_model.keras')\n",
        "\n",
        "print(f\"📍 El modelo se guardará en: {model_filepath}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nlss3vg8xstK",
        "outputId": "2c1d5b36-d5d9-44d6-d805-fbb5ef4786cc"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "📍 El modelo se guardará en: /content/drive/MyDrive/Modelos/Traductor/best_translator_model.keras\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VnlIx1Vezjwc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1c3d4d8c-21c6-478a-b5dd-04206b276c5c",
        "ExecuteTime": {
          "end_time": "2025-12-14T00:25:29.597547Z",
          "start_time": "2025-12-14T00:25:03.200128Z"
        }
      },
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from wandb.integration.keras import WandbMetricsLogger\n",
        "\n",
        "\n",
        "batch_size = 64 # Podemos permitirnos batches más grandes ahora\n",
        "\n",
        "# Generador de Entrenamiento\n",
        "train_gen = NMTDataGenerator(\n",
        "    input_train, dec_input_train, dec_target_train,\n",
        "    input_tokenizer, output_tokenizer,\n",
        "    batch_size=batch_size,\n",
        "    max_input_len=max_input_len,\n",
        "    max_out_len=max_out_len\n",
        ")\n",
        "\n",
        "# Generador de Validación\n",
        "val_gen = NMTDataGenerator(\n",
        "    input_val, dec_input_val, dec_target_val,\n",
        "    input_tokenizer, output_tokenizer,\n",
        "    batch_size=batch_size,\n",
        "    max_input_len=max_input_len,\n",
        "    max_out_len=max_out_len\n",
        ")\n",
        "\n",
        "# Inicializar la run de WANDB\n",
        "run = wandb.init(\n",
        "    project=\"traductor-seq2seq-lstm\", # Ponle el nombre que quieras a tu proyecto\n",
        "    config={\n",
        "        \"epochs\": 100,\n",
        "        \"batch_size\": batch_size,             # El default de Keras es 32 si no lo especificas\n",
        "        \"n_units\": n_units,           # 128\n",
        "        \"embedding_dim\": 300,         # FastText\n",
        "        \"architecture\": \"LSTM + FastText Frozen + sparse + dropout\"\n",
        "    }\n",
        ")\n",
        "\n",
        "\n",
        "checkpoint = ModelCheckpoint(\n",
        "    filepath=model_filepath,\n",
        "    monitor='val_accuracy',\n",
        "    save_best_only=True,\n",
        "    mode='max',\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Configuración del Early Stopping\n",
        "early_stopping = EarlyStopping(\n",
        "    monitor='val_accuracy',      # Miramos la accuracy de validación\n",
        "    patience=5,                  # Esperamos 5 épocas sin mejora antes de cortar\n",
        "    mode='max',                  # Queremos que la métrica suba\n",
        "    restore_best_weights=True,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# 3. Entrenamiento\n",
        "hist = model.fit(\n",
        "    train_gen,                   # Pasamos el generador en vez de arrays\n",
        "    validation_data=val_gen,     # Pasamos el generador de validación\n",
        "    epochs=100,\n",
        "    callbacks=[\n",
        "        WandbMetricsLogger(log_freq=\"batch\"),\n",
        "        early_stopping,\n",
        "        checkpoint\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Cerrar la run al terminar (opcional pero recomendado en notebooks)\n",
        "wandb.finish()"
      ],
      "outputs": [
        {
          "data": {
            "text/html": [
              "Finishing previous runs because reinit is set to 'default'."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>batch/accuracy</td><td>▁▆▆▇▇▇▇▇▇▇▇▇▇▇██████████████████████████</td></tr><tr><td>batch/batch_step</td><td>▁▁▁▁▁▂▃▃▃▃▃▃▃▃▄▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇█████</td></tr><tr><td>batch/learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>batch/loss</td><td>█▅▄▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>batch/accuracy</td><td>0.87968</td></tr><tr><td>batch/batch_step</td><td>828</td></tr><tr><td>batch/learning_rate</td><td>0.001</td></tr><tr><td>batch/loss</td><td>0.92433</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">leafy-terrain-21</strong> at: <a href='https://wandb.ai/diazjoseluis-auth0/traductor-seq2seq-lstm/runs/dism4sg6' target=\"_blank\">https://wandb.ai/diazjoseluis-auth0/traductor-seq2seq-lstm/runs/dism4sg6</a><br> View project at: <a href='https://wandb.ai/diazjoseluis-auth0/traductor-seq2seq-lstm' target=\"_blank\">https://wandb.ai/diazjoseluis-auth0/traductor-seq2seq-lstm</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20251214_035312-dism4sg6/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.23.1"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20251214_035434-s1aqpk0w</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/diazjoseluis-auth0/traductor-seq2seq-lstm/runs/s1aqpk0w' target=\"_blank\">worthy-monkey-22</a></strong> to <a href='https://wandb.ai/diazjoseluis-auth0/traductor-seq2seq-lstm' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/diazjoseluis-auth0/traductor-seq2seq-lstm' target=\"_blank\">https://wandb.ai/diazjoseluis-auth0/traductor-seq2seq-lstm</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/diazjoseluis-auth0/traductor-seq2seq-lstm/runs/s1aqpk0w' target=\"_blank\">https://wandb.ai/diazjoseluis-auth0/traductor-seq2seq-lstm/runs/s1aqpk0w</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m1487/1487\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.8714 - loss: 1.1676\n",
            "Epoch 1: val_accuracy improved from -inf to 0.90308, saving model to /content/drive/MyDrive/Modelos/Traductor/best_translator_model.keras\n",
            "\u001b[1m1487/1487\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 96ms/step - accuracy: 0.8714 - loss: 1.1673 - val_accuracy: 0.9031 - val_loss: 0.6127\n",
            "Epoch 2/100\n",
            "\u001b[1m1487/1487\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.9047 - loss: 0.5780\n",
            "Epoch 2: val_accuracy improved from 0.90308 to 0.91546, saving model to /content/drive/MyDrive/Modelos/Traductor/best_translator_model.keras\n",
            "\u001b[1m1487/1487\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 79ms/step - accuracy: 0.9047 - loss: 0.5780 - val_accuracy: 0.9155 - val_loss: 0.4884\n",
            "Epoch 3/100\n",
            "\u001b[1m1487/1487\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.9161 - loss: 0.4575\n",
            "Epoch 3: val_accuracy improved from 0.91546 to 0.92426, saving model to /content/drive/MyDrive/Modelos/Traductor/best_translator_model.keras\n",
            "\u001b[1m1487/1487\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 79ms/step - accuracy: 0.9161 - loss: 0.4575 - val_accuracy: 0.9243 - val_loss: 0.4162\n",
            "Epoch 4/100\n",
            "\u001b[1m1487/1487\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.9244 - loss: 0.3797\n",
            "Epoch 4: val_accuracy improved from 0.92426 to 0.93023, saving model to /content/drive/MyDrive/Modelos/Traductor/best_translator_model.keras\n",
            "\u001b[1m1487/1487\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 79ms/step - accuracy: 0.9244 - loss: 0.3797 - val_accuracy: 0.9302 - val_loss: 0.3728\n",
            "Epoch 5/100\n",
            "\u001b[1m1487/1487\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.9232 - loss: 0.4036\n",
            "Epoch 5: val_accuracy improved from 0.93023 to 0.93339, saving model to /content/drive/MyDrive/Modelos/Traductor/best_translator_model.keras\n",
            "\u001b[1m1487/1487\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 79ms/step - accuracy: 0.9232 - loss: 0.4036 - val_accuracy: 0.9334 - val_loss: 0.3519\n",
            "Epoch 6/100\n",
            "\u001b[1m1487/1487\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.9352 - loss: 0.2922\n",
            "Epoch 6: val_accuracy improved from 0.93339 to 0.93630, saving model to /content/drive/MyDrive/Modelos/Traductor/best_translator_model.keras\n",
            "\u001b[1m1487/1487\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 79ms/step - accuracy: 0.9352 - loss: 0.2922 - val_accuracy: 0.9363 - val_loss: 0.3344\n",
            "Epoch 7/100\n",
            "\u001b[1m1487/1487\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.9396 - loss: 0.2621\n",
            "Epoch 7: val_accuracy improved from 0.93630 to 0.93817, saving model to /content/drive/MyDrive/Modelos/Traductor/best_translator_model.keras\n",
            "\u001b[1m1487/1487\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 79ms/step - accuracy: 0.9396 - loss: 0.2621 - val_accuracy: 0.9382 - val_loss: 0.3235\n",
            "Epoch 8/100\n",
            "\u001b[1m1487/1487\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.9440 - loss: 0.2370\n",
            "Epoch 8: val_accuracy improved from 0.93817 to 0.93976, saving model to /content/drive/MyDrive/Modelos/Traductor/best_translator_model.keras\n",
            "\u001b[1m1487/1487\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 79ms/step - accuracy: 0.9440 - loss: 0.2370 - val_accuracy: 0.9398 - val_loss: 0.3154\n",
            "Epoch 9/100\n",
            "\u001b[1m1487/1487\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.9476 - loss: 0.2186\n",
            "Epoch 9: val_accuracy improved from 0.93976 to 0.94095, saving model to /content/drive/MyDrive/Modelos/Traductor/best_translator_model.keras\n",
            "\u001b[1m1487/1487\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 79ms/step - accuracy: 0.9476 - loss: 0.2186 - val_accuracy: 0.9410 - val_loss: 0.3110\n",
            "Epoch 10/100\n",
            "\u001b[1m1487/1487\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.9508 - loss: 0.2013\n",
            "Epoch 10: val_accuracy improved from 0.94095 to 0.94199, saving model to /content/drive/MyDrive/Modelos/Traductor/best_translator_model.keras\n",
            "\u001b[1m1487/1487\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 79ms/step - accuracy: 0.9508 - loss: 0.2013 - val_accuracy: 0.9420 - val_loss: 0.3068\n",
            "Epoch 11/100\n",
            "\u001b[1m1487/1487\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.9537 - loss: 0.1864\n",
            "Epoch 11: val_accuracy improved from 0.94199 to 0.94278, saving model to /content/drive/MyDrive/Modelos/Traductor/best_translator_model.keras\n",
            "\u001b[1m1487/1487\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 79ms/step - accuracy: 0.9537 - loss: 0.1864 - val_accuracy: 0.9428 - val_loss: 0.3054\n",
            "Epoch 12/100\n",
            "\u001b[1m1487/1487\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.9560 - loss: 0.1751\n",
            "Epoch 12: val_accuracy improved from 0.94278 to 0.94341, saving model to /content/drive/MyDrive/Modelos/Traductor/best_translator_model.keras\n",
            "\u001b[1m1487/1487\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 79ms/step - accuracy: 0.9560 - loss: 0.1751 - val_accuracy: 0.9434 - val_loss: 0.3038\n",
            "Epoch 13/100\n",
            "\u001b[1m1487/1487\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.9581 - loss: 0.1649\n",
            "Epoch 13: val_accuracy improved from 0.94341 to 0.94394, saving model to /content/drive/MyDrive/Modelos/Traductor/best_translator_model.keras\n",
            "\u001b[1m1487/1487\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 79ms/step - accuracy: 0.9581 - loss: 0.1649 - val_accuracy: 0.9439 - val_loss: 0.3030\n",
            "Epoch 14/100\n",
            "\u001b[1m1487/1487\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.9602 - loss: 0.1555\n",
            "Epoch 14: val_accuracy improved from 0.94394 to 0.94425, saving model to /content/drive/MyDrive/Modelos/Traductor/best_translator_model.keras\n",
            "\u001b[1m1487/1487\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 79ms/step - accuracy: 0.9602 - loss: 0.1555 - val_accuracy: 0.9443 - val_loss: 0.3036\n",
            "Epoch 15/100\n",
            "\u001b[1m1487/1487\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.9618 - loss: 0.1470\n",
            "Epoch 15: val_accuracy improved from 0.94425 to 0.94474, saving model to /content/drive/MyDrive/Modelos/Traductor/best_translator_model.keras\n",
            "\u001b[1m1487/1487\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 79ms/step - accuracy: 0.9618 - loss: 0.1470 - val_accuracy: 0.9447 - val_loss: 0.3036\n",
            "Epoch 16/100\n",
            "\u001b[1m1487/1487\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.9631 - loss: 0.1403\n",
            "Epoch 16: val_accuracy did not improve from 0.94474\n",
            "\u001b[1m1487/1487\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 78ms/step - accuracy: 0.9631 - loss: 0.1403 - val_accuracy: 0.9447 - val_loss: 0.3052\n",
            "Epoch 17/100\n",
            "\u001b[1m1487/1487\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.9645 - loss: 0.1341\n",
            "Epoch 17: val_accuracy improved from 0.94474 to 0.94508, saving model to /content/drive/MyDrive/Modelos/Traductor/best_translator_model.keras\n",
            "\u001b[1m1487/1487\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 79ms/step - accuracy: 0.9645 - loss: 0.1341 - val_accuracy: 0.9451 - val_loss: 0.3058\n",
            "Epoch 18/100\n",
            "\u001b[1m1487/1487\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.9659 - loss: 0.1274\n",
            "Epoch 18: val_accuracy improved from 0.94508 to 0.94521, saving model to /content/drive/MyDrive/Modelos/Traductor/best_translator_model.keras\n",
            "\u001b[1m1487/1487\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 79ms/step - accuracy: 0.9659 - loss: 0.1274 - val_accuracy: 0.9452 - val_loss: 0.3080\n",
            "Epoch 19/100\n",
            "\u001b[1m1487/1487\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.9671 - loss: 0.1226\n",
            "Epoch 19: val_accuracy did not improve from 0.94521\n",
            "\u001b[1m1487/1487\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 78ms/step - accuracy: 0.9671 - loss: 0.1226 - val_accuracy: 0.9452 - val_loss: 0.3103\n",
            "Epoch 20/100\n",
            "\u001b[1m1487/1487\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.9680 - loss: 0.1177\n",
            "Epoch 20: val_accuracy improved from 0.94521 to 0.94530, saving model to /content/drive/MyDrive/Modelos/Traductor/best_translator_model.keras\n",
            "\u001b[1m1487/1487\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 79ms/step - accuracy: 0.9680 - loss: 0.1177 - val_accuracy: 0.9453 - val_loss: 0.3123\n",
            "Epoch 21/100\n",
            "\u001b[1m1487/1487\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.9691 - loss: 0.1129\n",
            "Epoch 21: val_accuracy improved from 0.94530 to 0.94532, saving model to /content/drive/MyDrive/Modelos/Traductor/best_translator_model.keras\n",
            "\u001b[1m1487/1487\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 79ms/step - accuracy: 0.9691 - loss: 0.1129 - val_accuracy: 0.9453 - val_loss: 0.3144\n",
            "Epoch 22/100\n",
            "\u001b[1m1487/1487\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.9702 - loss: 0.1085\n",
            "Epoch 22: val_accuracy improved from 0.94532 to 0.94542, saving model to /content/drive/MyDrive/Modelos/Traductor/best_translator_model.keras\n",
            "\u001b[1m1487/1487\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 79ms/step - accuracy: 0.9702 - loss: 0.1085 - val_accuracy: 0.9454 - val_loss: 0.3161\n",
            "Epoch 23/100\n",
            "\u001b[1m1487/1487\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.9709 - loss: 0.1046\n",
            "Epoch 23: val_accuracy did not improve from 0.94542\n",
            "\u001b[1m1487/1487\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 78ms/step - accuracy: 0.9709 - loss: 0.1046 - val_accuracy: 0.9452 - val_loss: 0.3185\n",
            "Epoch 24/100\n",
            "\u001b[1m1487/1487\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.9719 - loss: 0.1009\n",
            "Epoch 24: val_accuracy did not improve from 0.94542\n",
            "\u001b[1m1487/1487\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 78ms/step - accuracy: 0.9719 - loss: 0.1009 - val_accuracy: 0.9451 - val_loss: 0.3213\n",
            "Epoch 25/100\n",
            "\u001b[1m1487/1487\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.9725 - loss: 0.0977\n",
            "Epoch 25: val_accuracy did not improve from 0.94542\n",
            "\u001b[1m1487/1487\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 78ms/step - accuracy: 0.9725 - loss: 0.0977 - val_accuracy: 0.9453 - val_loss: 0.3237\n",
            "Epoch 26/100\n",
            "\u001b[1m1487/1487\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.9733 - loss: 0.0947\n",
            "Epoch 26: val_accuracy did not improve from 0.94542\n",
            "\u001b[1m1487/1487\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 78ms/step - accuracy: 0.9733 - loss: 0.0947 - val_accuracy: 0.9452 - val_loss: 0.3263\n",
            "Epoch 27/100\n",
            "\u001b[1m1487/1487\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.9738 - loss: 0.0922\n",
            "Epoch 27: val_accuracy did not improve from 0.94542\n",
            "\u001b[1m1487/1487\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 78ms/step - accuracy: 0.9738 - loss: 0.0922 - val_accuracy: 0.9451 - val_loss: 0.3293\n",
            "Epoch 27: early stopping\n",
            "Restoring model weights from the end of the best epoch: 22.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>batch/accuracy</td><td>▁▃▄▅▅▅▄▅▅▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇██████████</td></tr><tr><td>batch/batch_step</td><td>▁▁▁▂▂▃▃▃▃▃▃▄▄▄▄▄▄▄▄▄▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇██</td></tr><tr><td>batch/learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>batch/loss</td><td>█▅▄▃▄▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/accuracy</td><td>▁▃▄▄▄▅▅▆▆▆▆▇▇▇▇▇▇▇▇████████</td></tr><tr><td>epoch/epoch</td><td>▁▁▂▂▂▂▃▃▃▃▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇██</td></tr><tr><td>epoch/learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/loss</td><td>█▅▄▄▄▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/val_accuracy</td><td>▁▃▅▅▆▆▇▇▇▇█████████████████</td></tr><tr><td>epoch/val_loss</td><td>█▅▄▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>batch/accuracy</td><td>0.97276</td></tr><tr><td>batch/batch_step</td><td>40148</td></tr><tr><td>batch/learning_rate</td><td>0.001</td></tr><tr><td>batch/loss</td><td>0.09592</td></tr><tr><td>epoch/accuracy</td><td>0.97276</td></tr><tr><td>epoch/epoch</td><td>26</td></tr><tr><td>epoch/learning_rate</td><td>0.001</td></tr><tr><td>epoch/loss</td><td>0.09592</td></tr><tr><td>epoch/val_accuracy</td><td>0.94514</td></tr><tr><td>epoch/val_loss</td><td>0.32929</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">worthy-monkey-22</strong> at: <a href='https://wandb.ai/diazjoseluis-auth0/traductor-seq2seq-lstm/runs/s1aqpk0w' target=\"_blank\">https://wandb.ai/diazjoseluis-auth0/traductor-seq2seq-lstm/runs/s1aqpk0w</a><br> View project at: <a href='https://wandb.ai/diazjoseluis-auth0/traductor-seq2seq-lstm' target=\"_blank\">https://wandb.ai/diazjoseluis-auth0/traductor-seq2seq-lstm</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20251214_035434-s1aqpk0w/logs</code>"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 15
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OVz1uug_zu2J",
        "ExecuteTime": {
          "end_time": "2025-12-14T00:15:08.064610Z",
          "start_time": "2025-12-14T00:15:07.938281Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "outputId": "152faea5-6728-459d-d399-7f148b61fc47"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Entrenamiento\n",
        "epoch_count = range(1, len(hist.history['accuracy']) + 1)\n",
        "sns.lineplot(x=epoch_count,  y=hist.history['accuracy'], label='train')\n",
        "sns.lineplot(x=epoch_count,  y=hist.history['val_accuracy'], label='valid')\n",
        "plt.show()"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "execution_count": 16
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zbwn0ekDy_s2"
      },
      "source": [
        "### 5 - Inferencia"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "jnkl3mSpsU_7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "286b6e10-b1d0-4967-caf0-e68d2e422e3c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nStep 1:\\nA deal is a deal -> Encoder -> enc(h1,c1)\\n\\nenc(h1,c1) + <sos> -> Decoder -> Un + dec(h1,c1)\\n\\nstep 2:\\ndec(h1,c1) + Un -> Decoder -> trato + dec(h2,c2)\\n\\nstep 3:\\ndec(h2,c2) + trato -> Decoder -> es + dec(h3,c3)\\n\\nstep 4:\\ndec(h3,c3) + es -> Decoder -> un + dec(h4,c4)\\n\\nstep 5:\\ndec(h4,c4) + un -> Decoder -> trato + dec(h5,c5)\\n\\nstep 6:\\ndec(h5,c5) + trato. -> Decoder -> <eos> + dec(h6,c6)\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "'''\n",
        "Step 1:\n",
        "A deal is a deal -> Encoder -> enc(h1,c1)\n",
        "\n",
        "enc(h1,c1) + <sos> -> Decoder -> Un + dec(h1,c1)\n",
        "\n",
        "step 2:\n",
        "dec(h1,c1) + Un -> Decoder -> trato + dec(h2,c2)\n",
        "\n",
        "step 3:\n",
        "dec(h2,c2) + trato -> Decoder -> es + dec(h3,c3)\n",
        "\n",
        "step 4:\n",
        "dec(h3,c3) + es -> Decoder -> un + dec(h4,c4)\n",
        "\n",
        "step 5:\n",
        "dec(h4,c4) + un -> Decoder -> trato + dec(h5,c5)\n",
        "\n",
        "step 6:\n",
        "dec(h5,c5) + trato. -> Decoder -> <eos> + dec(h6,c6)\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "71XeCtfYmOFx"
      },
      "outputs": [],
      "source": [
        "# Armar los conversores de índice a palabra:\n",
        "idx2word_input = {v:k for k, v in word2idx_inputs.items()}\n",
        "idx2word_target = {v:k for k, v in word2idx_outputs.items()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "MlUyp9M6ua2V"
      },
      "outputs": [],
      "source": [
        "def translate_sentence(input_seq):\n",
        "    # Se transforma la sequencia de entrada a los estados \"h\" y \"c\" de la LSTM\n",
        "    # para enviar la primera vez al decoder\n",
        "    states_value = encoder_model.predict(input_seq)\n",
        "\n",
        "    # Se inicializa la secuencia de entrada al decoder como \"<sos>\"\n",
        "    target_seq = np.zeros((1, 1))\n",
        "    target_seq[0, 0] = word2idx_outputs['<sos>']\n",
        "\n",
        "    # Se obtiene el índice que finaliza la inferencia\n",
        "    eos = word2idx_outputs['<eos>']\n",
        "\n",
        "    output_sentence = []\n",
        "    for _ in range(max_out_len):\n",
        "        # Predicción del próximo elemento\n",
        "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
        "        idx = np.argmax(output_tokens[0, 0, :])\n",
        "\n",
        "        # Si es \"end of sentece <eos>\" se acaba\n",
        "        if eos == idx:\n",
        "            break\n",
        "\n",
        "        # Transformar idx a palabra\n",
        "        word = ''\n",
        "        if idx > 0:\n",
        "            word = idx2word_target[idx]\n",
        "            output_sentence.append(word)\n",
        "\n",
        "        # Actualizar los estados dada la última predicción\n",
        "        states_value = [h, c]\n",
        "\n",
        "        # Actualizar secuencia de entrada con la salida (re-alimentación)\n",
        "        target_seq[0, 0] = idx\n",
        "\n",
        "    return ' '.join(output_sentence)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "KYZ1Q_Z_2G4m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "923f0c5e-b032-476f-c7f6-b2dcb944646a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: She was sick\n",
            "Representacion en vector de tokens de ids: [20, 13, 437]\n",
            "Padding del vector: [[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0  20  13 437]]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 175ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 192ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "Response: ella estaba enferma\n"
          ]
        }
      ],
      "source": [
        "input_test = \"She was sick\"\n",
        "print('Input:', input_test)\n",
        "\n",
        "# Convertir a secuencia\n",
        "integer_seq_test = input_tokenizer.texts_to_sequences([input_test])[0]\n",
        "print(\"Representacion en vector de tokens de ids:\", integer_seq_test)\n",
        "\n",
        "if len(integer_seq_test) == 0:\n",
        "    print(\"⚠️ ERROR: La palabra no está en el vocabulario del tokenizador (input_tokenizer).\")\n",
        "else:\n",
        "    # Padding\n",
        "    encoder_sequence_test = pad_sequences([integer_seq_test], maxlen=max_input_len)\n",
        "    print(\"Padding del vector:\", encoder_sequence_test)\n",
        "\n",
        "    # Inferencia\n",
        "    # Asegúrate de haber corrido la celda de 'translate_sentence'\n",
        "    # y la celda de definición de encoder_model/decoder_model de arriba.\n",
        "    translation = translate_sentence(encoder_sequence_test)\n",
        "    print('Response:', translation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "aA5PwLrjLziC",
        "outputId": "fce52324-2909-4306-e8a0-5d6128640daf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: The cat is under the table\n",
            "Representacion en vector de tokens de ids: [1, 366, 7, 426, 1, 389]\n",
            "Padding del vector: [[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   1 366   7 426   1 389]]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "Response: el gato está bajo la mesa\n"
          ]
        }
      ],
      "source": [
        "input_test = \"The cat is under the table\"\n",
        "print('Input:', input_test)\n",
        "\n",
        "# Convertir a secuencia\n",
        "integer_seq_test = input_tokenizer.texts_to_sequences([input_test])[0]\n",
        "print(\"Representacion en vector de tokens de ids:\", integer_seq_test)\n",
        "\n",
        "if len(integer_seq_test) == 0:\n",
        "    print(\"⚠️ ERROR: La palabra no está en el vocabulario del tokenizador (input_tokenizer).\")\n",
        "else:\n",
        "    # Padding\n",
        "    encoder_sequence_test = pad_sequences([integer_seq_test], maxlen=max_input_len)\n",
        "    print(\"Padding del vector:\", encoder_sequence_test)\n",
        "\n",
        "    # Inferencia\n",
        "    # Asegúrate de haber corrido la celda de 'translate_sentence'\n",
        "    # y la celda de definición de encoder_model/decoder_model de arriba.\n",
        "    translation = translate_sentence(encoder_sequence_test)\n",
        "    print('Response:', translation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "_fHBAlC4L4K8",
        "outputId": "ca78a1e2-9c45-4415-c0af-38805ff4ece5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: This morning I ate an orange\n",
            "Representacion en vector de tokens de ids: [16, 215, 2, 400, 65, 1695]\n",
            "Padding del vector: [[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0   16\n",
            "   215    2  400   65 1695]]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "Response: esta mañana me di una comí\n"
          ]
        }
      ],
      "source": [
        "input_test = \"This morning I ate an orange\"\n",
        "print('Input:', input_test)\n",
        "\n",
        "# Convertir a secuencia\n",
        "integer_seq_test = input_tokenizer.texts_to_sequences([input_test])[0]\n",
        "print(\"Representacion en vector de tokens de ids:\", integer_seq_test)\n",
        "\n",
        "if len(integer_seq_test) == 0:\n",
        "    print(\"⚠️ ERROR: La palabra no está en el vocabulario del tokenizador (input_tokenizer).\")\n",
        "else:\n",
        "    # Padding\n",
        "    encoder_sequence_test = pad_sequences([integer_seq_test], maxlen=max_input_len)\n",
        "    print(\"Padding del vector:\", encoder_sequence_test)\n",
        "\n",
        "    # Inferencia\n",
        "    # Asegúrate de haber corrido la celda de 'translate_sentence'\n",
        "    # y la celda de definición de encoder_model/decoder_model de arriba.\n",
        "    translation = translate_sentence(encoder_sequence_test)\n",
        "    print('Response:', translation)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_test = \"life is like a box of chocolates\"\n",
        "print('Input:', input_test)\n",
        "\n",
        "# Convertir a secuencia\n",
        "integer_seq_test = input_tokenizer.texts_to_sequences([input_test])[0]\n",
        "print(\"Representacion en vector de tokens de ids:\", integer_seq_test)\n",
        "\n",
        "if len(integer_seq_test) == 0:\n",
        "    print(\"⚠️ ERROR: La palabra no está en el vocabulario del tokenizador (input_tokenizer).\")\n",
        "else:\n",
        "    # Padding\n",
        "    encoder_sequence_test = pad_sequences([integer_seq_test], maxlen=max_input_len)\n",
        "    print(\"Padding del vector:\", encoder_sequence_test)\n",
        "\n",
        "    # Inferencia\n",
        "    # Asegúrate de haber corrido la celda de 'translate_sentence'\n",
        "    # y la celda de definición de encoder_model/decoder_model de arriba.\n",
        "    translation = translate_sentence(encoder_sequence_test)\n",
        "    print('Response:', translation)"
      ],
      "metadata": {
        "id": "qfsa37_YMSmT",
        "outputId": "c60e2375-eb5a-435f-fa46-88e897e43552",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: life is like a box of chocolates\n",
            "Representacion en vector de tokens de ids: [206, 7, 35, 6, 540, 10, 4403]\n",
            "Padding del vector: [[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0  206    7\n",
            "    35    6  540   10 4403]]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "Response: la vida es como una caja de jabón\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_test = \"How much is too much?\"\n",
        "print('Input:', input_test)\n",
        "\n",
        "# Convertir a secuencia\n",
        "integer_seq_test = input_tokenizer.texts_to_sequences([input_test])[0]\n",
        "print(\"Representacion en vector de tokens de ids:\", integer_seq_test)\n",
        "\n",
        "if len(integer_seq_test) == 0:\n",
        "    print(\"⚠️ ERROR: La palabra no está en el vocabulario del tokenizador (input_tokenizer).\")\n",
        "else:\n",
        "    # Padding\n",
        "    encoder_sequence_test = pad_sequences([integer_seq_test], maxlen=max_input_len)\n",
        "    print(\"Padding del vector:\", encoder_sequence_test)\n",
        "\n",
        "    # Inferencia\n",
        "    # Asegúrate de haber corrido la celda de 'translate_sentence'\n",
        "    # y la celda de definición de encoder_model/decoder_model de arriba.\n",
        "    translation = translate_sentence(encoder_sequence_test)\n",
        "    print('Response:', translation)"
      ],
      "metadata": {
        "id": "OuWWXELEMvYi",
        "outputId": "225bb2c0-e416-43b3-9232-d8231089d2dc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: How much is too much?\n",
            "Representacion en vector de tokens de ids: [47, 101, 7, 95, 101]\n",
            "Padding del vector: [[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0  47 101   7  95 101]]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
            "Response: cuánto es demasiado\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZSy0kaSKuC4-"
      },
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "vscode": {
      "interpreter": {
        "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}