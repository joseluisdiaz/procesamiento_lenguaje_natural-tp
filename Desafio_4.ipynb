{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pfa39F4lsLf3"
   },
   "source": [
    "<img src=\"https://github.com/hernancontigiani/ceia_memorias_especializacion/raw/master/Figures/logoFIUBA.jpg\" width=\"500\" align=\"center\">\n",
    "\n",
    "\n",
    "# Procesamiento de lenguaje natural\n",
    "## LSTM Traductor\n",
    "Ejemplo basado en [LINK](https://stackabuse.com/python-for-nlp-neural-machine-translation-with-seq2seq-in-keras/)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "cq3YXak9sGHd",
    "ExecuteTime": {
     "end_time": "2025-12-12T14:40:31.173334Z",
     "start_time": "2025-12-12T14:40:29.695748Z"
    }
   },
   "source": [
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import one_hot\n",
    "from tensorflow.keras.utils import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Activation, Dropout, Dense\n",
    "from tensorflow.keras.layers import Flatten, LSTM, SimpleRNN\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.layers import Input\n",
    "from keras.utils import plot_model"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-12 14:40:29.892220: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "RHNkUaPp6aYq",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "d75f6c71-12a3-4314-e8f3-ff74c0440259",
    "ExecuteTime": {
     "end_time": "2025-12-12T14:40:34.960179Z",
     "start_time": "2025-12-12T14:40:34.245264Z"
    }
   },
   "source": [
    "# Descargar la carpeta de dataset\n",
    "\n",
    "import os\n",
    "if os.access('spa-eng', os.F_OK) is False:\n",
    "    if os.access('spa-eng.zip', os.F_OK) is False:\n",
    "        !curl -L -o 'spa-eng.zip' 'http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip'\n",
    "    !unzip -q spa-eng.zip\n",
    "else:\n",
    "    print(\"El dataset ya se encuentra descargado\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\r\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\r\n",
      "100 2576k  100 2576k    0     0  6227k      0 --:--:-- --:--:-- --:--:-- 6239k\r\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "-9aNLZBDtA5J",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "e32597c0-65fc-4829-9594-2966ce514099",
    "ExecuteTime": {
     "end_time": "2025-12-12T14:40:36.761027Z",
     "start_time": "2025-12-12T14:40:36.680505Z"
    }
   },
   "source": [
    "# dataset_file\n",
    "\n",
    "text_file = \"./spa-eng/spa.txt\"\n",
    "with open(text_file) as f:\n",
    "    lines = f.read().split(\"\\n\")[:-1]\n",
    "\n",
    "# Por limitaciones de RAM no se leen todas las filas\n",
    "MAX_NUM_SENTENCES = 6000\n",
    "\n",
    "# Mezclar el dataset, forzar semilla siempre igual\n",
    "np.random.seed([40])\n",
    "np.random.shuffle(lines)\n",
    "\n",
    "input_sentences = []\n",
    "output_sentences = []\n",
    "output_sentences_inputs = []\n",
    "count = 0\n",
    "\n",
    "for line in lines:\n",
    "    count += 1\n",
    "    if count > MAX_NUM_SENTENCES:\n",
    "        break\n",
    "\n",
    "    # el tabulador señaliza la separación entre las oraciones\n",
    "    # en ambos idiomas\n",
    "    if '\\t' not in line:\n",
    "        continue\n",
    "\n",
    "    # Input sentence --> eng\n",
    "    # output --> spa\n",
    "    input_sentence, output = line.rstrip().split('\\t')\n",
    "\n",
    "    # output sentence (decoder_output) tiene <eos>\n",
    "    output_sentence = output + ' <eos>'\n",
    "    # output sentence input (decoder_input) tiene <sos>\n",
    "    output_sentence_input = '<sos> ' + output\n",
    "\n",
    "    input_sentences.append(input_sentence)\n",
    "    output_sentences.append(output_sentence)\n",
    "    output_sentences_inputs.append(output_sentence_input)\n",
    "\n",
    "print(\"Cantidad de rows disponibles:\", len(lines))\n",
    "print(\"Cantidad de rows utilizadas:\", len(input_sentences))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de rows disponibles: 118964\n",
      "Cantidad de rows utilizadas: 6000\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8P-ynUNP5xp6"
   },
   "source": [
    "### 2 - Preprocesamiento"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Definir el tamaño máximo del vocabulario\n",
    "MAX_VOCAB_SIZE = 8000\n",
    "# Vamos a necesitar un tokenizador para cada idioma\n",
    "\n",
    "# Tokenizar las palabras con el Tokenizer de Keras\n",
    "# Definir una máxima cantidad de palabras a utilizar:\n",
    "# - num_words --> the maximum number of words to keep, based on word frequency.\n",
    "# - Only the most common num_words-1 words will be kept.\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "# tokenizador de inglés\n",
    "input_tokenizer = Tokenizer(num_words=MAX_VOCAB_SIZE)\n",
    "input_tokenizer.fit_on_texts(input_sentences)\n",
    "input_integer_seq = input_tokenizer.texts_to_sequences(input_sentences)\n",
    "\n",
    "word2idx_inputs = input_tokenizer.word_index\n",
    "print(\"Palabras en el vocabulario:\", len(word2idx_inputs))\n",
    "\n",
    "max_input_len = max(len(sen) for sen in input_integer_seq)\n",
    "print(\"Sentencia de entrada más larga:\", max_input_len)\n",
    "# tokenizador de español\n",
    "# A los filtros de símbolos del Tokenizer agregamos el \"¿\",\n",
    "# sacamos los \"<>\" para que no afectar nuestros tokens\n",
    "output_tokenizer = Tokenizer(num_words=MAX_VOCAB_SIZE, filters='!\"#$%&()*+,-./:;=¿?@[\\\\]^_`{|}~\\t\\n')\n",
    "output_tokenizer.fit_on_texts([\"<sos>\", \"<eos>\"] + output_sentences)\n",
    "output_integer_seq = output_tokenizer.texts_to_sequences(output_sentences)\n",
    "output_input_integer_seq = output_tokenizer.texts_to_sequences(output_sentences_inputs)\n",
    "\n",
    "word2idx_outputs = output_tokenizer.word_index\n",
    "print(\"Palabras en el vocabulario:\", len(word2idx_outputs))\n",
    "\n",
    "num_words_output = min(len(word2idx_outputs) + 1, MAX_VOCAB_SIZE)\n",
    "# Se suma 1 para incluir el token de palabra desconocida\n",
    "\n",
    "max_out_len = max(len(sen) for sen in output_integer_seq)\n",
    "print(\"Sentencia de salida más larga:\", max_out_len)\n",
    "\n",
    "# Por una cuestion de que no explote la RAM se limitará el tamaño de las sentencias de entrada\n",
    "# a la mitad:\n",
    "max_input_len = 16\n",
    "max_out_len = 18\n",
    "\n",
    "print(\"Cantidad de rows del dataset:\", len(input_integer_seq))\n",
    "\n",
    "encoder_input_sequences = pad_sequences(input_integer_seq, maxlen=max_input_len)\n",
    "print(\"encoder_input_sequences shape:\", encoder_input_sequences.shape)\n",
    "\n",
    "decoder_input_sequences = pad_sequences(output_input_integer_seq, maxlen=max_out_len, padding='post')\n",
    "print(\"decoder_input_sequences shape:\", decoder_input_sequences.shape)\n",
    "\n",
    "#La última capa del modelo (softmax) necesita que los valores de salida del decoder (decoder_sequences) estén en formato oneHotEncoder.\n",
    "# Se utiliza \"decoder_output_sequences\" con la misma estrategia con que se transformó la entrada del decoder.\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "decoder_output_sequences = pad_sequences(output_integer_seq, maxlen=max_out_len, padding='post')\n",
    "decoder_targets = to_categorical(decoder_output_sequences, num_classes=num_words_output)\n",
    "decoder_targets.shape"
   ],
   "metadata": {
    "id": "EK_wY4KUw0EG",
    "outputId": "b10b5490-c491-4c87-dfd8-99d2a233923f",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 216
    },
    "ExecuteTime": {
     "end_time": "2025-12-12T14:40:42.946738Z",
     "start_time": "2025-12-12T14:40:42.479958Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Palabras en el vocabulario: 3851\n",
      "Sentencia de entrada más larga: 32\n",
      "Palabras en el vocabulario: 5721\n",
      "Sentencia de salida más larga: 36\n",
      "Cantidad de rows del dataset: 6000\n",
      "encoder_input_sequences shape: (6000, 16)\n",
      "decoder_input_sequences shape: (6000, 18)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(6000, 18, 5722)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_CJIsLBbj6rg"
   },
   "source": "#### 3 - Preparar los embeddings"
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Jlnzm7oOuC4z",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "74d7f7d8-dfe6-4861-f8a2-c4e36d54835a",
    "ExecuteTime": {
     "end_time": "2025-12-12T14:40:49.101661Z",
     "start_time": "2025-12-12T14:40:49.098334Z"
    }
   },
   "source": [
    "# Descargar los embeddings desde un google drive (es la forma más rápida)\n",
    "# NOTA: No hay garantía de que estos links perduren, en caso de que no estén\n",
    "# disponibles descargar de la página oficial como se explica en el siguiente bloque de código\n",
    "import os\n",
    "import gdown\n",
    "if os.access('gloveembedding.pkl', os.F_OK) is False:\n",
    "    url = 'https://drive.google.com/uc?id=1KY6avD5I1eI2dxQzMkR3WExwKwRq2g94&export=download'\n",
    "    output = 'gloveembedding.pkl'\n",
    "    gdown.download(url, output, quiet=False)\n",
    "else:\n",
    "    print(\"Los embeddings gloveembedding.pkl ya están descargados\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Los embeddings gloveembedding.pkl ya están descargados\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "ZgqtV8GpkSc8",
    "ExecuteTime": {
     "end_time": "2025-12-12T14:40:50.872061Z",
     "start_time": "2025-12-12T14:40:50.861796Z"
    }
   },
   "source": [
    "import logging\n",
    "import os\n",
    "from pathlib import Path\n",
    "from io import StringIO\n",
    "import pickle\n",
    "\n",
    "class WordsEmbeddings(object):\n",
    "    logger = logging.getLogger(__name__)\n",
    "\n",
    "    def __init__(self):\n",
    "        # load the embeddings\n",
    "        words_embedding_pkl = Path(self.PKL_PATH)\n",
    "        if not words_embedding_pkl.is_file():\n",
    "            words_embedding_txt = Path(self.WORD_TO_VEC_MODEL_TXT_PATH)\n",
    "            assert words_embedding_txt.is_file(), 'Words embedding not available'\n",
    "            embeddings = self.convert_model_to_pickle()\n",
    "        else:\n",
    "            embeddings = self.load_model_from_pickle()\n",
    "        self.embeddings = embeddings\n",
    "        # build the vocabulary hashmap\n",
    "        index = np.arange(self.embeddings.shape[0])\n",
    "        # Dicctionarios para traducir de embedding a IDX de la palabra\n",
    "        self.word2idx = dict(zip(self.embeddings['word'], index))\n",
    "        self.idx2word = dict(zip(index, self.embeddings['word']))\n",
    "\n",
    "    def get_words_embeddings(self, words):\n",
    "        words_idxs = self.words2idxs(words)\n",
    "        return self.embeddings[words_idxs]['embedding']\n",
    "\n",
    "    def words2idxs(self, words):\n",
    "        return np.array([self.word2idx.get(word, -1) for word in words])\n",
    "\n",
    "    def idxs2words(self, idxs):\n",
    "        return np.array([self.idx2word.get(idx, '-1') for idx in idxs])\n",
    "\n",
    "    def load_model_from_pickle(self):\n",
    "        self.logger.debug(\n",
    "            'loading words embeddings from pickle {}'.format(\n",
    "                self.PKL_PATH\n",
    "            )\n",
    "        )\n",
    "        max_bytes = 2**28 - 1 # 256MB\n",
    "        bytes_in = bytearray(0)\n",
    "        input_size = os.path.getsize(self.PKL_PATH)\n",
    "        with open(self.PKL_PATH, 'rb') as f_in:\n",
    "            for _ in range(0, input_size, max_bytes):\n",
    "                bytes_in += f_in.read(max_bytes)\n",
    "        embeddings = pickle.loads(bytes_in)\n",
    "        self.logger.debug('words embeddings loaded')\n",
    "        return embeddings\n",
    "\n",
    "    def convert_model_to_pickle(self):\n",
    "        # create a numpy strctured array:\n",
    "        # word     embedding\n",
    "        # U50      np.float32[]\n",
    "        # word_1   a, b, c\n",
    "        # word_2   d, e, f\n",
    "        # ...\n",
    "        # word_n   g, h, i\n",
    "        self.logger.debug(\n",
    "            'converting and loading words embeddings from text file {}'.format(\n",
    "                self.WORD_TO_VEC_MODEL_TXT_PATH\n",
    "            )\n",
    "        )\n",
    "        structure = [('word', np.dtype('U' + str(self.WORD_MAX_SIZE))),\n",
    "                     ('embedding', np.float32, (self.N_FEATURES,))]\n",
    "        structure = np.dtype(structure)\n",
    "        # load numpy array from disk using a generator\n",
    "        with open(self.WORD_TO_VEC_MODEL_TXT_PATH, encoding=\"utf8\") as words_embeddings_txt:\n",
    "            embeddings_gen = (\n",
    "                (line.split()[0], line.split()[1:]) for line in words_embeddings_txt\n",
    "                if len(line.split()[1:]) == self.N_FEATURES\n",
    "            )\n",
    "            embeddings = np.fromiter(embeddings_gen, structure)\n",
    "        # add a null embedding\n",
    "        null_embedding = np.array(\n",
    "            [('null_embedding', np.zeros((self.N_FEATURES,), dtype=np.float32))],\n",
    "            dtype=structure\n",
    "        )\n",
    "        embeddings = np.concatenate([embeddings, null_embedding])\n",
    "        # dump numpy array to disk using pickle\n",
    "        max_bytes = 2**28 - 1 # # 256MB\n",
    "        bytes_out = pickle.dumps(embeddings, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "        with open(self.PKL_PATH, 'wb') as f_out:\n",
    "            for idx in range(0, len(bytes_out), max_bytes):\n",
    "                f_out.write(bytes_out[idx:idx+max_bytes])\n",
    "        self.logger.debug('words embeddings loaded')\n",
    "        return embeddings\n",
    "\n",
    "\n",
    "class GloveEmbeddings(WordsEmbeddings):\n",
    "    WORD_TO_VEC_MODEL_TXT_PATH = 'glove.twitter.27B.50d.txt'\n",
    "    PKL_PATH = 'gloveembedding.pkl'\n",
    "    N_FEATURES = 50\n",
    "    WORD_MAX_SIZE = 60\n",
    "\n",
    "class FasttextEmbeddings(WordsEmbeddings):\n",
    "    WORD_TO_VEC_MODEL_TXT_PATH = 'cc.en.300.vec'\n",
    "    PKL_PATH = 'fasttext.pkl'\n",
    "    N_FEATURES = 300\n",
    "    WORD_MAX_SIZE = 60"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Mosj2-x-kXBK",
    "ExecuteTime": {
     "end_time": "2025-12-12T14:41:08.337193Z",
     "start_time": "2025-12-12T14:41:06.560055Z"
    }
   },
   "source": [
    "# Por una cuestion de RAM se utilizarán los embeddings de Glove de dimension 50\n",
    "model_embeddings = GloveEmbeddings()"
   ],
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "b9FS8ca1ke_B",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "4e21f33e-2137-4742-ca79-2ca2e367136b",
    "ExecuteTime": {
     "end_time": "2025-12-12T14:41:11.697391Z",
     "start_time": "2025-12-12T14:41:11.680221Z"
    }
   },
   "source": [
    "# Crear la Embedding matrix de las secuencias\n",
    "# en inglés\n",
    "\n",
    "print('preparing embedding matrix...')\n",
    "embed_dim = model_embeddings.N_FEATURES\n",
    "words_not_found = []\n",
    "\n",
    "# word_index provieen del tokenizer\n",
    "\n",
    "nb_words = min(MAX_VOCAB_SIZE, len(word2idx_inputs)) # vocab_size\n",
    "embedding_matrix = np.zeros((nb_words, embed_dim))\n",
    "for word, i in word2idx_inputs.items():\n",
    "    if i >= nb_words:\n",
    "        continue\n",
    "    embedding_vector = model_embeddings.get_words_embeddings(word)[0]\n",
    "    if (embedding_vector is not None) and len(embedding_vector) > 0:\n",
    "\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "    else:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        words_not_found.append(word)\n",
    "\n",
    "print('number of null word embeddings:', np.sum(np.sum(embedding_matrix**2, axis=1) == 0))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preparing embedding matrix...\n",
      "number of null word embeddings: 30\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "FpzJODHBlAtE",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "568f29d1-5f19-4fd6-982a-2344931f62d8",
    "ExecuteTime": {
     "end_time": "2025-12-12T14:41:15.077366Z",
     "start_time": "2025-12-12T14:41:15.072416Z"
    }
   },
   "source": [
    "# Dimensión de los embeddings de la secuencia en inglés\n",
    "embedding_matrix.shape"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3851, 50)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3vKbhjtIwPgM"
   },
   "source": [
    "### 4 - Entrenar el modelo"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "3fm3HCLMPSG-",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "8e00e285-4c00-4640-fc59-cc0e8eab3d3c",
    "ExecuteTime": {
     "end_time": "2025-12-12T14:41:16.984498Z",
     "start_time": "2025-12-12T14:41:16.981463Z"
    }
   },
   "source": [
    "max_input_len"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "t_urD1qO2kOx",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 512
    },
    "outputId": "45a0ee72-cf5d-4de6-ebf7-cdad0715ab2e",
    "ExecuteTime": {
     "end_time": "2025-12-12T14:41:19.955833Z",
     "start_time": "2025-12-12T14:41:19.045870Z"
    }
   },
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense, Embedding\n",
    "import tensorflow as tf\n",
    "\n",
    "# Asumo que estas variables ya las tenés definidas arriba:\n",
    "# n_units, max_input_len, nb_words, embed_dim, embedding_matrix,\n",
    "# num_words_output, max_out_len\n",
    "\n",
    "n_units = 128\n",
    "\n",
    "# --- ENCODER ---\n",
    "encoder_inputs = Input(shape=(max_input_len,), name='Encoder_Input')\n",
    "\n",
    "encoder_embedding_layer = Embedding(\n",
    "    input_dim=nb_words,          # Tamaño del vocabulario de entrada\n",
    "    output_dim=embed_dim,        # Dimensión del vector denso (ej. 50 para GloVe)\n",
    "    weights=[embedding_matrix],  # Cargar pesos pre-entrenados\n",
    "    trainable=False,             # Congelar para no re-entrenar GloVe\n",
    "    name='Encoder_Embedding'\n",
    ")\n",
    "\n",
    "encoder_inputs_x = encoder_embedding_layer(encoder_inputs)\n",
    "\n",
    "# LSTM Encoder\n",
    "encoder = LSTM(n_units, return_state=True, name='Encoder_LSTM')\n",
    "encoder_outputs, state_h, state_c = encoder(encoder_inputs_x)\n",
    "\n",
    "# Guardamos los estados para pasarlos al decoder (Context Vector)\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "# --- DECODER ---\n",
    "decoder_inputs = Input(shape=(max_out_len,), name='Decoder_Input')\n",
    "\n",
    "decoder_embedding_layer = Embedding(\n",
    "    input_dim=num_words_output,\n",
    "    output_dim=n_units,\n",
    "    name='Decoder_Embedding'\n",
    ")\n",
    "decoder_inputs_x = decoder_embedding_layer(decoder_inputs)\n",
    "\n",
    "# LSTM Decoder\n",
    "# return_sequences=True es vital aquí porque queremos la predicción palabra por palabra\n",
    "decoder_lstm = LSTM(n_units, return_sequences=True, return_state=True, name='Decoder_LSTM')\n",
    "\n",
    "# Inicializamos el decoder con los estados del encoder\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_inputs_x, initial_state=encoder_states)\n",
    "\n",
    "# --- SALIDA ---\n",
    "decoder_dense = Dense(num_words_output, activation='softmax', name='Output_Layer')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "# --- MODELO ---\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs, name='Seq2Seq_Translator')\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=\"Adam\", metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1765550479.390930  475257 gpu_device.cc:2020] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4626 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1660 SUPER, pci bus id: 0000:0a:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1mModel: \"Seq2Seq_Translator\"\u001B[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"Seq2Seq_Translator\"</span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001B[1m \u001B[0m\u001B[1mLayer (type)       \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mOutput Shape     \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1m   Param #\u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mConnected to     \u001B[0m\u001B[1m \u001B[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Encoder_Input       │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m16\u001B[0m)        │          \u001B[38;5;34m0\u001B[0m │ -                 │\n",
       "│ (\u001B[38;5;33mInputLayer\u001B[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Decoder_Input       │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m18\u001B[0m)        │          \u001B[38;5;34m0\u001B[0m │ -                 │\n",
       "│ (\u001B[38;5;33mInputLayer\u001B[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Encoder_Embedding   │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m16\u001B[0m, \u001B[38;5;34m50\u001B[0m)    │    \u001B[38;5;34m192,550\u001B[0m │ Encoder_Input[\u001B[38;5;34m0\u001B[0m]… │\n",
       "│ (\u001B[38;5;33mEmbedding\u001B[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Decoder_Embedding   │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m18\u001B[0m, \u001B[38;5;34m128\u001B[0m)   │    \u001B[38;5;34m732,416\u001B[0m │ Decoder_Input[\u001B[38;5;34m0\u001B[0m]… │\n",
       "│ (\u001B[38;5;33mEmbedding\u001B[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Encoder_LSTM (\u001B[38;5;33mLSTM\u001B[0m) │ [(\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m128\u001B[0m),     │     \u001B[38;5;34m91,648\u001B[0m │ Encoder_Embeddin… │\n",
       "│                     │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m128\u001B[0m),      │            │                   │\n",
       "│                     │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m128\u001B[0m)]      │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Decoder_LSTM (\u001B[38;5;33mLSTM\u001B[0m) │ [(\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m18\u001B[0m, \u001B[38;5;34m128\u001B[0m), │    \u001B[38;5;34m131,584\u001B[0m │ Decoder_Embeddin… │\n",
       "│                     │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m128\u001B[0m),      │            │ Encoder_LSTM[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m…\u001B[0m │\n",
       "│                     │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m128\u001B[0m)]      │            │ Encoder_LSTM[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m…\u001B[0m │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Output_Layer        │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m18\u001B[0m, \u001B[38;5;34m5722\u001B[0m)  │    \u001B[38;5;34m738,138\u001B[0m │ Decoder_LSTM[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m…\u001B[0m │\n",
       "│ (\u001B[38;5;33mDense\u001B[0m)             │                   │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Encoder_Input       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Decoder_Input       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Encoder_Embedding   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">192,550</span> │ Encoder_Input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Decoder_Embedding   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │    <span style=\"color: #00af00; text-decoration-color: #00af00\">732,416</span> │ Decoder_Input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Encoder_LSTM (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>) │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>),     │     <span style=\"color: #00af00; text-decoration-color: #00af00\">91,648</span> │ Encoder_Embeddin… │\n",
       "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>),      │            │                   │\n",
       "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)]      │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Decoder_LSTM (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>) │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>), │    <span style=\"color: #00af00; text-decoration-color: #00af00\">131,584</span> │ Decoder_Embeddin… │\n",
       "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>),      │            │ Encoder_LSTM[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)]      │            │ Encoder_LSTM[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Output_Layer        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5722</span>)  │    <span style=\"color: #00af00; text-decoration-color: #00af00\">738,138</span> │ Decoder_LSTM[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Total params: \u001B[0m\u001B[38;5;34m1,886,336\u001B[0m (7.20 MB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,886,336</span> (7.20 MB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Trainable params: \u001B[0m\u001B[38;5;34m1,693,786\u001B[0m (6.46 MB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,693,786</span> (6.46 MB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Non-trainable params: \u001B[0m\u001B[38;5;34m192,550\u001B[0m (752.15 KB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">192,550</span> (752.15 KB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "L_xanat4INez",
    "ExecuteTime": {
     "end_time": "2025-12-12T14:41:32.272367Z",
     "start_time": "2025-12-12T14:41:32.261297Z"
    }
   },
   "source": [
    "encoder_model = Model(encoder_inputs, encoder_states)\n",
    "\n",
    "# define inference decoder\n",
    "decoder_state_input_h = Input(shape=(n_units,))\n",
    "decoder_state_input_c = Input(shape=(n_units,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "\n",
    "# En cada predicción habrá una sola palabra de entrada al decoder,\n",
    "# que es la realimentación de la palabra anterior\n",
    "# por lo que hay que modificar el input shape de la layer de Embedding\n",
    "decoder_inputs_single = Input(shape=(1,))\n",
    "decoder_inputs_single_x = decoder_embedding_layer(decoder_inputs_single)\n",
    "\n",
    "decoder_outputs, state_h, state_c = decoder_lstm(decoder_inputs_single_x, initial_state=decoder_states_inputs)\n",
    "decoder_states = [state_h, state_c]\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "decoder_model = Model([decoder_inputs_single] + decoder_states_inputs, [decoder_outputs] + decoder_states)\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "VnlIx1Vezjwc",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "51db248e-b85d-4fea-baa4-76cebc5a715a",
    "ExecuteTime": {
     "end_time": "2025-12-12T14:43:02.603587Z",
     "start_time": "2025-12-12T14:42:31.516589Z"
    }
   },
   "source": [
    "hist = model.fit(\n",
    "    [encoder_input_sequences, decoder_input_sequences],\n",
    "    decoder_targets,\n",
    "    epochs=10,\n",
    "    validation_split=0.2)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 23ms/step - accuracy: 0.7369 - loss: 1.4284 - val_accuracy: 0.7135 - val_loss: 2.0112\n",
      "Epoch 2/10\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 18ms/step - accuracy: 0.7400 - loss: 1.3831 - val_accuracy: 0.7145 - val_loss: 2.0112\n",
      "Epoch 3/10\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 18ms/step - accuracy: 0.7432 - loss: 1.3399 - val_accuracy: 0.7134 - val_loss: 2.0175\n",
      "Epoch 4/10\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 17ms/step - accuracy: 0.7482 - loss: 1.2962 - val_accuracy: 0.7137 - val_loss: 2.0185\n",
      "Epoch 5/10\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 18ms/step - accuracy: 0.7520 - loss: 1.2551 - val_accuracy: 0.7165 - val_loss: 2.0205\n",
      "Epoch 6/10\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 18ms/step - accuracy: 0.7560 - loss: 1.2137 - val_accuracy: 0.7157 - val_loss: 2.0271\n",
      "Epoch 7/10\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 18ms/step - accuracy: 0.7612 - loss: 1.1729 - val_accuracy: 0.7153 - val_loss: 2.0316\n",
      "Epoch 8/10\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 18ms/step - accuracy: 0.7669 - loss: 1.1331 - val_accuracy: 0.7155 - val_loss: 2.0409\n",
      "Epoch 9/10\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 18ms/step - accuracy: 0.7726 - loss: 1.0949 - val_accuracy: 0.7181 - val_loss: 2.0470\n",
      "Epoch 10/10\n",
      "\u001B[1m150/150\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 18ms/step - accuracy: 0.7788 - loss: 1.0566 - val_accuracy: 0.7167 - val_loss: 2.0533\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OVz1uug_zu2J"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Entrenamiento\n",
    "epoch_count = range(1, len(hist.history['accuracy']) + 1)\n",
    "sns.lineplot(x=epoch_count,  y=hist.history['accuracy'], label='train')\n",
    "sns.lineplot(x=epoch_count,  y=hist.history['val_accuracy'], label='valid')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zbwn0ekDy_s2"
   },
   "source": [
    "### 5 - Inferencia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jnkl3mSpsU_7"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Step 1:\n",
    "A deal is a deal -> Encoder -> enc(h1,c1)\n",
    "\n",
    "enc(h1,c1) + <sos> -> Decoder -> Un + dec(h1,c1)\n",
    "\n",
    "step 2:\n",
    "dec(h1,c1) + Un -> Decoder -> trato + dec(h2,c2)\n",
    "\n",
    "step 3:\n",
    "dec(h2,c2) + trato -> Decoder -> es + dec(h3,c3)\n",
    "\n",
    "step 4:\n",
    "dec(h3,c3) + es -> Decoder -> un + dec(h4,c4)\n",
    "\n",
    "step 5:\n",
    "dec(h4,c4) + un -> Decoder -> trato + dec(h5,c5)\n",
    "\n",
    "step 6:\n",
    "dec(h5,c5) + trato. -> Decoder -> <eos> + dec(h6,c6)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "71XeCtfYmOFx"
   },
   "outputs": [],
   "source": [
    "# Armar los conversores de índice a palabra:\n",
    "idx2word_input = {v:k for k, v in word2idx_inputs.items()}\n",
    "idx2word_target = {v:k for k, v in word2idx_outputs.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MlUyp9M6ua2V"
   },
   "outputs": [],
   "source": [
    "def translate_sentence(input_seq):\n",
    "    # Se transforma la sequencia de entrada a los estados \"h\" y \"c\" de la LSTM\n",
    "    # para enviar la primera vez al decoder\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "\n",
    "    # Se inicializa la secuencia de entrada al decoder como \"<sos>\"\n",
    "    target_seq = np.zeros((1, 1))\n",
    "    target_seq[0, 0] = word2idx_outputs['<sos>']\n",
    "\n",
    "    # Se obtiene el índice que finaliza la inferencia\n",
    "    eos = word2idx_outputs['<eos>']\n",
    "\n",
    "    output_sentence = []\n",
    "    for _ in range(max_out_len):\n",
    "        # Predicción del próximo elemento\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
    "        idx = np.argmax(output_tokens[0, 0, :])\n",
    "\n",
    "        # Si es \"end of sentece <eos>\" se acaba\n",
    "        if eos == idx:\n",
    "            break\n",
    "\n",
    "        # Transformar idx a palabra\n",
    "        word = ''\n",
    "        if idx > 0:\n",
    "            word = idx2word_target[idx]\n",
    "            output_sentence.append(word)\n",
    "\n",
    "        # Actualizar los estados dada la última predicción\n",
    "        states_value = [h, c]\n",
    "\n",
    "        # Actualizar secuencia de entrada con la salida (re-alimentación)\n",
    "        target_seq[0, 0] = idx\n",
    "\n",
    "    return ' '.join(output_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZhGVjLKcunxW"
   },
   "outputs": [],
   "source": [
    "i = np.random.choice(len(input_sentences))\n",
    "input_seq = encoder_input_sequences[i:i+1]\n",
    "translation = translate_sentence(input_seq)\n",
    "print('-')\n",
    "print('Input:', input_sentences[i])\n",
    "print('Response:', translation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KYZ1Q_Z_2G4m"
   },
   "outputs": [],
   "source": [
    "input_test = \"Goodnight.\"\n",
    "print('Input:', input_test)\n",
    "integer_seq_test = input_tokenizer.texts_to_sequences([input_test])[0]\n",
    "print(\"Representacion en vector de tokens de ids\", integer_seq_test)\n",
    "encoder_sequence_test = pad_sequences([integer_seq_test], maxlen=max_input_len)\n",
    "print(\"Padding del vector:\", encoder_sequence_test)\n",
    "\n",
    "print('Input:', input_test)\n",
    "translation = translate_sentence(encoder_sequence_test)\n",
    "print('Response:', translation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pkOjSJweqdF8"
   },
   "source": [
    "### 6 - Conclusión\n",
    "A primera vista parece que el modelo tendría que funcionar muy bien por el accuracy alcanzado. La realidad es que las respuestas no tienen que ver demasiado con la pregunta/traducción pero la respuesta en si tiene bastante coherencia.\\\n",
    "Para poder mejorar el modelo haría falta poder consumir todo el dataset y todo el vocabulario, pero la cantidad de RAM no es suficiente.\\\n",
    "Este problema se resuelve con:\n",
    "- Utilizando un DataGenerator para no levantar todo el dataset junto en el entrenamiento.\n",
    "- Transfer learning evitando tener que entrenar todo el modelo  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZSy0kaSKuC4-"
   },
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": [],
   "machine_shape": "hm",
   "gpuType": "A100"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
